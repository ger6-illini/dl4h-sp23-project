{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652e22f4",
   "metadata": {
    "id": "652e22f4"
   },
   "source": [
    "<h1><center>CS598 Deep Learning for Healthcare Spring 2023<br>Paper Reproduction Project</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5cbba",
   "metadata": {
    "id": "5ee5cbba"
   },
   "source": [
    "<h3><center>Gilberto Ramirez and Jay Kakwani<br><span style=\"font-family:monospace;\">{ger6, kakwani2}@illinois.edu</span><br><font color=\"lightgrey\">Group ID: 27 | Paper ID: 181</font></center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9fb1c-0d45-4092-9518-1d11d101362a",
   "metadata": {},
   "source": [
    "### Ablation Study :  36 hours (cutoff period) + 18 hours (gap period)\n",
    "\n",
    "In this ablation study, we will process and run ablation for 36 hour ICU Stay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cc966",
   "metadata": {
    "id": "612cc966"
   },
   "source": [
    "In this project, we aim to reproduce the paper [*Learning Task for Multitask Learning: Heterogeneous Patient Populations in the ICU* by (Suresh et al, 2018)](https://arxiv.org/abs/1806.02878). In this paper, the authors propose a novel two-step pipeline to predict in-hospital mortality across patient populations with different characteristics. The first step of the pipeline divides patients into relevant non-overlapping cohorts in an unsupervised way using a long short-term memory (LSTM) autoencoder followed by a Gaussian Mixture Model (GMM). The second step of the pipeline predicts in-hospital mortality for each patient cohort identified in the previous step using an LSTM based multi-task learning model where every cohort is considered a different task.\n",
    "The paper claims that by applying this pipeline there will be better predictive results when compared to a model applied to the aggregate population using a single task learning model. According to the authors, the better performance given by this pipeline is due to the combination of a multi-task learning model leveraging shared knowledge across distinct patient groups and the way how those groups were created, i.e., identification using a data-driven method rather than relying on domain knowledge or auxiliary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e318a",
   "metadata": {
    "id": "413e318a"
   },
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58470c",
   "metadata": {
    "id": "eb58470c"
   },
   "source": [
    "This paper uses the publicly available [MIMIC-III database](https://www.nature.com/articles/sdata201635) which contains clinical data in a critical care setting. After reviewing the paper in detail, we decided to use [MIMIC-Extract](https://arxiv.org/abs/1907.08322), an open source pipeline by (Wang et al., 2020) for transforming the raw EHR data into usable [Pandas](https://pandas.pydata.org/) dataframes containing hourly time series of vitals and laboratory measurements after performing unit conversion, outlier handling, and aggregation of semantically similar features.\n",
    "\n",
    "Unfortunately, the MIMIC-Extract pipeline misses two features the [paper code](https://github.com/mit-caml/multitask-patients) makes use of:\n",
    "* `timecmo_chart` which indicates the timestamp of a patient after being declared in CMO (Comfort Measures Only) state. This feature comes from a MIMIC-III concept table called `code_status`.\n",
    "* `sapsii` which contains the SAPS (Simplified Acute Physiology Score) II for the patient. This feature comes from another MIMIC-III concept table called `sapsii`.\n",
    "\n",
    "As a result, there are three data files needed to run this notebook:\n",
    "* `all_hourly_data.h5`, an HDF file resulting from running the MIMIC-Extract pipeline which is publicly available in GCP using [this link](https://console.cloud.google.com/storage/browser/mimic_extract) and referenced in the [MIMIC-Extract github repo](https://github.com/MLforHealth/MIMIC_Extract).\n",
    "* `code_status.csv`, a CSV file holding the MIMIC concept table `CODE_STATUS` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "* `sapsii.csv`, a CSV file holding the MIMIC concept table `SAPSII` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "\n",
    "The functions used in this notebook assume the three files listed above are in the folder `../data/` by default. However, location can be changed using arguments to the functions that process the data.\n",
    "\n",
    "All code needed to replicate the paper is in [our github repo](https://github.com/ger6-illini/dl4h-sp23-team27-project) inside a Python module called `mtl_patients`.\n",
    "\n",
    "The first function from that module we will start using is `get_summaries()`. This function returns three summaries as dataframes:\n",
    "1. A summary providing some statistics of all patients broken by careunit.\n",
    "2. A summary providing some statistics of all patients broken by SAPS-II score quartile.\n",
    "3. A summary providing some statistics of the 29 distinct physiological measurements used in the paper.\n",
    "\n",
    "These summaries need two arguments to be created:\n",
    "* `cutoff_hours` (default 24) which is the minimum number of hours a patient needs to stay in the ICU to be considered part of a cohort.\n",
    "* `gap_hours` (default 12) which is the number of hours between the end of `cutoff_hours` and the moment a model can start making a mortality prediction.\n",
    "\n",
    "The importance of these two arguments is his impact in the exception criteria used in the paper. In particular, the paper:\n",
    "1. Excludes all patients that met the in-hospital mortality criteria before `cutoff period` + `gap period`.\n",
    "2. Excludes patients that were discharged before `cutoff period` + `gap period`.\n",
    "\n",
    "The in-hospital mortality criteria used in the paper is an extended one and not just considers patients who died but also patients with a CMO (Comfort Measures Only) note. That is considered in the summaries creation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f3462",
   "metadata": {
    "id": "548f3462"
   },
   "source": [
    "### 1.1. Summaries, 36 hours (cutoff period) + 18 hours (gap period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493677c",
   "metadata": {
    "id": "2493677c"
   },
   "source": [
    "Now let's run the `get_summaries()` function with `cutoff_hours` = 36 and `gap_hours` = 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b6c0d1-0a31-46ce-abcb-2a8c3582dec2",
   "metadata": {
    "id": "86b6c0d1-0a31-46ce-abcb-2a8c3582dec2",
    "outputId": "8f229589-61f1-41b6-9d69-048010435dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 13/04/2023 01:59:42\n"
     ]
    }
   ],
   "source": [
    "# store/print start time to measure runtime\n",
    "from datetime import datetime\n",
    "starttime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f'Start time: {starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475bac15-872d-4bac-93f5-598314107b79",
   "metadata": {
    "id": "475bac15-872d-4bac-93f5-598314107b79",
    "outputId": "72f7bfcf-9412-41f7-b1b8-9c6341390003",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tables\n",
      "  Downloading tables-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting blosc2~=2.0.0\n",
      "  Downloading blosc2-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /home/paperspace/.local/lib/python3.9/site-packages (from tables) (1.23.2)\n",
      "Requirement already satisfied: cython>=0.29.21 in /home/paperspace/.local/lib/python3.9/site-packages (from tables) (0.29.32)\n",
      "Collecting numexpr>=2.6.2\n",
      "  Downloading numexpr-2.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (380 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.7/380.7 kB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/paperspace/.local/lib/python3.9/site-packages (from tables) (23.0)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-1.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-cpuinfo, msgpack, numexpr, blosc2, tables\n",
      "Successfully installed blosc2-2.0.0 msgpack-1.0.5 numexpr-2.8.4 py-cpuinfo-9.0.0 tables-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install `pytables` using `pip` if running from Paperspace since TensorFlow image does not have it\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d024700",
   "metadata": {
    "id": "2d024700",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "pathname = \"../code/\"\n",
    "if pathname not in sys.path:\n",
    "    sys.path.append(\"../code/\")\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "from mtl_patients import get_summaries\n",
    "from mtl_patients import discover_cohorts\n",
    "from mtl_patients import run_mortality_prediction_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04a5c55",
   "metadata": {
    "id": "e04a5c55",
    "outputId": "46348dbd-3dad-4f79-b704-334a2c19e24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Creating summaries\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Merging dataframes to create X_full...\n",
      "    Creating summary by careunit...\n",
      "    Creating summary by SAPS II score quartile...\n",
      "    Creating summary by vitals/labs...\n",
      "    Done!\n",
      "CPU times: user 8.19 s, sys: 3.41 s, total: 11.6 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pat_summ_36_by_cu_df, pat_summ_36_by_sapsiiq_df, vitals_labs_summ_36_df = get_summaries(cutoff_hours=36, gap_hours=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcc93e",
   "metadata": {
    "id": "12bcc93e"
   },
   "source": [
    "Let's now display the resulting summaries one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48560",
   "metadata": {
    "id": "48b48560"
   },
   "source": [
    "#### 1.1.1. Data summary by patients in each intensive care unit (ICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451bdc7a",
   "metadata": {
    "id": "451bdc7a",
    "outputId": "9d34b8d3-f143-430f-a124-6dcbd9d80837"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>Class Imbalance</th>\n",
       "      <th>Age (Mean)</th>\n",
       "      <th>Gender (Male)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Careunit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCU</th>\n",
       "      <td>4725</td>\n",
       "      <td>287</td>\n",
       "      <td>0.061</td>\n",
       "      <td>82.59</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>6932</td>\n",
       "      <td>124</td>\n",
       "      <td>0.018</td>\n",
       "      <td>69.41</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>11065</td>\n",
       "      <td>986</td>\n",
       "      <td>0.089</td>\n",
       "      <td>77.88</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>5062</td>\n",
       "      <td>347</td>\n",
       "      <td>0.069</td>\n",
       "      <td>72.69</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>4132</td>\n",
       "      <td>240</td>\n",
       "      <td>0.058</td>\n",
       "      <td>67.35</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>31916</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.062</td>\n",
       "      <td>74.55</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              N     n  Class Imbalance  Age (Mean)  Gender (Male)\n",
       "Careunit                                                         \n",
       "CCU        4725   287            0.061       82.59           0.58\n",
       "CSRU       6932   124            0.018       69.41           0.67\n",
       "MICU      11065   986            0.089       77.88           0.51\n",
       "SICU       5062   347            0.069       72.69           0.52\n",
       "TSICU      4132   240            0.058       67.35           0.61\n",
       "Overall   31916  1984            0.062       74.55           0.57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_summ_36_by_cu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dff829",
   "metadata": {
    "id": "f3dff829"
   },
   "source": [
    "In the previous summary, patients were broken in groups where each group is one of five careunits where patients were first admitted:\n",
    "* CCU: Coronary Care Unit\n",
    "* CSRU: Cardiac Surgery Recovery Unit\n",
    "* MICU: Medical Intensive Care Unit\n",
    "* SICU: Surgical Intensive Care Unit\n",
    "* TSICU: Trauma Surgical Intensive Care Unit\n",
    "\n",
    "In addition, an overall group was also added. The statistics provided by the summary are:\n",
    "* `N`: The number of samples (patients) in the group.\n",
    "* `n`: The number of samples (patients) meeting the in-hospital mortality criteria defined in the paper: patient died or had a note of \"Do Not Resuscitate\" (DNR) or had a note of \"Comfort Measures Only\" (CMO).\n",
    "* `Class Imbalance`: Ratio of patients meeting the in-hospital mortality criteria defined in the paper, i.e., $\\dfrac{\\text{n}}{\\text{N}}$.\n",
    "* `Age (Mean)`: Mean age of patients for each group in years.\n",
    "* `Gender (Male)`: Ratio of patients that are males.\n",
    "\n",
    "This summary was prepared to match Table 1 in the original paper. There are differences between both that can be attributed to the way how data was preprocessed by MIMIC-Extract when compared to the preprocessing done by the authors back in 2018, before MIMIC-Extract became available, and that was not made available by the authors in [their code](https://github.com/mit-caml/multitask-patients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a8e12",
   "metadata": {
    "id": "9f1a8e12"
   },
   "source": [
    "#### 1.1.2. Data summary by patients in each SAPS-II score quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1474f4",
   "metadata": {
    "id": "2d1474f4",
    "outputId": "114e803d-7a37-4227-ffb3-ac770d9e0189"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>Class Imbalance</th>\n",
       "      <th>Age (Mean)</th>\n",
       "      <th>Gender (Male)</th>\n",
       "      <th>SAPS II (Min)</th>\n",
       "      <th>SAPS II (Mean)</th>\n",
       "      <th>SAPS II (Max)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAPS II Quartile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6884</td>\n",
       "      <td>51</td>\n",
       "      <td>0.007</td>\n",
       "      <td>45.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>16.63</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9844</td>\n",
       "      <td>236</td>\n",
       "      <td>0.024</td>\n",
       "      <td>68.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>23</td>\n",
       "      <td>27.75</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7995</td>\n",
       "      <td>490</td>\n",
       "      <td>0.061</td>\n",
       "      <td>86.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>33</td>\n",
       "      <td>36.72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7193</td>\n",
       "      <td>1207</td>\n",
       "      <td>0.168</td>\n",
       "      <td>96.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>42</td>\n",
       "      <td>51.16</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>31916</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.062</td>\n",
       "      <td>74.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>32.87</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      N     n  Class Imbalance  Age (Mean)  Gender (Male)  \\\n",
       "SAPS II Quartile                                                            \n",
       "0                  6884    51            0.007       45.83           0.61   \n",
       "1                  9844   236            0.024       68.84           0.58   \n",
       "2                  7995   490            0.061       86.50           0.55   \n",
       "3                  7193  1207            0.168       96.58           0.53   \n",
       "Overall           31916  1984            0.062       74.55           0.57   \n",
       "\n",
       "                  SAPS II (Min)  SAPS II (Mean)  SAPS II (Max)  \n",
       "SAPS II Quartile                                                \n",
       "0                             0           16.63             22  \n",
       "1                            23           27.75             32  \n",
       "2                            33           36.72             41  \n",
       "3                            42           51.16            118  \n",
       "Overall                       0           32.87            118  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_summ_36_by_sapsiiq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711c274",
   "metadata": {
    "id": "0711c274"
   },
   "source": [
    "In the previous summary, patients were broken based on the quartile of the SAPS-II score assigned to them. As it can be seen, the four quartiles have the ranges $[0, 22], [23, 32], [33, 41], [42, 118] $. This was included in the authors code but not in the paper. It seems the class imbalance might have been the primary reason. As it is evident from the summary, most of the patients are in quartile $3$ since they are in an ICU and is expected their values are on the high side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0959c",
   "metadata": {
    "id": "c3b0959c"
   },
   "source": [
    "#### 1.1.3. Data summary for physiological measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2e18ef",
   "metadata": {
    "id": "2c2e18ef",
    "outputId": "9e7865e7-e77c-4edf-f8af-dc4ab8da9876"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>N</th>\n",
       "      <th>pres.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anion gap</th>\n",
       "      <td>5.00</td>\n",
       "      <td>13.56</td>\n",
       "      <td>50.00</td>\n",
       "      <td>3.78</td>\n",
       "      <td>175155</td>\n",
       "      <td>0.0830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>53.00</td>\n",
       "      <td>4.65</td>\n",
       "      <td>183740</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood urea nitrogen</th>\n",
       "      <td>0.00</td>\n",
       "      <td>25.98</td>\n",
       "      <td>250.00</td>\n",
       "      <td>21.55</td>\n",
       "      <td>185610</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>50.00</td>\n",
       "      <td>105.19</td>\n",
       "      <td>175.00</td>\n",
       "      <td>6.22</td>\n",
       "      <td>201959</td>\n",
       "      <td>0.0957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.38</td>\n",
       "      <td>46.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>186419</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diastolic blood pressure</th>\n",
       "      <td>0.00</td>\n",
       "      <td>60.96</td>\n",
       "      <td>307.00</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1839715</td>\n",
       "      <td>0.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction inspired oxygen</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>93794</td>\n",
       "      <td>0.0444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glascow coma scale total</th>\n",
       "      <td>3.00</td>\n",
       "      <td>12.65</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>361281</td>\n",
       "      <td>0.1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>33.00</td>\n",
       "      <td>139.87</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>55.91</td>\n",
       "      <td>495648</td>\n",
       "      <td>0.2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart rate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>84.85</td>\n",
       "      <td>300.00</td>\n",
       "      <td>17.07</td>\n",
       "      <td>1898825</td>\n",
       "      <td>0.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hematocrit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>30.94</td>\n",
       "      <td>71.70</td>\n",
       "      <td>5.28</td>\n",
       "      <td>243966</td>\n",
       "      <td>0.1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>22.10</td>\n",
       "      <td>1.87</td>\n",
       "      <td>196643</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>0.40</td>\n",
       "      <td>2.44</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>56311</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnesium</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>173274</td>\n",
       "      <td>0.0821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean blood pressure</th>\n",
       "      <td>14.00</td>\n",
       "      <td>79.49</td>\n",
       "      <td>330.00</td>\n",
       "      <td>15.39</td>\n",
       "      <td>1830620</td>\n",
       "      <td>0.8670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxygen saturation</th>\n",
       "      <td>0.00</td>\n",
       "      <td>96.77</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1816478</td>\n",
       "      <td>0.8603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial thromboplastin time</th>\n",
       "      <td>18.80</td>\n",
       "      <td>40.97</td>\n",
       "      <td>150.00</td>\n",
       "      <td>24.31</td>\n",
       "      <td>129227</td>\n",
       "      <td>0.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>6.50</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.07</td>\n",
       "      <td>191486</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phosphate</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3.45</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>112940</td>\n",
       "      <td>0.0535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelets</th>\n",
       "      <td>0.00</td>\n",
       "      <td>204.89</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>113.17</td>\n",
       "      <td>178310</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>0.80</td>\n",
       "      <td>4.12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>226398</td>\n",
       "      <td>0.1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prothrombin time inr</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>88.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>122730</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prothrombin time pt</th>\n",
       "      <td>2.39</td>\n",
       "      <td>15.86</td>\n",
       "      <td>150.00</td>\n",
       "      <td>6.73</td>\n",
       "      <td>122708</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respiratory rate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>300.00</td>\n",
       "      <td>5.69</td>\n",
       "      <td>1869228</td>\n",
       "      <td>0.8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>50.00</td>\n",
       "      <td>138.57</td>\n",
       "      <td>225.00</td>\n",
       "      <td>5.18</td>\n",
       "      <td>213272</td>\n",
       "      <td>0.1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systolic blood pressure</th>\n",
       "      <td>0.00</td>\n",
       "      <td>122.08</td>\n",
       "      <td>311.00</td>\n",
       "      <td>21.80</td>\n",
       "      <td>1840139</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>26.00</td>\n",
       "      <td>36.98</td>\n",
       "      <td>42.22</td>\n",
       "      <td>0.77</td>\n",
       "      <td>626196</td>\n",
       "      <td>0.2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.00</td>\n",
       "      <td>83.35</td>\n",
       "      <td>250.00</td>\n",
       "      <td>23.40</td>\n",
       "      <td>58904</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white blood cell count</th>\n",
       "      <td>0.10</td>\n",
       "      <td>11.85</td>\n",
       "      <td>939.00</td>\n",
       "      <td>9.58</td>\n",
       "      <td>170830</td>\n",
       "      <td>0.0809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               min     avg      max     std        N   pres.\n",
       "variable                                                                    \n",
       "anion gap                     5.00   13.56    50.00    3.78   175155  0.0830\n",
       "bicarbonate                   0.00   24.37    53.00    4.65   183740  0.0870\n",
       "blood urea nitrogen           0.00   25.98   250.00   21.55   185610  0.0879\n",
       "chloride                     50.00  105.19   175.00    6.22   201959  0.0957\n",
       "creatinine                    0.10    1.38    46.60    1.48   186419  0.0883\n",
       "diastolic blood pressure      0.00   60.96   307.00   14.06  1839715  0.8713\n",
       "fraction inspired oxygen      0.21    0.53     1.00    0.19    93794  0.0444\n",
       "glascow coma scale total      3.00   12.65    15.00    3.45   361281  0.1711\n",
       "glucose                      33.00  139.87  1591.00   55.91   495648  0.2347\n",
       "heart rate                    0.00   84.85   300.00   17.07  1898825  0.8993\n",
       "hematocrit                    0.00   30.94    71.70    5.28   243966  0.1155\n",
       "hemoglobin                    0.00   10.62    22.10    1.87   196643  0.0931\n",
       "lactate                       0.40    2.44    30.00    2.24    56311  0.0267\n",
       "magnesium                     0.00    2.05    20.00    0.41   173274  0.0821\n",
       "mean blood pressure          14.00   79.49   330.00   15.39  1830620  0.8670\n",
       "oxygen saturation             0.00   96.77   100.00    3.37  1816478  0.8603\n",
       "partial thromboplastin time  18.80   40.97   150.00   24.31   129227  0.0612\n",
       "ph                            6.50    7.38     8.40    0.07   191486  0.0907\n",
       "phosphate                     0.50    3.45    20.00    1.37   112940  0.0535\n",
       "platelets                     0.00  204.89  2000.00  113.17   178310  0.0845\n",
       "potassium                     0.80    4.12    12.00    0.64   226398  0.1072\n",
       "prothrombin time inr          0.50    1.50    88.80    1.20   122730  0.0581\n",
       "prothrombin time pt           2.39   15.86   150.00    6.73   122708  0.0581\n",
       "respiratory rate              0.00   19.09   300.00    5.69  1869228  0.8853\n",
       "sodium                       50.00  138.57   225.00    5.18   213272  0.1010\n",
       "systolic blood pressure       0.00  122.08   311.00   21.80  1840139  0.8715\n",
       "temperature                  26.00   36.98    42.22    0.77   626196  0.2966\n",
       "weight                        0.00   83.35   250.00   23.40    58904  0.0279\n",
       "white blood cell count        0.10   11.85   939.00    9.58   170830  0.0809"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitals_labs_summ_36_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cab69",
   "metadata": {
    "id": "166cab69"
   },
   "source": [
    "In the previous summary, all vitals and lab measurements selected in the paper (29 in total) are listed with relevant statistics associated to it:\n",
    "* `min` representing the minimum of the measurement observed in the vitals/labs.\n",
    "* `avg` representing the average of the measurement observed in the vitals/labs.\n",
    "* `max` representing the maximum of the measurement observed in the vitals/labs.\n",
    "* `std` representing the standard deviation of the measurement observed in the vitals/labs.\n",
    "* `N` representing the number of non `NaN` samples for the specific vital/lab measurement.\n",
    "* `pres.` representing the portion of all possible hours across all patients, admissions, and ICU stays where at least one of the 104 vitals/labs measurements in the original MIMIC-Extract pipeline was taken.\n",
    "\n",
    "All these measurements are based on the `vitals_labs_mean` dataframe in the MIMIC-Extract pipeline which provides average of vitals/labs on a per hour basis for each patient after going into an ICU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b21a0",
   "metadata": {
    "id": "f21b21a0"
   },
   "source": [
    "## 2. Discovering Patient Cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a385d",
   "metadata": {
    "id": "3a0a385d"
   },
   "source": [
    "The paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the first step of the pipeline, i.e., patient cohort discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac0335",
   "metadata": {
    "id": "e0ac0335"
   },
   "source": [
    "In order to identify meaningful patient cohorts, the paper proposes to process the raw patient data in such a way that the result is a 3D matrix of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features as depicted in the figure below (in blue) which is partially based on Figure 2 of the original paper. All numbers shown in the figure below correspond to a specific experiment published in the paper in which the observation window is limited to the first $24$ hours (cutoff period) after a patient goes into a careunit and there is a gap of $12$ hours (gap period) between the end of the observation window and the beginning of the prediction window where the prediction task is in-hospital mortality.\n",
    "\n",
    "Preparation of the data to get the 3D (blue) matrix is performed by a function called `prepare_data()` inside the `mtl_patients.py` module. This preparation consists of the following transformations taken from the paper and the author's code reference implementation:\n",
    "1. Calculation of the mortality flag (prediction label) and mortality time for every patient in the dataset using an *extended* definition of mortality: death, a note of \"Do Not Resuscitate\" (DNR), or a note of \"Comfort Measures Only\" (CMO). In case any of these conditions are met for a patient, the corresponding mortality label is set to *True* and the corresponding mortality time is considered as the earliest time of any of the three conditions. After reviewing in detail the author's code implementation it seems mortality is based on deathtime and a CMO note but not DNR. However, the calculation of the time of death is based on the earliest time of the three conditions.\n",
    "2. Data used for the prediction is only limited to the first certain amount of hours after a patient goes into the ICU. This amount of hours is called inside the code \"a cutoff period\" (observation window) and defines the period of data used to train all models. In addition, there is another number of hours called inside the code \"the gap period\" which represents the time between the end of the observation window and the beginning of the prediction window to prevent label leakage. All patients that died under the *extended* definition before the cutoff period plus the gap period or stayed less than the cutoff period are excluded from the experiment as part of this step. Also, all patients under the age of 15 are excluded (this is already part of the exclusion criteria of the MIMIC-Extract pipeline).\n",
    "3. There are 29 vitals/labs timeseries selected by the paper. Only data within the cutoff period for vitals/labs is kept and rest is removed. This will be used for the rest of the machine learning pipeline.\n",
    "4. All vitals/labs values are converted to z-scores so they all have zero mean and unit standard deviation. Those z-scores are rounded to the closest integer and clipped between $-4$ and $4$ or set to $9$ in case of `NaN`. This allows to map every vital/lab measurement (a float) to one of ten possible values $[-4, -3, -2, -1, 0, 1, 2, 3, 4, 9]$, so they can be converted to dummy values. After dummifying the vitals/labs, column for the $9$ values (`NaN`) is removed, and the resulting matrix is sparse and containing either $0$s or $1$s.\n",
    "5. Every patient is padded with rows of zeroes for those hours that are missed. For example, if a patient only has vitals/labs for the first ten hours and the cutoff period is 24, code adds fourteen hours (rows) with zeroes for that patient. In the end, the matrix will have a size of $P \\times T \\times F$ as expected by the subsequent models.\n",
    "6. Finally, static data (gender, age, and ethnicity) is converted to integers representing categories and dummified. In case of age, there are four buckets established; $(10, 30), (30, 50), (50, 70), (70, \\infty)$; while ethnicity is broken into five buckets (asian, white, hispanic, black, other).\n",
    "7. Cohort assignments based on first careunit or Simplified Acute Physiology Score (SAPS) II score quartile is calculated for each patient and returned as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d014e8",
   "metadata": {
    "id": "45d014e8"
   },
   "source": [
    "![Figure 1](../img/paper-181-fig-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a251",
   "metadata": {
    "id": "c040a251"
   },
   "source": [
    "The `discover_cohorts()` function inside the `mtl_patients.py` module is the one implementing the pipeline shown in the figure above and then calling the `prepare_data()` function detailed previously as the first step. Once data has been processed, the function will break the data in training, validation, and test data sets in a $70\\%/10\\%/20\\%$ proportion.\n",
    "\n",
    "The training data is used to train an LSTM autoencoder. The main purpose of the LSTM autoencoder is to generate a fixed-length dense representation (embedding) of the sparse inputs trying to retain the most important parts of the inputs. The paper selected embeddings of size $50$ as the optimal dimension (hyperparameter). The purple box in the middle of the diagram above (a 2D matrix) represents the embeddings after the LSTM autoencoder learned the representation of the original 3D matrix of shape $(32537 \\times 24 \\times 232)$ where every row corresponds to a patient.\n",
    "\n",
    "Once the embeddings are calculated, a Gaussian Mixture Model is applied using $3$ clusters (the value the authors considered optimal). The result are the three green boxes representing three cohorts discovered in an unsupervised way and grouping similar patients based on the three static and the 29 time-varying vitals/labs selected from the MIMIC-III database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa284f2-7c60-42ae-a9f7-80b5236438fc",
   "metadata": {
    "id": "0fa284f2-7c60-42ae-a9f7-80b5236438fc"
   },
   "source": [
    "### 2.1. Cohort statistics at 36 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc972ff9-3e4b-4c88-b942-f267162c0b34",
   "metadata": {
    "id": "cc972ff9-3e4b-4c88-b942-f267162c0b34"
   },
   "source": [
    "The paper runs two experiments. The first experiment uses a cutoff period of 36 hours, a gap period of 18 hours, and three clusters. Let's run this first experiment using the `discover_cohorts()` function and determine the corresponding cohort assignment for every patient that does not meet the exception criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81181566",
   "metadata": {
    "id": "81181566"
   },
   "outputs": [],
   "source": [
    "from mtl_patients import discover_cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f8b82b",
   "metadata": {
    "id": "71f8b82b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Discovering cohorts in an unsupervised way\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Training LSTM autoencoder started at 13/04/2023 02:00:36. This will take several minutes (5 to 25). Please be patient...\n",
      "Epoch 1/100\n",
      "175/175 [==============================] - 8s 22ms/step - loss: 0.0368 - val_loss: 0.0316\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0292 - val_loss: 0.0276\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0265 - val_loss: 0.0259\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0252 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0244 - val_loss: 0.0242\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0234 - val_loss: 0.0233\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0228 - val_loss: 0.0227\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0214 - val_loss: 0.0215\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 55/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 56/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 57/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 58/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 59/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 60/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 61/100\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 62/100\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 63/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 64/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0200 - val_loss: 0.0202\n",
      "Epoch 65/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 66/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 67/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 68/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 69/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 70/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 71/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 72/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 73/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 74/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 75/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 76/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 77/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 78/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 79/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 80/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 81/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 82/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 83/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 84/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 85/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 86/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 87/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 88/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 89/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 90/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 91/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 92/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 93/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 94/100\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 95/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 96/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 97/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 98/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 99/100\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 100/100\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 0.0196 - val_loss: 0.0197\n",
      "    LSTM autoencoder trained!\n",
      "699/699 [==============================] - 2s 2ms/step\n",
      "998/998 [==============================] - 3s 2ms/step\n",
      "Patient embeddings created! Shape: (31916, 50)\n",
      "    Training Gaussian Mixture Model...\n",
      "    Gaussian Mixture Model applied to embeddings! Results shape: (31916,)\n",
      "    Cluster results saved to '../data/unsupervised_clusters_36.npy'\n",
      "    Done!\n",
      "CPU times: user 4min 15s, sys: 1min 42s, total: 5min 58s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cohort_unsupervised_36 = discover_cohorts(cutoff_hours=36, gap_hours=18, cohort_unsupervised_filename='../data/unsupervised_clusters_36.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d175b6-7a5e-4a1b-9afc-67a94c9a0d6b",
   "metadata": {
    "id": "48d175b6-7a5e-4a1b-9afc-67a94c9a0d6b",
    "tags": []
   },
   "source": [
    "Let's summarize the results of the 36 hour experiments similar to what Table 3 of the paper shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467dec00-4046-44dd-981b-6e6eaccc280f",
   "metadata": {
    "id": "467dec00-4046-44dd-981b-6e6eaccc280f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "# Let's create the summary for the 36 hour experiment\n",
    "\n",
    "cohort_unsupervised_36 = np.load('../data/unsupervised_clusters_36.npy')\n",
    "\n",
    "from mtl_patients import prepare_data\n",
    "_, Y, _, _, subject_ids = prepare_data(cutoff_hours=36, gap_hours=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c859cfff-9c3a-4135-bf83-52a30982042e",
   "metadata": {
    "id": "c859cfff-9c3a-4135-bf83-52a30982042e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "subject_ids = np.array(subject_ids.tolist())\n",
    "cohort_unsupervised_36_df = pd.DataFrame({'subject_id': subject_ids, 'Y': Y, 'Group': cohort_unsupervised_36}, dtype=int)\n",
    "\n",
    "# calculate summaries per cohort (36 hours)\n",
    "table3_a_df = cohort_unsupervised_36_df.groupby('Group').agg(\n",
    "    N=('Y', 'size'),\n",
    "    n=('Y', 'sum'),\n",
    ")\n",
    "table3_a_df.loc[:, 'Experiment'] = '36 hours'\n",
    "table3_a_df.loc[:, 'Cohort Type'] = 'Unsupervised'\n",
    "\n",
    "# calculate overall summary (36 hours)\n",
    "table3_a_overall_df = table3_a_df.groupby(['*'] * len(table3_a_df)).agg(\n",
    "    N=('N', 'sum'),\n",
    "    n=('n', 'sum'),\n",
    ")\n",
    "table3_a_overall_df.index.name = 'Group'\n",
    "table3_a_overall_df.loc[:, 'Experiment'] = '36 hours'\n",
    "table3_a_overall_df.loc[:, 'Cohort Type'] = 'Global'\n",
    "\n",
    "# merge 24 hour tables and make cosmetic changes\n",
    "table3_a_df = pd.concat([table3_a_df, table3_a_overall_df], axis=0)\n",
    "table3_a_df.reset_index(inplace=True)\n",
    "table3_a_df.set_index(['Experiment', 'Cohort Type', 'Group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af29a681-55f8-40db-ab68-51567aa5b1cb",
   "metadata": {
    "id": "af29a681-55f8-40db-ab68-51567aa5b1cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# assign\n",
    "table3_df = table3_a_df\n",
    "\n",
    "# calculate class imbalance\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'n'] / table3_df.loc[:, 'N']\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'Class Imbalance'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fcfcf3-9d5b-42e0-be79-29ed32ab4e3d",
   "metadata": {
    "id": "e9fcfcf3-9d5b-42e0-be79-29ed32ab4e3d",
    "outputId": "ea89dd43-9445-48fa-c59a-f54ab93a455f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>Class Imbalance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>Cohort Type</th>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">36 hours</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Unsupervised</th>\n",
       "      <th>0</th>\n",
       "      <td>18130</td>\n",
       "      <td>1059</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2721</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11065</td>\n",
       "      <td>836</td>\n",
       "      <td>0.0756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <th>*</th>\n",
       "      <td>31916</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.0622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   N     n  Class Imbalance\n",
       "Experiment Cohort Type  Group                              \n",
       "36 hours   Unsupervised 0      18130  1059           0.0584\n",
       "                        1       2721    89           0.0327\n",
       "                        2      11065   836           0.0756\n",
       "           Global       *      31916  1984           0.0622"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29774c-0fff-481f-8110-161bed1b65a5",
   "metadata": {
    "id": "8b29774c-0fff-481f-8110-161bed1b65a5"
   },
   "source": [
    "Table above is the equivalent to Table 3 in the paper. We can see the results are different. Data from MIMIC-Extract might be different from the data used by the authors.\n",
    "\n",
    "** TO-DO ** Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671387b-6023-49c7-a119-8ae1021d8e08",
   "metadata": {
    "id": "a671387b-6023-49c7-a119-8ae1021d8e08"
   },
   "source": [
    "### 2.2. Visualization of selected lab test and vital signs features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1077e-5513-4da4-a004-bb6e129517db",
   "metadata": {
    "id": "82f1077e-5513-4da4-a004-bb6e129517db"
   },
   "source": [
    "In this section, we will try to reproduce the results from Figure 4 (section 6.1.1) in the paper. In Figure 4, data from experiment 1 (18 hours) is used to create heatmap plots to determine if patients from different cohorts are physiologically distinct. To do that, we added the function `get_heatmap_data()` to get the mean of all z-scores by patient, by hour in the ICU, by cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901b173-79ad-48d2-bbfe-1777bf4018d3",
   "metadata": {
    "id": "e901b173-79ad-48d2-bbfe-1777bf4018d3"
   },
   "source": [
    "#### 2.2.1. Heatmap plots for experiment 1 (36 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fcfdf-b0a2-4b96-be22-a6161ac264c0",
   "metadata": {
    "id": "e04fcfdf-b0a2-4b96-be22-a6161ac264c0"
   },
   "source": [
    "Let's run the `get_heatmap_data()` function using the cohorts discovered in experiment 1 (36 hour cutoff period and 18 hour gap period):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072de563-acf3-4d8d-9cfa-28cff6c798b5",
   "metadata": {
    "id": "072de563-acf3-4d8d-9cfa-28cff6c798b5",
    "outputId": "76cae05d-5a45-4246-a0a3-eff3612c2ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 s, sys: 2.83 s, total: 8.58 s\n",
      "Wall time: 7.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import get_heatmap_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labs_df, vitals_df = get_heatmap_data(cutoff_hours=36, gap_hours=18,\n",
    "                                      cohort_unsupervised_filename='../data/unsupervised_clusters_36.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e156d2-30a5-4f54-9223-0a33ac593ac7",
   "metadata": {
    "id": "d9e156d2-30a5-4f54-9223-0a33ac593ac7"
   },
   "source": [
    "Let's plot the heatmaps for the selected lab tests and vitals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b3a472-9588-4bb6-b473-a19df11e1886",
   "metadata": {
    "id": "66b3a472-9588-4bb6-b473-a19df11e1886"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x1800 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cohorts = len(np.unique(labs_df.index.get_level_values(0)))\n",
    "fig, axs = plt.subplots(nrows=2, ncols=num_cohorts)\n",
    "fig.set_size_inches(24, 12)\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = labs_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[0, i], yticklabels=True if i==0 else False).set(title=f'Lab Tests – Cohort {i}')\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = vitals_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[1, i], yticklabels=True if i==0 else False).set(title=f'Vitals – Cohort {i}')\n",
    "plt.savefig('../img/heatmap_36')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c31f21-a203-44cb-b0e7-51b340e8b411",
   "metadata": {
    "id": "96c31f21-a203-44cb-b0e7-51b340e8b411"
   },
   "source": [
    "From the heatmap plots there are some trends in the physiological data that seems to show a distinction between cohorts. \n",
    "\n",
    "** TO-DO ** Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db5427-8514-4b98-a260-ba574192e822",
   "metadata": {
    "id": "50db5427-8514-4b98-a260-ba574192e822"
   },
   "source": [
    "## 3. Predicting In-Hospital Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e49cd5-dafc-401c-b946-2be0c4734bfb",
   "metadata": {
    "id": "90e49cd5-dafc-401c-b946-2be0c4734bfb"
   },
   "source": [
    "As mentioned in the previous section, the paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the second step of the pipeline, i.e., use multi-task learning to make in-hospital mortality predictions for different patient cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68d853-3a48-403e-8ee9-427bb876f783",
   "metadata": {
    "id": "cd68d853-3a48-403e-8ee9-427bb876f783"
   },
   "source": [
    "The second step uses as input the result from the first step which is a series of 3D matrices, one per discovered cohort, of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features. As an example, the 24 hour experiment described by the authors in the paper and reproduced in the previous section resulted in three cohorts (clusters) called group 0, group 1, and group 2 where the shapes of the corresponding 3D matrices are:\n",
    "* $14120 \\times 24 \\times 232$ for group 0,\n",
    "* $10841 \\times 24 \\times 232$ for group 1, and\n",
    "* $7752 \\times 24 \\times 232$ for group 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbd026-c557-41b8-b7ac-f1d11e78aef3",
   "metadata": {
    "id": "fdcbd026-c557-41b8-b7ac-f1d11e78aef3"
   },
   "source": [
    "To convert these matrices into predictions, the paper proposes an LSTM for all model configurations including the baseline. In particular, the paper shows results from two specific models: a baseline model that is called *global* and using single-task learning and the multi-task learning model the authors claim as superior to the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f9738-790c-472c-b329-bcc654eaea0a",
   "metadata": {
    "id": "530f9738-790c-472c-b329-bcc654eaea0a"
   },
   "source": [
    "A diagram of the baseline (*global*) model proposed by the authors is shown below. As it can be seen, this model consists of an LSTM layer of 16 cells using a RELU activation function followed by a *single* dense layer with a sigmoid activation function. The result of the dense (fully-connected) layer is an estimate of the probability of in-hospital mortality for a given patient. This baseline model is trained with all patient samples regardless the cohort, hence the name *global*, and used for per cohort predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07256b-dc0b-4238-8a79-c37ddba39885",
   "metadata": {
    "id": "9b07256b-dc0b-4238-8a79-c37ddba39885"
   },
   "source": [
    "![Figure 2](../img/paper-181-fig-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44531b75-a84e-4089-9a2a-3620becfc355",
   "metadata": {
    "id": "44531b75-a84e-4089-9a2a-3620becfc355"
   },
   "source": [
    "Moving to the second model and the one the authors claim it provides benefits against the baseline is the so called *multi-task learning model*. This model consists of an LSTM layer with same number of cells (16) as the baseline model, to ensure the comparison is fair, connected to as many dense layers as population subgroups (cohorts). Each of these cohorts is considered a *task* and authors propose training these models on multiple tasks simultaneously in contrast to the baseline model with just one dense layer. The benefit of this approach according to the authors is the ability to share knowledge learned from one task (cohort) to rest of tasks under the assumption that the subpopulations used are distinct enough with relation to the outcome learned (mortality) that such shared knowledge truly exists. A representation of the multi-task learning model is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8a713-3999-400d-880d-1c98a8738ab8",
   "metadata": {
    "id": "bfb8a713-3999-400d-880d-1c98a8738ab8"
   },
   "source": [
    "![Figure 3](../img/paper-181-fig-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776d05-12aa-4b18-ac87-468f91d79ee1",
   "metadata": {
    "id": "5c776d05-12aa-4b18-ac87-468f91d79ee1"
   },
   "source": [
    "For benchmarking purposes of the entire pipeline, the authors compared the results from running the pipeline using unsupervised cohort discovery (step one) against cohorts created using the first careunit the patient went into which can be considered an engineered feature. We will show those results in the next subsections.\n",
    "\n",
    "The overall performance of this model is measured using both macro and micro metrics (section 4.3 in the paper) where:\n",
    "* In *micro* metrics all predicted probabilities for all patients are treated as if they come from a single classifier: $\\text{Metric}_\\text{Micro} = \\text{Metric}([\\hat{y}_0, ..., \\hat{y}_k], [y_0, ..., y_K])$.\n",
    "* In *macro* metrics probabilities are evaluated on a *per cohort* basis, and then averaged: $\\text{Metric}_\\text{Macro} = \\dfrac{1}{K} \\displaystyle\\sum_{k=0}^K \\text{Metric}(\\hat{y}_K, y_K)$.\n",
    "\n",
    "Paper suggests that, although micro metrics are the ones typically chosen in the literature, evaluating performance on different subpopulations will benefit from macro metrics instead of micro metrics specially when there is class imbalance in every cohort. All results show macro and micro versions of the metrics for the aggregate performance of the models.\n",
    "\n",
    "All results being used for comparison between models by the paper will use three metrics:\n",
    "* AUC (Area Under the ROC Curve) for every cohort and, for the aggregate performance, macro and micro.\n",
    "* PPV (Positive Predictive Value which is same as Precision) for every cohort and, for the aggregate performance, macro and micro. This PPV is calculated at a sensitivity of 80%, a value selected by the paper authors.\n",
    "* Specificity for every cohort and, for the aggregate performance, macro and micro. This specificity is calculated at a sensitivity of 80%, a value selected by the paper authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec025760-eb01-4aab-8180-304ae4599a38",
   "metadata": {
    "id": "ec025760-eb01-4aab-8180-304ae4599a38"
   },
   "source": [
    "All in-hospital mortality prediction tasks are implemented using the function `run_mortality_prediction_task()`. This function will call other functions to prepare the data, split the data in training/validation/test data sets, train the corresponding model, predict using the resulting model, and calculate the metrics of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d4117-f1f1-4d75-aead-36a9c740e9ae",
   "metadata": {
    "id": "d78d4117-f1f1-4d75-aead-36a9c740e9ae"
   },
   "source": [
    "### 3.1. Predictions with Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da524a9c-1d6f-4d2d-b37d-2e0ef4c369b3",
   "metadata": {
    "id": "da524a9c-1d6f-4d2d-b37d-2e0ef4c369b3"
   },
   "source": [
    "In this section all in-hospital mortality predictions across the two models, global and multi-task learning, and for 36 hours experiment, are calculated for the three metrics; AUC, PPV (precision) @80% sensitivity, and Specificity @80% sensitivity; using 100 bootstrapped samples of the test set (20% of the original dataset). The results will be metrics (AUC, PPV, and Specificity) for each bootstrapped sample. This will allow the comparison between the global model and the multi-task learning model using the Wilcoxon signed-rank test as indicated in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28906d07-2252-4ee3-b4c0-536add086263",
   "metadata": {
    "id": "28906d07-2252-4ee3-b4c0-536add086263"
   },
   "source": [
    "#### 3.1.1. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 36 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a1bcc-c348-4d61-9ecf-0ee3ab219132",
   "metadata": {
    "id": "d52a1bcc-c348-4d61-9ecf-0ee3ab219132"
   },
   "source": [
    "Let's first run the mortality prediction task using the *global* model (baseline) in the 36 hour experiment setting. In this experiment, the cutoff period is 36 hours and the gap period is 18 hours, meaning model can only feed from patient data collected during the first 36 hours of the ICU stay, and predict mortality 54 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eacb099-b8b7-46c2-9d5b-b7bb024edf02",
   "metadata": {
    "id": "7eacb099-b8b7-46c2-9d5b-b7bb024edf02",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3278\n",
      "        # of patients in cohort CSRU is 4901\n",
      "        # of patients in cohort MICU is 7744\n",
      "        # of patients in cohort SICU is 3542\n",
      "        # of patients in cohort TSICU is 2875\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"single_task_learning_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                15936     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "224/224 [==============================] - 10s 39ms/step - loss: 0.4016 - accuracy: 0.9365 - val_loss: 0.2870 - val_accuracy: 0.9380\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.2554 - accuracy: 0.9378 - val_loss: 0.2309 - val_accuracy: 0.9380\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.2240 - accuracy: 0.9378 - val_loss: 0.2193 - val_accuracy: 0.9380\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.2143 - accuracy: 0.9378 - val_loss: 0.2105 - val_accuracy: 0.9380\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.2047 - accuracy: 0.9378 - val_loss: 0.2016 - val_accuracy: 0.9380\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1966 - accuracy: 0.9379 - val_loss: 0.1938 - val_accuracy: 0.9380\n",
      "Epoch 7/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1903 - accuracy: 0.9379 - val_loss: 0.1881 - val_accuracy: 0.9380\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1851 - accuracy: 0.9385 - val_loss: 0.1834 - val_accuracy: 0.9383\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1813 - accuracy: 0.9389 - val_loss: 0.1804 - val_accuracy: 0.9398\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1784 - accuracy: 0.9394 - val_loss: 0.1779 - val_accuracy: 0.9398\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1755 - accuracy: 0.9399 - val_loss: 0.1760 - val_accuracy: 0.9402\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1729 - accuracy: 0.9402 - val_loss: 0.1747 - val_accuracy: 0.9411\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1708 - accuracy: 0.9406 - val_loss: 0.1743 - val_accuracy: 0.9395\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1692 - accuracy: 0.9411 - val_loss: 0.1723 - val_accuracy: 0.9411\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1672 - accuracy: 0.9415 - val_loss: 0.1727 - val_accuracy: 0.9411\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1656 - accuracy: 0.9421 - val_loss: 0.1715 - val_accuracy: 0.9417\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1641 - accuracy: 0.9422 - val_loss: 0.1713 - val_accuracy: 0.9405\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1631 - accuracy: 0.9421 - val_loss: 0.1698 - val_accuracy: 0.9424\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1618 - accuracy: 0.9425 - val_loss: 0.1693 - val_accuracy: 0.9430\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1599 - accuracy: 0.9432 - val_loss: 0.1687 - val_accuracy: 0.9442\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1588 - accuracy: 0.9432 - val_loss: 0.1685 - val_accuracy: 0.9427\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1576 - accuracy: 0.9430 - val_loss: 0.1688 - val_accuracy: 0.9430\n",
      "Epoch 23/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1568 - accuracy: 0.9434 - val_loss: 0.1683 - val_accuracy: 0.9427\n",
      "Epoch 24/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1559 - accuracy: 0.9444 - val_loss: 0.1711 - val_accuracy: 0.9436\n",
      "Epoch 25/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1545 - accuracy: 0.9451 - val_loss: 0.1676 - val_accuracy: 0.9433\n",
      "Epoch 26/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1535 - accuracy: 0.9445 - val_loss: 0.1677 - val_accuracy: 0.9430\n",
      "Epoch 27/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1523 - accuracy: 0.9453 - val_loss: 0.1682 - val_accuracy: 0.9433\n",
      "Epoch 28/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1516 - accuracy: 0.9452 - val_loss: 0.1692 - val_accuracy: 0.9433\n",
      "Epoch 29/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1505 - accuracy: 0.9454 - val_loss: 0.1667 - val_accuracy: 0.9427\n",
      "Epoch 30/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1496 - accuracy: 0.9458 - val_loss: 0.1688 - val_accuracy: 0.9424\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_global_36+18_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "200/200 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cea9167baf4b18bd52b6a4336b8cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a9e5548b434bfab4efa46e929b4083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95886f0a06854c08a7826fb5cb74b1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dd33a4e5434e2ab1d10a7e90fbe662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287dbe01bf674e04aad620ea8e238004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4157328009484491f94b566ffe7629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 10min 19s, sys: 4min 41s, total: 15min 1s\n",
      "Wall time: 12min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_global_36_careunits_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=36, gap_hours=18, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f519ff41-0303-4a3f-9ad1-2fd486509878",
   "metadata": {
    "id": "f519ff41-0303-4a3f-9ad1-2fd486509878",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Macro</th>\n",
       "      <th>96</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "CCU    1       0.853  0.199        0.828\n",
       "       2       0.852  0.184        0.843\n",
       "       3       0.901  0.253        0.865\n",
       "       4       0.823  0.124        0.738\n",
       "       5       0.883  0.241        0.857\n",
       "...              ...    ...          ...\n",
       "Macro  96      0.849  0.203        0.779\n",
       "       97      0.871  0.190        0.789\n",
       "       98      0.852  0.185        0.758\n",
       "       99      0.883  0.213        0.807\n",
       "       100     0.885  0.215        0.814\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 20\n",
    "metrics_global_36_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d00a05-ff33-4b9b-bc34-3b6070b65a9f",
   "metadata": {
    "id": "b2d00a05-ff33-4b9b-bc34-3b6070b65a9f"
   },
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789dbf10-6372-4855-980a-c4bd0a90c4cb",
   "metadata": {
    "id": "789dbf10-6372-4855-980a-c4bd0a90c4cb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort 0 is 12716\n",
      "        # of patients in cohort 1 is 1914\n",
      "        # of patients in cohort 2 is 7710\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"single_task_learning_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                15936     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "224/224 [==============================] - 10s 36ms/step - loss: 0.4016 - accuracy: 0.9365 - val_loss: 0.2870 - val_accuracy: 0.9380\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.2554 - accuracy: 0.9378 - val_loss: 0.2309 - val_accuracy: 0.9380\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2240 - accuracy: 0.9378 - val_loss: 0.2193 - val_accuracy: 0.9380\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.2143 - accuracy: 0.9378 - val_loss: 0.2105 - val_accuracy: 0.9380\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.2047 - accuracy: 0.9378 - val_loss: 0.2016 - val_accuracy: 0.9380\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1966 - accuracy: 0.9379 - val_loss: 0.1938 - val_accuracy: 0.9380\n",
      "Epoch 7/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1903 - accuracy: 0.9379 - val_loss: 0.1881 - val_accuracy: 0.9380\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1851 - accuracy: 0.9385 - val_loss: 0.1834 - val_accuracy: 0.9383\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1813 - accuracy: 0.9389 - val_loss: 0.1804 - val_accuracy: 0.9398\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1784 - accuracy: 0.9394 - val_loss: 0.1779 - val_accuracy: 0.9398\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1755 - accuracy: 0.9399 - val_loss: 0.1760 - val_accuracy: 0.9402\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1729 - accuracy: 0.9402 - val_loss: 0.1747 - val_accuracy: 0.9411\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.1708 - accuracy: 0.9406 - val_loss: 0.1743 - val_accuracy: 0.9395\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1692 - accuracy: 0.9411 - val_loss: 0.1723 - val_accuracy: 0.9411\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1672 - accuracy: 0.9415 - val_loss: 0.1727 - val_accuracy: 0.9411\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1656 - accuracy: 0.9421 - val_loss: 0.1715 - val_accuracy: 0.9417\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1641 - accuracy: 0.9422 - val_loss: 0.1713 - val_accuracy: 0.9405\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.1631 - accuracy: 0.9421 - val_loss: 0.1698 - val_accuracy: 0.9424\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.1618 - accuracy: 0.9425 - val_loss: 0.1693 - val_accuracy: 0.9430\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1599 - accuracy: 0.9432 - val_loss: 0.1687 - val_accuracy: 0.9442\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.1588 - accuracy: 0.9432 - val_loss: 0.1685 - val_accuracy: 0.9427\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1576 - accuracy: 0.9430 - val_loss: 0.1688 - val_accuracy: 0.9430\n",
      "Epoch 23/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1568 - accuracy: 0.9434 - val_loss: 0.1683 - val_accuracy: 0.9427\n",
      "Epoch 24/30\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.1559 - accuracy: 0.9444 - val_loss: 0.1711 - val_accuracy: 0.9436\n",
      "Epoch 25/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1545 - accuracy: 0.9451 - val_loss: 0.1676 - val_accuracy: 0.9433\n",
      "Epoch 26/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1535 - accuracy: 0.9445 - val_loss: 0.1677 - val_accuracy: 0.9430\n",
      "Epoch 27/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1523 - accuracy: 0.9453 - val_loss: 0.1682 - val_accuracy: 0.9433\n",
      "Epoch 28/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1516 - accuracy: 0.9452 - val_loss: 0.1692 - val_accuracy: 0.9433\n",
      "Epoch 29/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1505 - accuracy: 0.9454 - val_loss: 0.1667 - val_accuracy: 0.9427\n",
      "Epoch 30/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1496 - accuracy: 0.9458 - val_loss: 0.1688 - val_accuracy: 0.9424\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_global_36+18_unsupervised/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "200/200 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"0\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64096194237a41a2bb3620d92efa47b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"1\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fa927963da4f659e0e1d3514cf5141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"2\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b88df751534da0978ae14c8a1f6eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b18ea3f1914bd4967f75136f28577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 9min 44s, sys: 3min 58s, total: 13min 43s\n",
      "Wall time: 12min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_global_36_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=36, gap_hours=18, bootstrap=True,\n",
    "                                                                         cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_36.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdbd97a-6b01-472b-9461-0277692f0082",
   "metadata": {
    "id": "bcdbd97a-6b01-472b-9461-0277692f0082",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Micro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Macro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "0      1       0.880  0.204        0.804\n",
       "       2       0.880  0.217        0.814\n",
       "       3       0.867  0.195        0.777\n",
       "       4       0.872  0.195        0.795\n",
       "       5       0.879  0.199        0.788\n",
       "       6       0.880  0.201        0.793\n",
       "       7       0.885  0.236        0.831\n",
       "       8       0.884  0.218        0.815\n",
       "       9       0.888  0.194        0.800\n",
       "       10      0.887  0.202        0.820\n",
       "       11      0.876  0.190        0.792\n",
       "       12      0.879  0.215        0.815\n",
       "       13      0.875  0.195        0.803\n",
       "       14      0.878  0.187        0.786\n",
       "       15      0.885  0.201        0.810\n",
       "       16      0.906  0.243        0.843\n",
       "       17      0.873  0.192        0.786\n",
       "       18      0.881  0.199        0.801\n",
       "       19      0.893  0.205        0.821\n",
       "       20      0.881  0.213        0.824\n",
       "       21      0.875  0.197        0.780\n",
       "       22      0.884  0.195        0.808\n",
       "       23      0.886  0.209        0.810\n",
       "       24      0.877  0.225        0.816\n",
       "       25      0.869  0.186        0.762\n",
       "       26      0.873  0.216        0.816\n",
       "       27      0.868  0.198        0.803\n",
       "       28      0.875  0.216        0.811\n",
       "       29      0.881  0.206        0.802\n",
       "       30      0.893  0.195        0.800\n",
       "       31      0.888  0.198        0.817\n",
       "       32      0.888  0.200        0.804\n",
       "       33      0.891  0.198        0.797\n",
       "       34      0.868  0.189        0.794\n",
       "       35      0.889  0.204        0.821\n",
       "       36      0.894  0.221        0.820\n",
       "       37      0.884  0.204        0.810\n",
       "       38      0.891  0.198        0.808\n",
       "       39      0.882  0.178        0.790\n",
       "       40      0.874  0.189        0.795\n",
       "       41      0.887  0.209        0.819\n",
       "       42      0.874  0.194        0.786\n",
       "       43      0.884  0.208        0.800\n",
       "       44      0.871  0.181        0.769\n",
       "       45      0.862  0.167        0.769\n",
       "       46      0.872  0.176        0.777\n",
       "       47      0.877  0.194        0.797\n",
       "       48      0.875  0.190        0.773\n",
       "       49      0.883  0.224        0.827\n",
       "       50      0.868  0.185        0.788\n",
       "       51      0.871  0.178        0.781\n",
       "       52      0.882  0.208        0.809\n",
       "       53      0.883  0.223        0.818\n",
       "       54      0.879  0.191        0.787\n",
       "       55      0.891  0.202        0.817\n",
       "       56      0.846  0.162        0.742\n",
       "       57      0.881  0.223        0.826\n",
       "       58      0.880  0.212        0.803\n",
       "       59      0.856  0.176        0.781\n",
       "       60      0.891  0.203        0.820\n",
       "       61      0.880  0.218        0.817\n",
       "       62      0.868  0.181        0.798\n",
       "       63      0.862  0.176        0.753\n",
       "       64      0.891  0.222        0.826\n",
       "       65      0.882  0.214        0.809\n",
       "       66      0.876  0.176        0.786\n",
       "       67      0.884  0.190        0.802\n",
       "       68      0.873  0.204        0.815\n",
       "       69      0.891  0.226        0.818\n",
       "       70      0.884  0.218        0.821\n",
       "       71      0.876  0.214        0.802\n",
       "       72      0.865  0.190        0.783\n",
       "       73      0.875  0.188        0.783\n",
       "       74      0.868  0.196        0.798\n",
       "       75      0.878  0.213        0.807\n",
       "       76      0.873  0.186        0.790\n",
       "       77      0.873  0.189        0.789\n",
       "       78      0.882  0.195        0.796\n",
       "       79      0.883  0.199        0.792\n",
       "       80      0.901  0.218        0.829\n",
       "       81      0.876  0.210        0.811\n",
       "       82      0.897  0.215        0.818\n",
       "       83      0.859  0.189        0.791\n",
       "       84      0.883  0.198        0.799\n",
       "       85      0.876  0.206        0.809\n",
       "       86      0.863  0.192        0.788\n",
       "       87      0.880  0.205        0.815\n",
       "       88      0.869  0.207        0.810\n",
       "       89      0.875  0.199        0.808\n",
       "       90      0.874  0.204        0.794\n",
       "       91      0.874  0.193        0.800\n",
       "       92      0.869  0.176        0.770\n",
       "       93      0.880  0.201        0.801\n",
       "       94      0.885  0.207        0.816\n",
       "       95      0.872  0.170        0.782\n",
       "       96      0.863  0.183        0.774\n",
       "       97      0.881  0.208        0.817\n",
       "       98      0.873  0.184        0.786\n",
       "       99      0.880  0.214        0.813\n",
       "       100     0.889  0.221        0.833\n",
       "1      1       0.862  0.083        0.735\n",
       "       2       0.819  0.090        0.736\n",
       "       3       0.931  0.225        0.945\n",
       "       4       0.936  0.194        0.948\n",
       "       5       0.853  0.105        0.801\n",
       "       6       0.866  0.098        0.730\n",
       "       7       0.785  0.063        0.632\n",
       "       8       0.886  0.053        0.736\n",
       "       9       0.886  0.112        0.753\n",
       "       10      0.892  0.296        0.933\n",
       "       11      0.750  0.066        0.597\n",
       "       12      0.882  0.375        0.971\n",
       "       13      0.858  0.054        0.715\n",
       "       14      0.826  0.065        0.695\n",
       "       15      0.917  0.060        0.788\n",
       "       16      0.795  0.070        0.766\n",
       "       17      0.794  0.126        0.765\n",
       "       18      0.916  0.467        0.956\n",
       "       19      0.867  0.105        0.739\n",
       "       20      0.826  0.088        0.680\n",
       "       21      0.822  0.115        0.784\n",
       "       22      0.858  0.078        0.746\n",
       "       23      0.956  0.391        0.973\n",
       "       24      0.863  0.171        0.945\n",
       "       25      0.915  0.519        0.976\n",
       "       26      0.965  0.692        0.986\n",
       "       27      0.885  0.120        0.769\n",
       "       28      0.923  0.400        0.965\n",
       "       29      0.767  0.081        0.740\n",
       "       30      0.896  0.079        0.749\n",
       "       31      0.879  0.099        0.722\n",
       "       32      0.868  0.286        0.973\n",
       "       33      0.937  0.275        0.946\n",
       "       34      0.941  0.448        0.969\n",
       "       35      0.848  0.192        0.919\n",
       "       36      0.858  0.094        0.739\n",
       "       37      0.858  0.076        0.795\n",
       "       38      0.889  0.065        0.747\n",
       "       39      0.865  0.141        0.741\n",
       "       40      0.902  0.083        0.769\n",
       "       41      0.883  0.107        0.769\n",
       "       42      0.792  0.041        0.776\n",
       "       43      0.819  0.035        0.728\n",
       "       44      0.935  0.343        0.957\n",
       "       45      0.924  0.500        0.976\n",
       "       46      0.865  0.059        0.711\n",
       "       47      0.882  0.091        0.775\n",
       "       48      0.812  0.018        0.576\n",
       "       49      0.833  0.090        0.737\n",
       "       50      0.946  0.500        0.971\n",
       "       51      0.936  0.321        0.963\n",
       "       52      0.924  0.545        0.981\n",
       "       53      0.833  0.085        0.701\n",
       "       54      0.919  0.196        0.935\n",
       "       55      0.907  0.070        0.921\n",
       "       56      0.895  0.302        0.940\n",
       "       57      0.865  0.636        0.985\n",
       "       58      0.906  0.278        0.927\n",
       "       59      0.907  0.327        0.931\n",
       "       60      0.703  0.027        0.589\n",
       "       61      0.847  0.077        0.719\n",
       "       62      0.907  0.400        0.973\n",
       "       63      0.883  0.125        0.769\n",
       "       64      0.966  0.458        0.974\n",
       "       65      0.804  0.073        0.701\n",
       "       66      0.917  0.065        0.741\n",
       "       67      0.838  0.095        0.686\n",
       "       68      0.911  0.236        0.916\n",
       "       69      0.937  0.500        0.990\n",
       "       70      0.830  0.100        0.712\n",
       "       71      0.922  0.111        0.756\n",
       "       72      0.842  0.071        0.789\n",
       "       73      0.771  0.068        0.697\n",
       "       74      0.821  0.069        0.743\n",
       "       75      0.907  0.142        0.769\n",
       "       76      0.946  0.429        0.978\n",
       "       77      0.780  0.053        0.723\n",
       "       78      0.876  0.115        0.727\n",
       "       79      0.872  0.089        0.705\n",
       "       80      0.876  0.333        0.974\n",
       "       81      0.953  0.684        0.989\n",
       "       82      0.874  0.106        0.750\n",
       "       83      0.835  0.092        0.703\n",
       "       84      0.931  0.360        0.969\n",
       "       85      0.835  0.094        0.757\n",
       "       86      0.852  0.092        0.736\n",
       "       87      0.870  0.115        0.773\n",
       "       88      0.753  0.062        0.749\n",
       "       89      0.829  0.070        0.740\n",
       "       90      0.934  0.208        0.924\n",
       "       91      0.916  0.192        0.960\n",
       "       92      0.866  0.094        0.761\n",
       "       93      0.810  0.085        0.788\n",
       "       94      0.851  0.076        0.748\n",
       "       95      0.858  0.096        0.714\n",
       "       96      0.725  0.035        0.589\n",
       "       97      0.768  0.076        0.738\n",
       "       98      0.953  0.167        0.926\n",
       "       99      0.836  0.076        0.751\n",
       "       100     0.858  0.086        0.778\n",
       "2      1       0.877  0.201        0.754\n",
       "       2       0.844  0.206        0.750\n",
       "       3       0.859  0.194        0.744\n",
       "       4       0.833  0.151        0.656\n",
       "       5       0.858  0.223        0.770\n",
       "       6       0.835  0.182        0.714\n",
       "       7       0.823  0.184        0.700\n",
       "       8       0.820  0.147        0.633\n",
       "       9       0.821  0.165        0.702\n",
       "       10      0.831  0.165        0.647\n",
       "       11      0.839  0.199        0.729\n",
       "       12      0.826  0.181        0.685\n",
       "       13      0.832  0.179        0.700\n",
       "       14      0.855  0.191        0.743\n",
       "       15      0.847  0.165        0.720\n",
       "       16      0.838  0.194        0.732\n",
       "       17      0.839  0.177        0.696\n",
       "       18      0.837  0.187        0.695\n",
       "       19      0.825  0.150        0.697\n",
       "       20      0.819  0.155        0.637\n",
       "       21      0.848  0.195        0.741\n",
       "       22      0.843  0.189        0.729\n",
       "       23      0.837  0.195        0.734\n",
       "       24      0.828  0.167        0.698\n",
       "       25      0.843  0.189        0.714\n",
       "       26      0.842  0.191        0.724\n",
       "       27      0.834  0.174        0.713\n",
       "       28      0.819  0.191        0.698\n",
       "       29      0.829  0.152        0.682\n",
       "       30      0.829  0.156        0.643\n",
       "       31      0.853  0.212        0.737\n",
       "       32      0.828  0.175        0.720\n",
       "       33      0.825  0.190        0.695\n",
       "       34      0.849  0.192        0.745\n",
       "       35      0.863  0.201        0.758\n",
       "       36      0.867  0.231        0.782\n",
       "       37      0.843  0.195        0.735\n",
       "       38      0.864  0.245        0.767\n",
       "       39      0.832  0.169        0.699\n",
       "       40      0.838  0.202        0.748\n",
       "       41      0.850  0.194        0.743\n",
       "       42      0.830  0.164        0.677\n",
       "       43      0.837  0.194        0.728\n",
       "       44      0.839  0.153        0.629\n",
       "       45      0.827  0.180        0.691\n",
       "       46      0.838  0.185        0.730\n",
       "       47      0.853  0.195        0.732\n",
       "       48      0.858  0.217        0.770\n",
       "       49      0.814  0.143        0.626\n",
       "       50      0.843  0.158        0.677\n",
       "       51      0.821  0.175        0.706\n",
       "       52      0.843  0.194        0.736\n",
       "       53      0.821  0.158        0.685\n",
       "       54      0.849  0.185        0.726\n",
       "       55      0.848  0.184        0.743\n",
       "       56      0.824  0.178        0.684\n",
       "       57      0.833  0.197        0.734\n",
       "       58      0.825  0.155        0.641\n",
       "       59      0.836  0.182        0.723\n",
       "       60      0.856  0.184        0.724\n",
       "       61      0.831  0.167        0.707\n",
       "       62      0.858  0.185        0.742\n",
       "       63      0.861  0.253        0.807\n",
       "       64      0.820  0.175        0.674\n",
       "       65      0.835  0.140        0.630\n",
       "       66      0.873  0.220        0.777\n",
       "       67      0.842  0.183        0.727\n",
       "       68      0.837  0.175        0.732\n",
       "       69      0.834  0.181        0.717\n",
       "       70      0.844  0.184        0.724\n",
       "       71      0.828  0.158        0.636\n",
       "       72      0.866  0.225        0.763\n",
       "       73      0.857  0.206        0.752\n",
       "       74      0.823  0.167        0.680\n",
       "       75      0.836  0.196        0.711\n",
       "       76      0.836  0.183        0.725\n",
       "       77      0.821  0.164        0.689\n",
       "       78      0.836  0.184        0.717\n",
       "       79      0.853  0.180        0.743\n",
       "       80      0.832  0.166        0.699\n",
       "       81      0.852  0.192        0.723\n",
       "       82      0.845  0.180        0.704\n",
       "       83      0.858  0.207        0.740\n",
       "       84      0.849  0.231        0.773\n",
       "       85      0.864  0.185        0.728\n",
       "       86      0.838  0.163        0.694\n",
       "       87      0.834  0.178        0.692\n",
       "       88      0.839  0.209        0.722\n",
       "       89      0.859  0.205        0.760\n",
       "       90      0.847  0.177        0.709\n",
       "       91      0.856  0.192        0.745\n",
       "       92      0.838  0.178        0.701\n",
       "       93      0.844  0.177        0.715\n",
       "       94      0.824  0.150        0.649\n",
       "       95      0.838  0.136        0.652\n",
       "       96      0.824  0.174        0.686\n",
       "       97      0.859  0.220        0.768\n",
       "       98      0.840  0.158        0.675\n",
       "       99      0.839  0.172        0.704\n",
       "       100     0.837  0.191        0.710\n",
       "Micro  1       0.865  0.181        0.761\n",
       "       2       0.856  0.187        0.770\n",
       "       3       0.870  0.193        0.780\n",
       "       4       0.853  0.185        0.767\n",
       "       5       0.886  0.210        0.801\n",
       "       6       0.863  0.200        0.789\n",
       "       7       0.860  0.184        0.766\n",
       "       8       0.873  0.209        0.800\n",
       "       9       0.875  0.205        0.795\n",
       "       10      0.870  0.196        0.784\n",
       "       11      0.878  0.205        0.795\n",
       "       12      0.873  0.202        0.792\n",
       "       13      0.860  0.177        0.754\n",
       "       14      0.874  0.205        0.796\n",
       "       15      0.873  0.198        0.786\n",
       "       16      0.862  0.205        0.796\n",
       "       17      0.874  0.211        0.803\n",
       "       18      0.853  0.182        0.764\n",
       "       19      0.854  0.174        0.750\n",
       "       20      0.862  0.180        0.759\n",
       "       21      0.872  0.203        0.793\n",
       "       22      0.872  0.191        0.776\n",
       "       23      0.865  0.193        0.780\n",
       "       24      0.849  0.169        0.742\n",
       "       25      0.864  0.177        0.757\n",
       "       26      0.870  0.197        0.785\n",
       "       27      0.880  0.201        0.790\n",
       "       28      0.866  0.185        0.767\n",
       "       29      0.872  0.197        0.784\n",
       "       30      0.871  0.210        0.801\n",
       "       31      0.863  0.190        0.775\n",
       "       32      0.870  0.214        0.806\n",
       "       33      0.870  0.188        0.771\n",
       "       34      0.868  0.192        0.779\n",
       "       35      0.878  0.214        0.806\n",
       "       36      0.864  0.188        0.773\n",
       "       37      0.886  0.216        0.809\n",
       "       38      0.869  0.186        0.770\n",
       "       39      0.857  0.173        0.750\n",
       "       40      0.861  0.183        0.764\n",
       "       41      0.871  0.195        0.782\n",
       "       42      0.853  0.161        0.725\n",
       "       43      0.871  0.186        0.768\n",
       "       44      0.867  0.194        0.780\n",
       "       45      0.865  0.180        0.758\n",
       "       46      0.859  0.185        0.768\n",
       "       47      0.873  0.206        0.796\n",
       "       48      0.876  0.202        0.792\n",
       "       49      0.861  0.178        0.756\n",
       "       50      0.872  0.188        0.771\n",
       "       51      0.871  0.204        0.793\n",
       "       52      0.865  0.192        0.777\n",
       "       53      0.869  0.194        0.780\n",
       "       54      0.878  0.212        0.805\n",
       "       55      0.852  0.173        0.749\n",
       "       56      0.864  0.181        0.761\n",
       "       57      0.870  0.190        0.775\n",
       "       58      0.870  0.192        0.778\n",
       "       59      0.873  0.185        0.767\n",
       "       60      0.853  0.178        0.757\n",
       "       61      0.874  0.192        0.779\n",
       "       62      0.882  0.205        0.796\n",
       "       63      0.859  0.182        0.763\n",
       "       64      0.874  0.204        0.794\n",
       "       65      0.878  0.205        0.795\n",
       "       66      0.871  0.197        0.785\n",
       "       67      0.873  0.210        0.801\n",
       "       68      0.870  0.192        0.777\n",
       "       69      0.876  0.210        0.802\n",
       "       70      0.857  0.180        0.759\n",
       "       71      0.883  0.210        0.801\n",
       "       72      0.878  0.192        0.777\n",
       "       73      0.863  0.196        0.783\n",
       "       74      0.862  0.185        0.768\n",
       "       75      0.868  0.196        0.783\n",
       "       76      0.870  0.194        0.781\n",
       "       77      0.860  0.176        0.753\n",
       "       78      0.880  0.207        0.798\n",
       "       79      0.864  0.185        0.768\n",
       "       80      0.864  0.183        0.764\n",
       "       81      0.861  0.180        0.759\n",
       "       82      0.874  0.192        0.778\n",
       "       83      0.867  0.192        0.779\n",
       "       84      0.873  0.211        0.802\n",
       "       85      0.862  0.198        0.786\n",
       "       86      0.870  0.192        0.778\n",
       "       87      0.869  0.193        0.779\n",
       "       88      0.874  0.194        0.781\n",
       "       89      0.865  0.191        0.777\n",
       "       90      0.850  0.172        0.746\n",
       "       91      0.868  0.202        0.792\n",
       "       92      0.841  0.180        0.759\n",
       "       93      0.865  0.192        0.778\n",
       "       94      0.868  0.191        0.777\n",
       "       95      0.848  0.177        0.755\n",
       "       96      0.881  0.214        0.806\n",
       "       97      0.862  0.193        0.779\n",
       "       98      0.859  0.180        0.758\n",
       "       99      0.883  0.219        0.812\n",
       "       100     0.869  0.187        0.771\n",
       "Macro  1       0.873  0.163        0.765\n",
       "       2       0.870  0.221        0.800\n",
       "       3       0.861  0.166        0.774\n",
       "       4       0.822  0.152        0.706\n",
       "       5       0.862  0.257        0.824\n",
       "       6       0.855  0.143        0.739\n",
       "       7       0.853  0.148        0.741\n",
       "       8       0.883  0.142        0.773\n",
       "       9       0.846  0.169        0.780\n",
       "       10      0.835  0.165        0.749\n",
       "       11      0.878  0.284        0.817\n",
       "       12      0.862  0.154        0.752\n",
       "       13      0.847  0.171        0.767\n",
       "       14      0.842  0.152        0.714\n",
       "       15      0.849  0.169        0.768\n",
       "       16      0.862  0.154        0.761\n",
       "       17      0.893  0.265        0.839\n",
       "       18      0.856  0.188        0.820\n",
       "       19      0.876  0.298        0.817\n",
       "       20      0.893  0.366        0.842\n",
       "       21      0.862  0.164        0.762\n",
       "       22      0.872  0.269        0.825\n",
       "       23      0.826  0.146        0.741\n",
       "       24      0.886  0.205        0.822\n",
       "       25      0.873  0.143        0.731\n",
       "       26      0.873  0.170        0.759\n",
       "       27      0.861  0.220        0.832\n",
       "       28      0.884  0.221        0.813\n",
       "       29      0.886  0.277        0.836\n",
       "       30      0.867  0.199        0.833\n",
       "       31      0.873  0.182        0.780\n",
       "       32      0.862  0.158        0.780\n",
       "       33      0.881  0.169        0.774\n",
       "       34      0.860  0.163        0.743\n",
       "       35      0.880  0.180        0.800\n",
       "       36      0.871  0.158        0.770\n",
       "       37      0.873  0.170        0.777\n",
       "       38      0.832  0.133        0.746\n",
       "       39      0.846  0.146        0.752\n",
       "       40      0.882  0.226        0.785\n",
       "       41      0.871  0.282        0.812\n",
       "       42      0.858  0.140        0.739\n",
       "       43      0.871  0.160        0.768\n",
       "       44      0.848  0.141        0.706\n",
       "       45      0.843  0.152        0.730\n",
       "       46      0.863  0.176        0.786\n",
       "       47      0.886  0.281        0.812\n",
       "       48      0.876  0.225        0.817\n",
       "       49      0.883  0.316        0.842\n",
       "       50      0.846  0.155        0.735\n",
       "       51      0.883  0.191        0.816\n",
       "       52      0.882  0.152        0.827\n",
       "       53      0.855  0.214        0.789\n",
       "       54      0.860  0.352        0.848\n",
       "       55      0.871  0.215        0.790\n",
       "       56      0.866  0.228        0.812\n",
       "       57      0.860  0.160        0.746\n",
       "       58      0.816  0.138        0.711\n",
       "       59      0.853  0.154        0.747\n",
       "       60      0.878  0.255        0.838\n",
       "       61      0.869  0.185        0.776\n",
       "       62      0.892  0.285        0.825\n",
       "       63      0.840  0.142        0.713\n",
       "       64      0.888  0.153        0.768\n",
       "       65      0.855  0.156        0.738\n",
       "       66      0.874  0.205        0.821\n",
       "       67      0.887  0.302        0.842\n",
       "       68      0.831  0.161        0.721\n",
       "       69      0.853  0.167        0.753\n",
       "       70      0.875  0.161        0.732\n",
       "       71      0.857  0.162        0.778\n",
       "       72      0.834  0.154        0.744\n",
       "       73      0.837  0.144        0.740\n",
       "       74      0.874  0.184        0.762\n",
       "       75      0.885  0.266        0.831\n",
       "       76      0.824  0.135        0.733\n",
       "       77      0.864  0.165        0.747\n",
       "       78      0.869  0.156        0.747\n",
       "       79      0.863  0.139        0.728\n",
       "       80      0.870  0.239        0.834\n",
       "       81      0.893  0.362        0.841\n",
       "       82      0.872  0.167        0.757\n",
       "       83      0.850  0.163        0.744\n",
       "       84      0.887  0.263        0.847\n",
       "       85      0.858  0.162        0.765\n",
       "       86      0.851  0.149        0.739\n",
       "       87      0.861  0.166        0.760\n",
       "       88      0.821  0.159        0.760\n",
       "       89      0.854  0.158        0.769\n",
       "       90      0.865  0.157        0.751\n",
       "       91      0.885  0.196        0.809\n",
       "       92      0.882  0.192        0.835\n",
       "       93      0.858  0.149        0.744\n",
       "       94      0.844  0.154        0.768\n",
       "       95      0.853  0.144        0.738\n",
       "       96      0.856  0.134        0.716\n",
       "       97      0.804  0.131        0.683\n",
       "       98      0.836  0.168        0.774\n",
       "       99      0.889  0.170        0.796\n",
       "       100     0.852  0.154        0.756"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_global_36_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079b1d-28fd-4a67-9613-f188139cf2f5",
   "metadata": {
    "id": "31079b1d-28fd-4a67-9613-f188139cf2f5"
   },
   "source": [
    "#### 3.1.2. In-Hospital Mortality Prediction – Multi-Task Learning Model at 36 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a6085-32a9-411a-82be-a1a48894c36d",
   "metadata": {
    "id": "1f3a6085-32a9-411a-82be-a1a48894c36d"
   },
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 36 hour experiment setting. In this experiment, the cutoff period is 36 hours and the gap period is 18 hours, meaning model can only feed from patient data collected during the first 36 hours of the ICU stay, and predict mortality 54 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3358dc-8459-4225-abfe-841a8db5b496",
   "metadata": {
    "id": "6b3358dc-8459-4225-abfe-841a8db5b496",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3278\n",
      "        # of patients in cohort CSRU is 4901\n",
      "        # of patients in cohort MICU is 7744\n",
      "        # of patients in cohort SICU is 3542\n",
      "        # of patients in cohort TSICU is 2875\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'multitask' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"multitask_learning_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 36, 232)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 16)           15936       ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " CCU (Dense)                    (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " CSRU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " MICU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " SICU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " TSICU (Dense)                  (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,021\n",
      "Trainable params: 16,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "224/224 [==============================] - 12s 41ms/step - loss: 0.4471 - CCU_loss: 0.0685 - CSRU_loss: 0.0647 - MICU_loss: 0.1728 - SICU_loss: 0.0760 - TSICU_loss: 0.0652 - CCU_accuracy: 0.9352 - CSRU_accuracy: 0.8887 - MICU_accuracy: 0.9053 - SICU_accuracy: 0.9166 - TSICU_accuracy: 0.8789 - val_loss: 1.7331 - val_CCU_loss: 0.3472 - val_CSRU_loss: 0.3399 - val_MICU_loss: 0.3502 - val_SICU_loss: 0.3432 - val_TSICU_loss: 0.3526 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9364 - val_MICU_accuracy: 0.9380 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9380\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.3100 - CCU_loss: 0.0504 - CSRU_loss: 0.0287 - MICU_loss: 0.1352 - SICU_loss: 0.0532 - TSICU_loss: 0.0425 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9376 - MICU_accuracy: 0.9378 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9377 - val_loss: 1.4428 - val_CCU_loss: 0.2921 - val_CSRU_loss: 0.2807 - val_MICU_loss: 0.2879 - val_SICU_loss: 0.2884 - val_TSICU_loss: 0.2938 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9380\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.2609 - CCU_loss: 0.0418 - CSRU_loss: 0.0224 - MICU_loss: 0.1190 - SICU_loss: 0.0440 - TSICU_loss: 0.0336 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9378 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9378 - val_loss: 1.2467 - val_CCU_loss: 0.2455 - val_CSRU_loss: 0.2487 - val_MICU_loss: 0.2568 - val_SICU_loss: 0.2456 - val_TSICU_loss: 0.2502 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9386 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9380\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.2304 - CCU_loss: 0.0359 - CSRU_loss: 0.0195 - MICU_loss: 0.1067 - SICU_loss: 0.0393 - TSICU_loss: 0.0290 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9380 - SICU_accuracy: 0.9378 - TSICU_accuracy: 0.9378 - val_loss: 1.1243 - val_CCU_loss: 0.2218 - val_CSRU_loss: 0.2244 - val_MICU_loss: 0.2297 - val_SICU_loss: 0.2224 - val_TSICU_loss: 0.2260 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9386 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9380\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.2098 - CCU_loss: 0.0322 - CSRU_loss: 0.0173 - MICU_loss: 0.0982 - SICU_loss: 0.0361 - TSICU_loss: 0.0260 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9382 - SICU_accuracy: 0.9378 - TSICU_accuracy: 0.9378 - val_loss: 1.0325 - val_CCU_loss: 0.2033 - val_CSRU_loss: 0.2111 - val_MICU_loss: 0.2118 - val_SICU_loss: 0.2025 - val_TSICU_loss: 0.2039 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9389 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9380\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1962 - CCU_loss: 0.0299 - CSRU_loss: 0.0157 - MICU_loss: 0.0921 - SICU_loss: 0.0341 - TSICU_loss: 0.0244 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9386 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9378 - val_loss: 0.9790 - val_CCU_loss: 0.1949 - val_CSRU_loss: 0.1983 - val_MICU_loss: 0.1975 - val_SICU_loss: 0.1940 - val_TSICU_loss: 0.1943 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9386 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 7/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1873 - CCU_loss: 0.0284 - CSRU_loss: 0.0149 - MICU_loss: 0.0878 - SICU_loss: 0.0332 - TSICU_loss: 0.0231 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9388 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9378 - val_loss: 0.9550 - val_CCU_loss: 0.1911 - val_CSRU_loss: 0.1956 - val_MICU_loss: 0.1908 - val_SICU_loss: 0.1895 - val_TSICU_loss: 0.1881 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1819 - CCU_loss: 0.0275 - CSRU_loss: 0.0142 - MICU_loss: 0.0852 - SICU_loss: 0.0324 - TSICU_loss: 0.0226 - CCU_accuracy: 0.9378 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9388 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9378 - val_loss: 0.9365 - val_CCU_loss: 0.1882 - val_CSRU_loss: 0.1873 - val_MICU_loss: 0.1866 - val_SICU_loss: 0.1871 - val_TSICU_loss: 0.1873 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 9s 38ms/step - loss: 0.1787 - CCU_loss: 0.0270 - CSRU_loss: 0.0140 - MICU_loss: 0.0836 - SICU_loss: 0.0320 - TSICU_loss: 0.0222 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9389 - SICU_accuracy: 0.9379 - TSICU_accuracy: 0.9378 - val_loss: 0.9244 - val_CCU_loss: 0.1863 - val_CSRU_loss: 0.1865 - val_MICU_loss: 0.1836 - val_SICU_loss: 0.1841 - val_TSICU_loss: 0.1839 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9377 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1768 - CCU_loss: 0.0267 - CSRU_loss: 0.0139 - MICU_loss: 0.0824 - SICU_loss: 0.0318 - TSICU_loss: 0.0220 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9392 - SICU_accuracy: 0.9380 - TSICU_accuracy: 0.9378 - val_loss: 0.9165 - val_CCU_loss: 0.1851 - val_CSRU_loss: 0.1843 - val_MICU_loss: 0.1813 - val_SICU_loss: 0.1829 - val_TSICU_loss: 0.1830 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9380 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1747 - CCU_loss: 0.0265 - CSRU_loss: 0.0137 - MICU_loss: 0.0812 - SICU_loss: 0.0315 - TSICU_loss: 0.0219 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9392 - SICU_accuracy: 0.9380 - TSICU_accuracy: 0.9378 - val_loss: 0.9126 - val_CCU_loss: 0.1841 - val_CSRU_loss: 0.1825 - val_MICU_loss: 0.1808 - val_SICU_loss: 0.1825 - val_TSICU_loss: 0.1827 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9377 - val_SICU_accuracy: 0.9370 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 9s 39ms/step - loss: 0.1727 - CCU_loss: 0.0261 - CSRU_loss: 0.0133 - MICU_loss: 0.0805 - SICU_loss: 0.0313 - TSICU_loss: 0.0215 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9392 - SICU_accuracy: 0.9381 - TSICU_accuracy: 0.9379 - val_loss: 0.9072 - val_CCU_loss: 0.1832 - val_CSRU_loss: 0.1823 - val_MICU_loss: 0.1794 - val_SICU_loss: 0.1811 - val_TSICU_loss: 0.1812 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9386 - val_SICU_accuracy: 0.9370 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 8s 38ms/step - loss: 0.1713 - CCU_loss: 0.0259 - CSRU_loss: 0.0134 - MICU_loss: 0.0795 - SICU_loss: 0.0310 - TSICU_loss: 0.0215 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9394 - SICU_accuracy: 0.9382 - TSICU_accuracy: 0.9380 - val_loss: 0.9079 - val_CCU_loss: 0.1839 - val_CSRU_loss: 0.1874 - val_MICU_loss: 0.1782 - val_SICU_loss: 0.1792 - val_TSICU_loss: 0.1792 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9370 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1700 - CCU_loss: 0.0258 - CSRU_loss: 0.0133 - MICU_loss: 0.0788 - SICU_loss: 0.0308 - TSICU_loss: 0.0214 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9380 - MICU_accuracy: 0.9396 - SICU_accuracy: 0.9384 - TSICU_accuracy: 0.9380 - val_loss: 0.8990 - val_CCU_loss: 0.1817 - val_CSRU_loss: 0.1809 - val_MICU_loss: 0.1772 - val_SICU_loss: 0.1794 - val_TSICU_loss: 0.1798 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9386 - val_SICU_accuracy: 0.9370 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1689 - CCU_loss: 0.0256 - CSRU_loss: 0.0133 - MICU_loss: 0.0782 - SICU_loss: 0.0307 - TSICU_loss: 0.0212 - CCU_accuracy: 0.9379 - CSRU_accuracy: 0.9380 - MICU_accuracy: 0.9397 - SICU_accuracy: 0.9387 - TSICU_accuracy: 0.9380 - val_loss: 0.8988 - val_CCU_loss: 0.1822 - val_CSRU_loss: 0.1837 - val_MICU_loss: 0.1764 - val_SICU_loss: 0.1782 - val_TSICU_loss: 0.1784 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9370 - val_TSICU_accuracy: 0.9383\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1676 - CCU_loss: 0.0255 - CSRU_loss: 0.0131 - MICU_loss: 0.0777 - SICU_loss: 0.0304 - TSICU_loss: 0.0209 - CCU_accuracy: 0.9380 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9397 - SICU_accuracy: 0.9388 - TSICU_accuracy: 0.9380 - val_loss: 0.8939 - val_CCU_loss: 0.1809 - val_CSRU_loss: 0.1815 - val_MICU_loss: 0.1758 - val_SICU_loss: 0.1776 - val_TSICU_loss: 0.1781 - val_CCU_accuracy: 0.9377 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9383 - val_SICU_accuracy: 0.9373 - val_TSICU_accuracy: 0.9386\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1665 - CCU_loss: 0.0253 - CSRU_loss: 0.0131 - MICU_loss: 0.0771 - SICU_loss: 0.0301 - TSICU_loss: 0.0209 - CCU_accuracy: 0.9380 - CSRU_accuracy: 0.9380 - MICU_accuracy: 0.9400 - SICU_accuracy: 0.9390 - TSICU_accuracy: 0.9381 - val_loss: 0.8973 - val_CCU_loss: 0.1826 - val_CSRU_loss: 0.1859 - val_MICU_loss: 0.1753 - val_SICU_loss: 0.1769 - val_TSICU_loss: 0.1767 - val_CCU_accuracy: 0.9377 - val_CSRU_accuracy: 0.9383 - val_MICU_accuracy: 0.9380 - val_SICU_accuracy: 0.9373 - val_TSICU_accuracy: 0.9386\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1660 - CCU_loss: 0.0252 - CSRU_loss: 0.0132 - MICU_loss: 0.0768 - SICU_loss: 0.0300 - TSICU_loss: 0.0207 - CCU_accuracy: 0.9380 - CSRU_accuracy: 0.9380 - MICU_accuracy: 0.9401 - SICU_accuracy: 0.9391 - TSICU_accuracy: 0.9382 - val_loss: 0.8880 - val_CCU_loss: 0.1799 - val_CSRU_loss: 0.1801 - val_MICU_loss: 0.1744 - val_SICU_loss: 0.1763 - val_TSICU_loss: 0.1773 - val_CCU_accuracy: 0.9377 - val_CSRU_accuracy: 0.9383 - val_MICU_accuracy: 0.9392 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9389\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1645 - CCU_loss: 0.0249 - CSRU_loss: 0.0130 - MICU_loss: 0.0759 - SICU_loss: 0.0300 - TSICU_loss: 0.0207 - CCU_accuracy: 0.9382 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9404 - SICU_accuracy: 0.9392 - TSICU_accuracy: 0.9381 - val_loss: 0.8860 - val_CCU_loss: 0.1798 - val_CSRU_loss: 0.1799 - val_MICU_loss: 0.1739 - val_SICU_loss: 0.1757 - val_TSICU_loss: 0.1767 - val_CCU_accuracy: 0.9373 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9395 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9389\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1633 - CCU_loss: 0.0248 - CSRU_loss: 0.0127 - MICU_loss: 0.0754 - SICU_loss: 0.0299 - TSICU_loss: 0.0204 - CCU_accuracy: 0.9384 - CSRU_accuracy: 0.9379 - MICU_accuracy: 0.9406 - SICU_accuracy: 0.9393 - TSICU_accuracy: 0.9381 - val_loss: 0.8856 - val_CCU_loss: 0.1783 - val_CSRU_loss: 0.1762 - val_MICU_loss: 0.1756 - val_SICU_loss: 0.1768 - val_TSICU_loss: 0.1786 - val_CCU_accuracy: 0.9377 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9402 - val_SICU_accuracy: 0.9380 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 8s 37ms/step - loss: 0.1621 - CCU_loss: 0.0248 - CSRU_loss: 0.0126 - MICU_loss: 0.0750 - SICU_loss: 0.0294 - TSICU_loss: 0.0203 - CCU_accuracy: 0.9384 - CSRU_accuracy: 0.9380 - MICU_accuracy: 0.9411 - SICU_accuracy: 0.9395 - TSICU_accuracy: 0.9381 - val_loss: 0.8870 - val_CCU_loss: 0.1801 - val_CSRU_loss: 0.1805 - val_MICU_loss: 0.1742 - val_SICU_loss: 0.1757 - val_TSICU_loss: 0.1765 - val_CCU_accuracy: 0.9370 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9402 - val_SICU_accuracy: 0.9377 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1612 - CCU_loss: 0.0245 - CSRU_loss: 0.0127 - MICU_loss: 0.0745 - SICU_loss: 0.0292 - TSICU_loss: 0.0203 - CCU_accuracy: 0.9387 - CSRU_accuracy: 0.9382 - MICU_accuracy: 0.9411 - SICU_accuracy: 0.9395 - TSICU_accuracy: 0.9380 - val_loss: 0.8928 - val_CCU_loss: 0.1815 - val_CSRU_loss: 0.1844 - val_MICU_loss: 0.1754 - val_SICU_loss: 0.1752 - val_TSICU_loss: 0.1763 - val_CCU_accuracy: 0.9370 - val_CSRU_accuracy: 0.9380 - val_MICU_accuracy: 0.9402 - val_SICU_accuracy: 0.9383 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 23/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1607 - CCU_loss: 0.0244 - CSRU_loss: 0.0127 - MICU_loss: 0.0745 - SICU_loss: 0.0291 - TSICU_loss: 0.0201 - CCU_accuracy: 0.9389 - CSRU_accuracy: 0.9384 - MICU_accuracy: 0.9413 - SICU_accuracy: 0.9398 - TSICU_accuracy: 0.9380 - val_loss: 0.8792 - val_CCU_loss: 0.1778 - val_CSRU_loss: 0.1762 - val_MICU_loss: 0.1735 - val_SICU_loss: 0.1748 - val_TSICU_loss: 0.1769 - val_CCU_accuracy: 0.9383 - val_CSRU_accuracy: 0.9383 - val_MICU_accuracy: 0.9402 - val_SICU_accuracy: 0.9389 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 24/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1599 - CCU_loss: 0.0241 - CSRU_loss: 0.0127 - MICU_loss: 0.0740 - SICU_loss: 0.0291 - TSICU_loss: 0.0200 - CCU_accuracy: 0.9389 - CSRU_accuracy: 0.9385 - MICU_accuracy: 0.9417 - SICU_accuracy: 0.9400 - TSICU_accuracy: 0.9380 - val_loss: 0.8992 - val_CCU_loss: 0.1833 - val_CSRU_loss: 0.1874 - val_MICU_loss: 0.1769 - val_SICU_loss: 0.1752 - val_TSICU_loss: 0.1765 - val_CCU_accuracy: 0.9377 - val_CSRU_accuracy: 0.9383 - val_MICU_accuracy: 0.9402 - val_SICU_accuracy: 0.9389 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 25/30\n",
      "224/224 [==============================] - 8s 37ms/step - loss: 0.1585 - CCU_loss: 0.0241 - CSRU_loss: 0.0124 - MICU_loss: 0.0733 - SICU_loss: 0.0287 - TSICU_loss: 0.0200 - CCU_accuracy: 0.9393 - CSRU_accuracy: 0.9385 - MICU_accuracy: 0.9422 - SICU_accuracy: 0.9402 - TSICU_accuracy: 0.9382 - val_loss: 0.8782 - val_CCU_loss: 0.1782 - val_CSRU_loss: 0.1764 - val_MICU_loss: 0.1730 - val_SICU_loss: 0.1740 - val_TSICU_loss: 0.1765 - val_CCU_accuracy: 0.9383 - val_CSRU_accuracy: 0.9386 - val_MICU_accuracy: 0.9408 - val_SICU_accuracy: 0.9395 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 26/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1573 - CCU_loss: 0.0240 - CSRU_loss: 0.0123 - MICU_loss: 0.0728 - SICU_loss: 0.0284 - TSICU_loss: 0.0197 - CCU_accuracy: 0.9396 - CSRU_accuracy: 0.9389 - MICU_accuracy: 0.9423 - SICU_accuracy: 0.9404 - TSICU_accuracy: 0.9384 - val_loss: 0.8755 - val_CCU_loss: 0.1776 - val_CSRU_loss: 0.1750 - val_MICU_loss: 0.1727 - val_SICU_loss: 0.1738 - val_TSICU_loss: 0.1764 - val_CCU_accuracy: 0.9380 - val_CSRU_accuracy: 0.9386 - val_MICU_accuracy: 0.9411 - val_SICU_accuracy: 0.9395 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 27/30\n",
      "224/224 [==============================] - 8s 37ms/step - loss: 0.1563 - CCU_loss: 0.0237 - CSRU_loss: 0.0123 - MICU_loss: 0.0725 - SICU_loss: 0.0283 - TSICU_loss: 0.0196 - CCU_accuracy: 0.9396 - CSRU_accuracy: 0.9390 - MICU_accuracy: 0.9427 - SICU_accuracy: 0.9411 - TSICU_accuracy: 0.9383 - val_loss: 0.8769 - val_CCU_loss: 0.1780 - val_CSRU_loss: 0.1766 - val_MICU_loss: 0.1724 - val_SICU_loss: 0.1738 - val_TSICU_loss: 0.1761 - val_CCU_accuracy: 0.9386 - val_CSRU_accuracy: 0.9389 - val_MICU_accuracy: 0.9411 - val_SICU_accuracy: 0.9402 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 28/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1559 - CCU_loss: 0.0236 - CSRU_loss: 0.0122 - MICU_loss: 0.0723 - SICU_loss: 0.0282 - TSICU_loss: 0.0195 - CCU_accuracy: 0.9402 - CSRU_accuracy: 0.9393 - MICU_accuracy: 0.9431 - SICU_accuracy: 0.9413 - TSICU_accuracy: 0.9382 - val_loss: 0.8893 - val_CCU_loss: 0.1816 - val_CSRU_loss: 0.1828 - val_MICU_loss: 0.1755 - val_SICU_loss: 0.1739 - val_TSICU_loss: 0.1755 - val_CCU_accuracy: 0.9389 - val_CSRU_accuracy: 0.9389 - val_MICU_accuracy: 0.9408 - val_SICU_accuracy: 0.9408 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 29/30\n",
      "224/224 [==============================] - 8s 36ms/step - loss: 0.1546 - CCU_loss: 0.0236 - CSRU_loss: 0.0120 - MICU_loss: 0.0715 - SICU_loss: 0.0280 - TSICU_loss: 0.0195 - CCU_accuracy: 0.9404 - CSRU_accuracy: 0.9397 - MICU_accuracy: 0.9435 - SICU_accuracy: 0.9416 - TSICU_accuracy: 0.9383 - val_loss: 0.8696 - val_CCU_loss: 0.1764 - val_CSRU_loss: 0.1737 - val_MICU_loss: 0.1719 - val_SICU_loss: 0.1723 - val_TSICU_loss: 0.1752 - val_CCU_accuracy: 0.9398 - val_CSRU_accuracy: 0.9392 - val_MICU_accuracy: 0.9411 - val_SICU_accuracy: 0.9405 - val_TSICU_accuracy: 0.9392\n",
      "Epoch 30/30\n",
      "224/224 [==============================] - 8s 38ms/step - loss: 0.1532 - CCU_loss: 0.0232 - CSRU_loss: 0.0117 - MICU_loss: 0.0711 - SICU_loss: 0.0277 - TSICU_loss: 0.0195 - CCU_accuracy: 0.9402 - CSRU_accuracy: 0.9397 - MICU_accuracy: 0.9435 - SICU_accuracy: 0.9418 - TSICU_accuracy: 0.9382 - val_loss: 0.8766 - val_CCU_loss: 0.1790 - val_CSRU_loss: 0.1772 - val_MICU_loss: 0.1734 - val_SICU_loss: 0.1723 - val_TSICU_loss: 0.1747 - val_CCU_accuracy: 0.9402 - val_CSRU_accuracy: 0.9389 - val_MICU_accuracy: 0.9411 - val_SICU_accuracy: 0.9408 - val_TSICU_accuracy: 0.9395\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_multitask_36+18_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'multitask' model...\n",
      "200/200 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89457592defb43a4adb403e8837013b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8969e5623645389bed9760c13afe75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596b07de3ddf42b0b3031751aaa62064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07818a458934a52b94047cc203bb868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82e915d522c42879fdf9a9ba12b9158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d339a7f2345f4d02854c24fbb7b15ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 11min 10s, sys: 4min 33s, total: 15min 44s\n",
      "Wall time: 13min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_mtl_36_careunits_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=36, gap_hours=18, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef88acf-1368-465d-80b4-79da55c24be2",
   "metadata": {
    "id": "6ef88acf-1368-465d-80b4-79da55c24be2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">CSRU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.957</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">MICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">SICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">TSICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Micro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Macro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "CCU    1       0.873  0.248        0.874\n",
       "       2       0.869  0.200        0.863\n",
       "       3       0.917  0.300        0.899\n",
       "       4       0.823  0.081        0.577\n",
       "       5       0.877  0.257        0.872\n",
       "       6       0.888  0.203        0.870\n",
       "       7       0.929  0.429        0.919\n",
       "       8       0.870  0.183        0.851\n",
       "       9       0.891  0.212        0.870\n",
       "       10      0.923  0.336        0.912\n",
       "       11      0.917  0.268        0.874\n",
       "       12      0.905  0.294        0.888\n",
       "       13      0.883  0.292        0.873\n",
       "       14      0.898  0.255        0.879\n",
       "       15      0.887  0.293        0.874\n",
       "       16      0.924  0.374        0.916\n",
       "       17      0.858  0.276        0.854\n",
       "       18      0.922  0.389        0.926\n",
       "       19      0.895  0.267        0.859\n",
       "       20      0.880  0.262        0.870\n",
       "       21      0.854  0.201        0.843\n",
       "       22      0.881  0.224        0.864\n",
       "       23      0.873  0.231        0.840\n",
       "       24      0.917  0.244        0.865\n",
       "       25      0.898  0.245        0.882\n",
       "       26      0.911  0.295        0.915\n",
       "       27      0.896  0.352        0.901\n",
       "       28      0.909  0.285        0.885\n",
       "       29      0.917  0.364        0.920\n",
       "       30      0.900  0.299        0.893\n",
       "       31      0.873  0.199        0.847\n",
       "       32      0.872  0.267        0.853\n",
       "       33      0.913  0.250        0.863\n",
       "       34      0.880  0.310        0.888\n",
       "       35      0.889  0.218        0.853\n",
       "       36      0.920  0.312        0.906\n",
       "       37      0.915  0.305        0.904\n",
       "       38      0.888  0.250        0.864\n",
       "       39      0.893  0.287        0.903\n",
       "       40      0.894  0.204        0.861\n",
       "       41      0.929  0.328        0.911\n",
       "       42      0.909  0.295        0.904\n",
       "       43      0.937  0.363        0.923\n",
       "       44      0.914  0.333        0.882\n",
       "       45      0.898  0.348        0.900\n",
       "       46      0.907  0.247        0.874\n",
       "       47      0.917  0.270        0.900\n",
       "       48      0.893  0.311        0.900\n",
       "       49      0.899  0.286        0.871\n",
       "       50      0.898  0.281        0.870\n",
       "       51      0.919  0.328        0.906\n",
       "       52      0.879  0.227        0.874\n",
       "       53      0.912  0.294        0.874\n",
       "       54      0.894  0.236        0.857\n",
       "       55      0.924  0.322        0.889\n",
       "       56      0.907  0.238        0.875\n",
       "       57      0.851  0.218        0.818\n",
       "       58      0.892  0.288        0.873\n",
       "       59      0.871  0.232        0.853\n",
       "       60      0.899  0.279        0.896\n",
       "       61      0.922  0.273        0.872\n",
       "       62      0.910  0.298        0.905\n",
       "       63      0.904  0.270        0.879\n",
       "       64      0.924  0.336        0.902\n",
       "       65      0.921  0.391        0.910\n",
       "       66      0.877  0.327        0.891\n",
       "       67      0.946  0.305        0.924\n",
       "       68      0.908  0.250        0.870\n",
       "       69      0.888  0.333        0.901\n",
       "       70      0.905  0.293        0.909\n",
       "       71      0.901  0.289        0.887\n",
       "       72      0.892  0.222        0.858\n",
       "       73      0.880  0.265        0.867\n",
       "       74      0.904  0.339        0.908\n",
       "       75      0.911  0.221        0.864\n",
       "       76      0.918  0.385        0.932\n",
       "       77      0.911  0.257        0.861\n",
       "       78      0.885  0.301        0.872\n",
       "       79      0.871  0.263        0.865\n",
       "       80      0.906  0.256        0.874\n",
       "       81      0.885  0.301        0.875\n",
       "       82      0.925  0.432        0.929\n",
       "       83      0.910  0.256        0.859\n",
       "       84      0.890  0.252        0.876\n",
       "       85      0.896  0.346        0.891\n",
       "       86      0.881  0.274        0.857\n",
       "       87      0.916  0.346        0.902\n",
       "       88      0.897  0.313        0.886\n",
       "       89      0.843  0.149        0.741\n",
       "       90      0.920  0.336        0.902\n",
       "       91      0.912  0.360        0.903\n",
       "       92      0.800  0.073        0.546\n",
       "       93      0.904  0.241        0.879\n",
       "       94      0.869  0.231        0.867\n",
       "       95      0.894  0.263        0.881\n",
       "       96      0.874  0.267        0.861\n",
       "       97      0.880  0.251        0.855\n",
       "       98      0.915  0.272        0.873\n",
       "       99      0.900  0.366        0.910\n",
       "       100     0.877  0.258        0.846\n",
       "CSRU   1       0.895  0.112        0.921\n",
       "       2       0.902  0.123        0.913\n",
       "       3       0.881  0.053        0.867\n",
       "       4       0.858  0.077        0.805\n",
       "       5       0.862  0.065        0.816\n",
       "       6       0.894  0.073        0.819\n",
       "       7       0.950  0.120        0.933\n",
       "       8       0.904  0.099        0.884\n",
       "       9       0.866  0.031        0.708\n",
       "       10      0.847  0.034        0.706\n",
       "       11      0.914  0.108        0.882\n",
       "       12      0.916  0.121        0.868\n",
       "       13      0.902  0.087        0.878\n",
       "       14      0.904  0.116        0.910\n",
       "       15      0.910  0.123        0.918\n",
       "       16      0.951  0.102        0.917\n",
       "       17      0.859  0.070        0.829\n",
       "       18      0.880  0.071        0.904\n",
       "       19      0.895  0.104        0.909\n",
       "       20      0.911  0.103        0.915\n",
       "       21      0.903  0.147        0.906\n",
       "       22      0.869  0.062        0.801\n",
       "       23      0.902  0.068        0.831\n",
       "       24      0.901  0.090        0.882\n",
       "       25      0.921  0.157        0.919\n",
       "       26      0.902  0.115        0.917\n",
       "       27      0.902  0.141        0.916\n",
       "       28      0.865  0.049        0.711\n",
       "       29      0.962  0.237        0.944\n",
       "       30      0.889  0.049        0.816\n",
       "       31      0.902  0.059        0.834\n",
       "       32      0.943  0.117        0.918\n",
       "       33      0.859  0.060        0.829\n",
       "       34      0.906  0.092        0.918\n",
       "       35      0.898  0.103        0.879\n",
       "       36      0.917  0.120        0.902\n",
       "       37      0.841  0.059        0.827\n",
       "       38      0.907  0.123        0.910\n",
       "       39      0.900  0.060        0.858\n",
       "       40      0.941  0.091        0.914\n",
       "       41      0.924  0.081        0.871\n",
       "       42      0.906  0.153        0.916\n",
       "       43      0.902  0.068        0.824\n",
       "       44      0.913  0.204        0.942\n",
       "       45      0.902  0.068        0.872\n",
       "       46      0.896  0.089        0.874\n",
       "       47      0.898  0.071        0.824\n",
       "       48      0.891  0.123        0.893\n",
       "       49      0.862  0.054        0.784\n",
       "       50      0.830  0.035        0.703\n",
       "       51      0.906  0.114        0.932\n",
       "       52      0.889  0.088        0.839\n",
       "       53      0.883  0.081        0.819\n",
       "       54      0.921  0.101        0.885\n",
       "       55      0.949  0.164        0.919\n",
       "       56      0.906  0.109        0.887\n",
       "       57      0.920  0.142        0.915\n",
       "       58      0.893  0.098        0.875\n",
       "       59      0.846  0.029        0.690\n",
       "       60      0.931  0.153        0.923\n",
       "       61      0.909  0.082        0.872\n",
       "       62      0.911  0.070        0.819\n",
       "       63      0.892  0.097        0.872\n",
       "       64      0.901  0.128        0.906\n",
       "       65      0.901  0.028        0.819\n",
       "       66      0.915  0.056        0.867\n",
       "       67      0.895  0.064        0.811\n",
       "       68      0.825  0.066        0.802\n",
       "       69      0.973  0.143        0.947\n",
       "       70      0.953  0.196        0.944\n",
       "       71      0.927  0.121        0.906\n",
       "       72      0.911  0.094        0.912\n",
       "       73      0.897  0.060        0.800\n",
       "       74      0.887  0.078        0.808\n",
       "       75      0.878  0.064        0.870\n",
       "       76      0.873  0.067        0.825\n",
       "       77      0.844  0.069        0.808\n",
       "       78      0.839  0.054        0.786\n",
       "       79      0.882  0.068        0.818\n",
       "       80      0.935  0.134        0.936\n",
       "       81      0.929  0.122        0.902\n",
       "       82      0.899  0.069        0.910\n",
       "       83      0.932  0.123        0.919\n",
       "       84      0.922  0.081        0.868\n",
       "       85      0.840  0.078        0.852\n",
       "       86      0.899  0.137        0.920\n",
       "       87      0.945  0.068        0.910\n",
       "       88      0.883  0.120        0.900\n",
       "       89      0.893  0.067        0.832\n",
       "       90      0.886  0.058        0.826\n",
       "       91      0.908  0.101        0.817\n",
       "       92      0.932  0.110        0.909\n",
       "       93      0.888  0.079        0.871\n",
       "       94      0.925  0.127        0.912\n",
       "       95      0.888  0.111        0.857\n",
       "       96      0.946  0.117        0.908\n",
       "       97      0.893  0.101        0.868\n",
       "       98      0.904  0.078        0.900\n",
       "       99      0.957  0.118        0.933\n",
       "       100     0.862  0.065        0.824\n",
       "MICU   1       0.858  0.228        0.730\n",
       "       2       0.843  0.213        0.698\n",
       "       3       0.812  0.165        0.633\n",
       "       4       0.830  0.194        0.687\n",
       "       5       0.824  0.190        0.663\n",
       "       6       0.813  0.217        0.678\n",
       "       7       0.820  0.198        0.627\n",
       "       8       0.831  0.201        0.665\n",
       "       9       0.817  0.195        0.680\n",
       "       10      0.837  0.183        0.672\n",
       "       11      0.850  0.220        0.718\n",
       "       12      0.838  0.226        0.688\n",
       "       13      0.824  0.185        0.663\n",
       "       14      0.807  0.167        0.611\n",
       "       15      0.830  0.206        0.686\n",
       "       16      0.835  0.231        0.705\n",
       "       17      0.847  0.220        0.705\n",
       "       18      0.839  0.211        0.715\n",
       "       19      0.813  0.165        0.601\n",
       "       20      0.843  0.199        0.669\n",
       "       21      0.838  0.219        0.706\n",
       "       22      0.835  0.206        0.686\n",
       "       23      0.856  0.213        0.708\n",
       "       24      0.831  0.211        0.695\n",
       "       25      0.830  0.176        0.681\n",
       "       26      0.822  0.186        0.663\n",
       "       27      0.825  0.189        0.669\n",
       "       28      0.833  0.200        0.670\n",
       "       29      0.819  0.196        0.639\n",
       "       30      0.815  0.172        0.624\n",
       "       31      0.841  0.217        0.677\n",
       "       32      0.823  0.190        0.681\n",
       "       33      0.839  0.238        0.728\n",
       "       34      0.849  0.234        0.708\n",
       "       35      0.868  0.252        0.761\n",
       "       36      0.850  0.213        0.720\n",
       "       37      0.828  0.192        0.666\n",
       "       38      0.847  0.218        0.723\n",
       "       39      0.853  0.250        0.717\n",
       "       40      0.831  0.222        0.703\n",
       "       41      0.831  0.201        0.697\n",
       "       42      0.852  0.197        0.693\n",
       "       43      0.813  0.169        0.604\n",
       "       44      0.848  0.225        0.724\n",
       "       45      0.823  0.211        0.673\n",
       "       46      0.852  0.225        0.739\n",
       "       47      0.831  0.192        0.675\n",
       "       48      0.813  0.190        0.656\n",
       "       49      0.796  0.192        0.636\n",
       "       50      0.834  0.199        0.676\n",
       "       51      0.827  0.190        0.646\n",
       "       52      0.836  0.189        0.683\n",
       "       53      0.823  0.196        0.648\n",
       "       54      0.823  0.197        0.654\n",
       "       55      0.832  0.207        0.693\n",
       "       56      0.813  0.180        0.636\n",
       "       57      0.842  0.184        0.688\n",
       "       58      0.828  0.199        0.659\n",
       "       59      0.814  0.187        0.659\n",
       "       60      0.837  0.201        0.690\n",
       "       61      0.846  0.202        0.690\n",
       "       62      0.829  0.187        0.662\n",
       "       63      0.839  0.206        0.702\n",
       "       64      0.805  0.199        0.666\n",
       "       65      0.840  0.206        0.687\n",
       "       66      0.840  0.216        0.685\n",
       "       67      0.830  0.186        0.675\n",
       "       68      0.835  0.207        0.709\n",
       "       69      0.820  0.209        0.695\n",
       "       70      0.839  0.204        0.705\n",
       "       71      0.834  0.201        0.694\n",
       "       72      0.856  0.206        0.690\n",
       "       73      0.826  0.185        0.663\n",
       "       74      0.837  0.218        0.697\n",
       "       75      0.850  0.215        0.698\n",
       "       76      0.844  0.217        0.721\n",
       "       77      0.813  0.183        0.644\n",
       "       78      0.830  0.213        0.663\n",
       "       79      0.837  0.216        0.700\n",
       "       80      0.840  0.196        0.691\n",
       "       81      0.835  0.186        0.664\n",
       "       82      0.842  0.196        0.677\n",
       "       83      0.827  0.187        0.675\n",
       "       84      0.834  0.204        0.683\n",
       "       85      0.817  0.182        0.648\n",
       "       86      0.852  0.191        0.677\n",
       "       87      0.834  0.207        0.675\n",
       "       88      0.825  0.194        0.676\n",
       "       89      0.831  0.211        0.688\n",
       "       90      0.814  0.206        0.675\n",
       "       91      0.846  0.216        0.711\n",
       "       92      0.831  0.197        0.671\n",
       "       93      0.835  0.198        0.694\n",
       "       94      0.821  0.192        0.674\n",
       "       95      0.799  0.172        0.591\n",
       "       96      0.790  0.163        0.608\n",
       "       97      0.817  0.169        0.603\n",
       "       98      0.834  0.214        0.679\n",
       "       99      0.827  0.204        0.675\n",
       "       100     0.857  0.228        0.720\n",
       "SICU   1       0.841  0.154        0.743\n",
       "       2       0.809  0.119        0.645\n",
       "       3       0.841  0.155        0.754\n",
       "       4       0.819  0.150        0.717\n",
       "       5       0.836  0.126        0.656\n",
       "       6       0.793  0.128        0.655\n",
       "       7       0.865  0.153        0.707\n",
       "       8       0.880  0.152        0.744\n",
       "       9       0.811  0.145        0.709\n",
       "       10      0.827  0.166        0.679\n",
       "       11      0.844  0.162        0.734\n",
       "       12      0.820  0.141        0.702\n",
       "       13      0.816  0.178        0.699\n",
       "       14      0.827  0.166        0.734\n",
       "       15      0.822  0.173        0.723\n",
       "       16      0.840  0.156        0.726\n",
       "       17      0.810  0.155        0.678\n",
       "       18      0.814  0.171        0.706\n",
       "       19      0.802  0.164        0.712\n",
       "       20      0.835  0.126        0.752\n",
       "       21      0.863  0.184        0.772\n",
       "       22      0.863  0.253        0.817\n",
       "       23      0.781  0.136        0.681\n",
       "       24      0.867  0.192        0.767\n",
       "       25      0.818  0.173        0.693\n",
       "       26      0.858  0.153        0.740\n",
       "       27      0.837  0.188        0.743\n",
       "       28      0.862  0.197        0.743\n",
       "       29      0.807  0.117        0.687\n",
       "       30      0.783  0.108        0.671\n",
       "       31      0.843  0.167        0.716\n",
       "       32      0.824  0.142        0.695\n",
       "       33      0.813  0.151        0.688\n",
       "       34      0.854  0.163        0.742\n",
       "       35      0.824  0.117        0.682\n",
       "       36      0.821  0.150        0.727\n",
       "       37      0.839  0.124        0.705\n",
       "       38      0.858  0.160        0.756\n",
       "       39      0.822  0.145        0.740\n",
       "       40      0.808  0.175        0.683\n",
       "       41      0.882  0.185        0.754\n",
       "       42      0.859  0.172        0.793\n",
       "       43      0.881  0.182        0.817\n",
       "       44      0.841  0.134        0.695\n",
       "       45      0.828  0.130        0.670\n",
       "       46      0.826  0.164        0.743\n",
       "       47      0.829  0.133        0.693\n",
       "       48      0.838  0.168        0.726\n",
       "       49      0.854  0.135        0.711\n",
       "       50      0.823  0.147        0.684\n",
       "       51      0.823  0.160        0.731\n",
       "       52      0.828  0.162        0.728\n",
       "       53      0.825  0.159        0.722\n",
       "       54      0.837  0.194        0.764\n",
       "       55      0.800  0.172        0.727\n",
       "       56      0.852  0.153        0.745\n",
       "       57      0.843  0.154        0.741\n",
       "       58      0.820  0.151        0.703\n",
       "       59      0.799  0.139        0.664\n",
       "       60      0.790  0.154        0.677\n",
       "       61      0.851  0.157        0.689\n",
       "       62      0.838  0.169        0.740\n",
       "       63      0.828  0.152        0.727\n",
       "       64      0.862  0.166        0.757\n",
       "       65      0.818  0.126        0.677\n",
       "       66      0.815  0.154        0.720\n",
       "       67      0.834  0.193        0.763\n",
       "       68      0.794  0.126        0.669\n",
       "       69      0.839  0.173        0.744\n",
       "       70      0.841  0.151        0.696\n",
       "       71      0.850  0.143        0.719\n",
       "       72      0.833  0.186        0.748\n",
       "       73      0.805  0.128        0.677\n",
       "       74      0.808  0.130        0.685\n",
       "       75      0.855  0.137        0.734\n",
       "       76      0.837  0.169        0.736\n",
       "       77      0.845  0.168        0.737\n",
       "       78      0.824  0.153        0.750\n",
       "       79      0.862  0.195        0.798\n",
       "       80      0.856  0.157        0.750\n",
       "       81      0.814  0.152        0.711\n",
       "       82      0.861  0.177        0.773\n",
       "       83      0.806  0.119        0.709\n",
       "       84      0.840  0.170        0.724\n",
       "       85      0.843  0.150        0.726\n",
       "       86      0.825  0.164        0.722\n",
       "       87      0.835  0.162        0.738\n",
       "       88      0.829  0.136        0.731\n",
       "       89      0.844  0.177        0.742\n",
       "       90      0.813  0.132        0.688\n",
       "       91      0.847  0.157        0.713\n",
       "       92      0.819  0.167        0.710\n",
       "       93      0.837  0.158        0.735\n",
       "       94      0.834  0.152        0.730\n",
       "       95      0.814  0.129        0.652\n",
       "       96      0.856  0.176        0.742\n",
       "       97      0.810  0.132        0.674\n",
       "       98      0.832  0.186        0.731\n",
       "       99      0.818  0.154        0.723\n",
       "       100     0.817  0.167        0.708\n",
       "TSICU  1       0.914  0.251        0.835\n",
       "       2       0.888  0.211        0.823\n",
       "       3       0.929  0.372        0.877\n",
       "       4       0.898  0.254        0.821\n",
       "       5       0.931  0.260        0.855\n",
       "       6       0.915  0.280        0.838\n",
       "       7       0.925  0.248        0.853\n",
       "       8       0.922  0.315        0.876\n",
       "       9       0.899  0.292        0.850\n",
       "       10      0.941  0.397        0.908\n",
       "       11      0.939  0.385        0.901\n",
       "       12      0.915  0.288        0.857\n",
       "       13      0.886  0.188        0.806\n",
       "       14      0.906  0.275        0.854\n",
       "       15      0.912  0.252        0.865\n",
       "       16      0.927  0.310        0.877\n",
       "       17      0.941  0.395        0.915\n",
       "       18      0.909  0.278        0.848\n",
       "       19      0.902  0.245        0.850\n",
       "       20      0.938  0.313        0.872\n",
       "       21      0.898  0.214        0.812\n",
       "       22      0.899  0.241        0.831\n",
       "       23      0.909  0.238        0.837\n",
       "       24      0.942  0.285        0.883\n",
       "       25      0.915  0.261        0.857\n",
       "       26      0.898  0.200        0.815\n",
       "       27      0.929  0.245        0.867\n",
       "       28      0.920  0.270        0.838\n",
       "       29      0.915  0.256        0.842\n",
       "       30      0.910  0.272        0.851\n",
       "       31      0.901  0.253        0.843\n",
       "       32      0.920  0.304        0.879\n",
       "       33      0.929  0.257        0.865\n",
       "       34      0.933  0.359        0.899\n",
       "       35      0.895  0.199        0.809\n",
       "       36      0.916  0.282        0.872\n",
       "       37      0.941  0.354        0.888\n",
       "       38      0.894  0.240        0.819\n",
       "       39      0.928  0.340        0.883\n",
       "       40      0.921  0.280        0.857\n",
       "       41      0.931  0.353        0.889\n",
       "       42      0.909  0.261        0.843\n",
       "       43      0.918  0.253        0.851\n",
       "       44      0.889  0.258        0.831\n",
       "       45      0.918  0.226        0.859\n",
       "       46      0.920  0.306        0.842\n",
       "       47      0.920  0.325        0.888\n",
       "       48      0.924  0.313        0.869\n",
       "       49      0.893  0.199        0.829\n",
       "       50      0.907  0.292        0.860\n",
       "       51      0.870  0.223        0.815\n",
       "       52      0.916  0.230        0.845\n",
       "       53      0.918  0.255        0.855\n",
       "       54      0.912  0.257        0.844\n",
       "       55      0.907  0.245        0.823\n",
       "       56      0.905  0.240        0.846\n",
       "       57      0.891  0.269        0.825\n",
       "       58      0.911  0.215        0.838\n",
       "       59      0.896  0.335        0.863\n",
       "       60      0.921  0.269        0.862\n",
       "       61      0.911  0.259        0.857\n",
       "       62      0.920  0.278        0.877\n",
       "       63      0.917  0.267        0.862\n",
       "       64      0.911  0.276        0.854\n",
       "       65      0.917  0.259        0.865\n",
       "       66      0.905  0.276        0.852\n",
       "       67      0.925  0.293        0.867\n",
       "       68      0.905  0.216        0.833\n",
       "       69      0.923  0.282        0.860\n",
       "       70      0.885  0.254        0.837\n",
       "       71      0.928  0.255        0.860\n",
       "       72      0.927  0.325        0.864\n",
       "       73      0.929  0.290        0.863\n",
       "       74      0.916  0.325        0.869\n",
       "       75      0.890  0.216        0.776\n",
       "       76      0.894  0.260        0.833\n",
       "       77      0.908  0.302        0.866\n",
       "       78      0.919  0.284        0.849\n",
       "       79      0.893  0.256        0.851\n",
       "       80      0.895  0.234        0.838\n",
       "       81      0.898  0.262        0.843\n",
       "       82      0.922  0.271        0.840\n",
       "       83      0.925  0.306        0.870\n",
       "       84      0.908  0.225        0.863\n",
       "       85      0.902  0.259        0.825\n",
       "       86      0.926  0.293        0.871\n",
       "       87      0.888  0.217        0.784\n",
       "       88      0.927  0.325        0.860\n",
       "       89      0.921  0.283        0.857\n",
       "       90      0.902  0.232        0.835\n",
       "       91      0.937  0.293        0.883\n",
       "       92      0.912  0.265        0.852\n",
       "       93      0.907  0.228        0.871\n",
       "       94      0.905  0.226        0.834\n",
       "       95      0.926  0.368        0.891\n",
       "       96      0.889  0.218        0.809\n",
       "       97      0.913  0.300        0.861\n",
       "       98      0.932  0.371        0.885\n",
       "       99      0.927  0.315        0.872\n",
       "       100     0.917  0.367        0.894\n",
       "Micro  1       0.877  0.193        0.779\n",
       "       2       0.865  0.197        0.784\n",
       "       3       0.878  0.205        0.797\n",
       "       4       0.891  0.221        0.815\n",
       "       5       0.865  0.177        0.754\n",
       "       6       0.867  0.187        0.770\n",
       "       7       0.882  0.219        0.812\n",
       "       8       0.866  0.200        0.790\n",
       "       9       0.864  0.192        0.777\n",
       "       10      0.872  0.200        0.789\n",
       "       11      0.879  0.202        0.792\n",
       "       12      0.871  0.186        0.768\n",
       "       13      0.865  0.182        0.762\n",
       "       14      0.872  0.167        0.737\n",
       "       15      0.883  0.223        0.817\n",
       "       16      0.869  0.200        0.788\n",
       "       17      0.882  0.225        0.818\n",
       "       18      0.876  0.201        0.790\n",
       "       19      0.868  0.187        0.772\n",
       "       20      0.879  0.200        0.789\n",
       "       21      0.873  0.191        0.776\n",
       "       22      0.874  0.205        0.796\n",
       "       23      0.878  0.205        0.795\n",
       "       24      0.871  0.196        0.783\n",
       "       25      0.876  0.195        0.782\n",
       "       26      0.860  0.167        0.736\n",
       "       27      0.871  0.199        0.789\n",
       "       28      0.878  0.194        0.781\n",
       "       29      0.867  0.178        0.757\n",
       "       30      0.874  0.209        0.800\n",
       "       31      0.881  0.211        0.802\n",
       "       32      0.851  0.164        0.730\n",
       "       33      0.879  0.207        0.798\n",
       "       34      0.882  0.208        0.799\n",
       "       35      0.860  0.169        0.740\n",
       "       36      0.867  0.187        0.772\n",
       "       37      0.886  0.224        0.818\n",
       "       38      0.865  0.191        0.776\n",
       "       39      0.858  0.181        0.761\n",
       "       40      0.877  0.203        0.793\n",
       "       41      0.863  0.178        0.759\n",
       "       42      0.864  0.181        0.760\n",
       "       43      0.873  0.196        0.785\n",
       "       44      0.868  0.179        0.758\n",
       "       45      0.867  0.186        0.769\n",
       "       46      0.871  0.199        0.787\n",
       "       47      0.880  0.202        0.792\n",
       "       48      0.864  0.171        0.743\n",
       "       49      0.865  0.191        0.778\n",
       "       50      0.866  0.178        0.757\n",
       "       51      0.877  0.188        0.772\n",
       "       52      0.865  0.189        0.772\n",
       "       53      0.876  0.204        0.794\n",
       "       54      0.859  0.172        0.746\n",
       "       55      0.871  0.187        0.772\n",
       "       56      0.868  0.197        0.786\n",
       "       57      0.867  0.198        0.787\n",
       "       58      0.888  0.218        0.810\n",
       "       59      0.873  0.204        0.794\n",
       "       60      0.892  0.221        0.814\n",
       "       61      0.883  0.208        0.800\n",
       "       62      0.881  0.203        0.792\n",
       "       63      0.869  0.185        0.768\n",
       "       64      0.860  0.170        0.741\n",
       "       65      0.875  0.198        0.785\n",
       "       66      0.875  0.193        0.779\n",
       "       67      0.867  0.170        0.742\n",
       "       68      0.890  0.225        0.818\n",
       "       69      0.869  0.180        0.759\n",
       "       70      0.873  0.190        0.775\n",
       "       71      0.876  0.208        0.799\n",
       "       72      0.886  0.220        0.812\n",
       "       73      0.884  0.211        0.804\n",
       "       74      0.879  0.203        0.792\n",
       "       75      0.868  0.193        0.781\n",
       "       76      0.878  0.201        0.789\n",
       "       77      0.867  0.183        0.765\n",
       "       78      0.881  0.214        0.805\n",
       "       79      0.881  0.204        0.795\n",
       "       80      0.858  0.164        0.731\n",
       "       81      0.882  0.202        0.791\n",
       "       82      0.864  0.180        0.759\n",
       "       83      0.878  0.208        0.799\n",
       "       84      0.870  0.183        0.764\n",
       "       85      0.871  0.176        0.754\n",
       "       86      0.870  0.192        0.778\n",
       "       87      0.874  0.204        0.795\n",
       "       88      0.877  0.214        0.806\n",
       "       89      0.870  0.190        0.775\n",
       "       90      0.876  0.204        0.794\n",
       "       91      0.880  0.198        0.787\n",
       "       92      0.878  0.202        0.791\n",
       "       93      0.865  0.182        0.763\n",
       "       94      0.866  0.186        0.768\n",
       "       95      0.883  0.219        0.811\n",
       "       96      0.870  0.192        0.777\n",
       "       97      0.868  0.199        0.788\n",
       "       98      0.871  0.181        0.761\n",
       "       99      0.872  0.201        0.791\n",
       "       100     0.888  0.225        0.818\n",
       "Macro  1       0.876  0.199        0.820\n",
       "       2       0.875  0.223        0.775\n",
       "       3       0.866  0.217        0.799\n",
       "       4       0.893  0.229        0.822\n",
       "       5       0.879  0.214        0.801\n",
       "       6       0.862  0.186        0.784\n",
       "       7       0.868  0.196        0.798\n",
       "       8       0.872  0.209        0.813\n",
       "       9       0.896  0.235        0.828\n",
       "       10      0.863  0.223        0.796\n",
       "       11      0.873  0.224        0.820\n",
       "       12      0.861  0.189        0.786\n",
       "       13      0.862  0.173        0.788\n",
       "       14      0.882  0.201        0.816\n",
       "       15      0.871  0.193        0.808\n",
       "       16      0.870  0.197        0.800\n",
       "       17      0.864  0.177        0.779\n",
       "       18      0.892  0.204        0.818\n",
       "       19      0.876  0.202        0.807\n",
       "       20      0.878  0.190        0.810\n",
       "       21      0.878  0.223        0.819\n",
       "       22      0.878  0.200        0.769\n",
       "       23      0.884  0.234        0.806\n",
       "       24      0.876  0.209        0.806\n",
       "       25      0.860  0.180        0.771\n",
       "       26      0.872  0.179        0.783\n",
       "       27      0.876  0.204        0.805\n",
       "       28      0.870  0.191        0.795\n",
       "       29      0.884  0.231        0.831\n",
       "       30      0.875  0.178        0.797\n",
       "       31      0.885  0.215        0.825\n",
       "       32      0.872  0.207        0.798\n",
       "       33      0.879  0.198        0.814\n",
       "       34      0.879  0.216        0.820\n",
       "       35      0.846  0.151        0.722\n",
       "       36      0.879  0.194        0.803\n",
       "       37      0.899  0.230        0.824\n",
       "       38      0.887  0.215        0.830\n",
       "       39      0.890  0.207        0.804\n",
       "       40      0.881  0.231        0.815\n",
       "       41      0.874  0.197        0.795\n",
       "       42      0.880  0.206        0.815\n",
       "       43      0.879  0.199        0.796\n",
       "       44      0.872  0.221        0.809\n",
       "       45      0.861  0.173        0.766\n",
       "       46      0.866  0.180        0.773\n",
       "       47      0.859  0.191        0.758\n",
       "       48      0.869  0.203        0.806\n",
       "       49      0.870  0.179        0.794\n",
       "       50      0.872  0.197        0.784\n",
       "       51      0.877  0.197        0.801\n",
       "       52      0.882  0.222        0.810\n",
       "       53      0.876  0.184        0.798\n",
       "       54      0.869  0.193        0.798\n",
       "       55      0.869  0.190        0.790\n",
       "       56      0.845  0.184        0.746\n",
       "       57      0.860  0.180        0.772\n",
       "       58      0.876  0.211        0.810\n",
       "       59      0.888  0.195        0.796\n",
       "       60      0.881  0.200        0.801\n",
       "       61      0.876  0.198        0.808\n",
       "       62      0.880  0.221        0.817\n",
       "       63      0.879  0.202        0.792\n",
       "       64      0.871  0.206        0.803\n",
       "       65      0.886  0.208        0.808\n",
       "       66      0.853  0.173        0.777\n",
       "       67      0.888  0.228        0.829\n",
       "       68      0.898  0.230        0.808\n",
       "       69      0.885  0.219        0.818\n",
       "       70      0.888  0.202        0.813\n",
       "       71      0.884  0.207        0.814\n",
       "       72      0.867  0.186        0.774\n",
       "       73      0.870  0.218        0.793\n",
       "       74      0.877  0.170        0.788\n",
       "       75      0.873  0.220        0.809\n",
       "       76      0.864  0.196        0.783\n",
       "       77      0.859  0.201        0.784\n",
       "       78      0.869  0.200        0.806\n",
       "       79      0.882  0.190        0.804\n",
       "       80      0.886  0.195        0.818\n",
       "       81      0.872  0.205        0.799\n",
       "       82      0.890  0.229        0.826\n",
       "       83      0.880  0.198        0.806\n",
       "       84      0.879  0.186        0.803\n",
       "       85      0.860  0.203        0.789\n",
       "       86      0.876  0.212        0.809\n",
       "       87      0.884  0.200        0.802\n",
       "       88      0.872  0.218        0.811\n",
       "       89      0.866  0.178        0.772\n",
       "       90      0.857  0.175        0.763\n",
       "       91      0.867  0.193        0.785\n",
       "       92      0.890  0.226        0.805\n",
       "       93      0.859  0.162        0.737\n",
       "       94      0.874  0.181        0.810\n",
       "       95      0.871  0.186        0.803\n",
       "       96      0.864  0.208        0.774\n",
       "       97      0.871  0.188        0.786\n",
       "       98      0.863  0.191        0.772\n",
       "       99      0.883  0.224        0.814\n",
       "       100     0.886  0.231        0.823"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_mtl_36_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00efa1-fc2a-4a82-b443-4b4ced5f7f74",
   "metadata": {
    "id": "cf00efa1-fc2a-4a82-b443-4b4ced5f7f74"
   },
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c8284e-e848-4c66-8217-e33f9badb079",
   "metadata": {
    "id": "25c8284e-e848-4c66-8217-e33f9badb079",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 36]...\n",
      "        New X_discrete.shape: (1110984, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 36 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 986 out of 11065\n",
      "        SICU: 347 out of 5062\n",
      "        CCU: 287 out of 4725\n",
      "        CSRU: 124 out of 6932\n",
      "        TSICU: 240 out of 4132\n",
      "    Final shape of X: (31916, 36, 232)\n",
      "    Number of positive samples: 1984\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort 0 is 12716\n",
      "        # of patients in cohort 1 is 1914\n",
      "        # of patients in cohort 2 is 7710\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'multitask' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"multitask_learning_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 36, 232)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 16)           15936       ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " 0 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " 1 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " 2 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,987\n",
      "Trainable params: 15,987\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "224/224 [==============================] - 11s 36ms/step - loss: 0.4319 - 0_loss: 0.2360 - 1_loss: 0.0427 - 2_loss: 0.1533 - 0_accuracy: 0.9352 - 1_accuracy: 0.8846 - 2_accuracy: 0.9014 - val_loss: 1.0509 - val_0_loss: 0.3296 - val_1_loss: 0.3537 - val_2_loss: 0.3676 - val_0_accuracy: 0.9380 - val_1_accuracy: 0.9377 - val_2_accuracy: 0.9383\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.2906 - 0_loss: 0.1544 - 1_loss: 0.0224 - 2_loss: 0.1138 - 0_accuracy: 0.9372 - 1_accuracy: 0.9378 - 2_accuracy: 0.9377 - val_loss: 0.8880 - val_0_loss: 0.2951 - val_1_loss: 0.2912 - val_2_loss: 0.3016 - val_0_accuracy: 0.9361 - val_1_accuracy: 0.9380 - val_2_accuracy: 0.9380\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.2445 - 0_loss: 0.1295 - 1_loss: 0.0152 - 2_loss: 0.0999 - 0_accuracy: 0.9361 - 1_accuracy: 0.9378 - 2_accuracy: 0.9378 - val_loss: 0.8228 - val_0_loss: 0.2755 - val_1_loss: 0.2673 - val_2_loss: 0.2800 - val_0_accuracy: 0.9367 - val_1_accuracy: 0.9380 - val_2_accuracy: 0.9383\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.2200 - 0_loss: 0.1162 - 1_loss: 0.0119 - 2_loss: 0.0919 - 0_accuracy: 0.9357 - 1_accuracy: 0.9378 - 2_accuracy: 0.9379 - val_loss: 0.7763 - val_0_loss: 0.2694 - val_1_loss: 0.2474 - val_2_loss: 0.2595 - val_0_accuracy: 0.9358 - val_1_accuracy: 0.9380 - val_2_accuracy: 0.9383\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.2055 - 0_loss: 0.1089 - 1_loss: 0.0103 - 2_loss: 0.0864 - 0_accuracy: 0.9353 - 1_accuracy: 0.9378 - 2_accuracy: 0.9378 - val_loss: 0.7489 - val_0_loss: 0.2573 - val_1_loss: 0.2399 - val_2_loss: 0.2517 - val_0_accuracy: 0.9364 - val_1_accuracy: 0.9380 - val_2_accuracy: 0.9383\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1957 - 0_loss: 0.1045 - 1_loss: 0.0094 - 2_loss: 0.0818 - 0_accuracy: 0.9359 - 1_accuracy: 0.9379 - 2_accuracy: 0.9378 - val_loss: 0.7041 - val_0_loss: 0.2538 - val_1_loss: 0.2214 - val_2_loss: 0.2290 - val_0_accuracy: 0.9367 - val_1_accuracy: 0.9377 - val_2_accuracy: 0.9383\n",
      "Epoch 7/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1885 - 0_loss: 0.1013 - 1_loss: 0.0087 - 2_loss: 0.0785 - 0_accuracy: 0.9363 - 1_accuracy: 0.9379 - 2_accuracy: 0.9379 - val_loss: 0.6896 - val_0_loss: 0.2446 - val_1_loss: 0.2179 - val_2_loss: 0.2270 - val_0_accuracy: 0.9377 - val_1_accuracy: 0.9377 - val_2_accuracy: 0.9383\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1834 - 0_loss: 0.0987 - 1_loss: 0.0086 - 2_loss: 0.0761 - 0_accuracy: 0.9368 - 1_accuracy: 0.9379 - 2_accuracy: 0.9380 - val_loss: 0.6606 - val_0_loss: 0.2479 - val_1_loss: 0.2040 - val_2_loss: 0.2087 - val_0_accuracy: 0.9367 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9380\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1798 - 0_loss: 0.0971 - 1_loss: 0.0083 - 2_loss: 0.0743 - 0_accuracy: 0.9369 - 1_accuracy: 0.9380 - 2_accuracy: 0.9380 - val_loss: 0.6558 - val_0_loss: 0.2398 - val_1_loss: 0.2047 - val_2_loss: 0.2114 - val_0_accuracy: 0.9370 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9380\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1775 - 0_loss: 0.0958 - 1_loss: 0.0082 - 2_loss: 0.0734 - 0_accuracy: 0.9368 - 1_accuracy: 0.9380 - 2_accuracy: 0.9383 - val_loss: 0.6406 - val_0_loss: 0.2423 - val_1_loss: 0.1969 - val_2_loss: 0.2015 - val_0_accuracy: 0.9352 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9380\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1753 - 0_loss: 0.0948 - 1_loss: 0.0082 - 2_loss: 0.0724 - 0_accuracy: 0.9364 - 1_accuracy: 0.9380 - 2_accuracy: 0.9382 - val_loss: 0.6369 - val_0_loss: 0.2379 - val_1_loss: 0.1965 - val_2_loss: 0.2024 - val_0_accuracy: 0.9364 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9383\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1729 - 0_loss: 0.0933 - 1_loss: 0.0079 - 2_loss: 0.0716 - 0_accuracy: 0.9368 - 1_accuracy: 0.9380 - 2_accuracy: 0.9385 - val_loss: 0.6394 - val_0_loss: 0.2374 - val_1_loss: 0.1974 - val_2_loss: 0.2045 - val_0_accuracy: 0.9358 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9383\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 8s 35ms/step - loss: 0.1715 - 0_loss: 0.0926 - 1_loss: 0.0080 - 2_loss: 0.0709 - 0_accuracy: 0.9362 - 1_accuracy: 0.9380 - 2_accuracy: 0.9387 - val_loss: 0.6467 - val_0_loss: 0.2319 - val_1_loss: 0.2024 - val_2_loss: 0.2123 - val_0_accuracy: 0.9364 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9383\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1700 - 0_loss: 0.0919 - 1_loss: 0.0078 - 2_loss: 0.0704 - 0_accuracy: 0.9352 - 1_accuracy: 0.9380 - 2_accuracy: 0.9386 - val_loss: 0.6344 - val_0_loss: 0.2408 - val_1_loss: 0.1934 - val_2_loss: 0.2002 - val_0_accuracy: 0.9342 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9383\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1688 - 0_loss: 0.0911 - 1_loss: 0.0077 - 2_loss: 0.0700 - 0_accuracy: 0.9351 - 1_accuracy: 0.9380 - 2_accuracy: 0.9389 - val_loss: 0.6470 - val_0_loss: 0.2432 - val_1_loss: 0.1975 - val_2_loss: 0.2063 - val_0_accuracy: 0.9279 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9386\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1673 - 0_loss: 0.0903 - 1_loss: 0.0077 - 2_loss: 0.0694 - 0_accuracy: 0.9314 - 1_accuracy: 0.9380 - 2_accuracy: 0.9391 - val_loss: 0.6350 - val_0_loss: 0.2387 - val_1_loss: 0.1939 - val_2_loss: 0.2024 - val_0_accuracy: 0.9348 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9392\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1663 - 0_loss: 0.0895 - 1_loss: 0.0077 - 2_loss: 0.0691 - 0_accuracy: 0.9328 - 1_accuracy: 0.9380 - 2_accuracy: 0.9392 - val_loss: 0.6515 - val_0_loss: 0.2334 - val_1_loss: 0.2027 - val_2_loss: 0.2154 - val_0_accuracy: 0.9345 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9392\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.1655 - 0_loss: 0.0889 - 1_loss: 0.0077 - 2_loss: 0.0689 - 0_accuracy: 0.9267 - 1_accuracy: 0.9380 - 2_accuracy: 0.9394 - val_loss: 0.6333 - val_0_loss: 0.2410 - val_1_loss: 0.1920 - val_2_loss: 0.2003 - val_0_accuracy: 0.9352 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9398\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1642 - 0_loss: 0.0884 - 1_loss: 0.0075 - 2_loss: 0.0683 - 0_accuracy: 0.9300 - 1_accuracy: 0.9380 - 2_accuracy: 0.9395 - val_loss: 0.6415 - val_0_loss: 0.2448 - val_1_loss: 0.1939 - val_2_loss: 0.2027 - val_0_accuracy: 0.9314 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9402\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1629 - 0_loss: 0.0879 - 1_loss: 0.0073 - 2_loss: 0.0676 - 0_accuracy: 0.9287 - 1_accuracy: 0.9382 - 2_accuracy: 0.9397 - val_loss: 0.6377 - val_0_loss: 0.2435 - val_1_loss: 0.1920 - val_2_loss: 0.2022 - val_0_accuracy: 0.9276 - val_1_accuracy: 0.9373 - val_2_accuracy: 0.9398\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 8s 34ms/step - loss: 0.1616 - 0_loss: 0.0873 - 1_loss: 0.0072 - 2_loss: 0.0670 - 0_accuracy: 0.9249 - 1_accuracy: 0.9382 - 2_accuracy: 0.9397 - val_loss: 0.6400 - val_0_loss: 0.2425 - val_1_loss: 0.1931 - val_2_loss: 0.2044 - val_0_accuracy: 0.9279 - val_1_accuracy: 0.9377 - val_2_accuracy: 0.9392\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 7s 33ms/step - loss: 0.1609 - 0_loss: 0.0868 - 1_loss: 0.0074 - 2_loss: 0.0667 - 0_accuracy: 0.9252 - 1_accuracy: 0.9383 - 2_accuracy: 0.9401 - val_loss: 0.6464 - val_0_loss: 0.2379 - val_1_loss: 0.1968 - val_2_loss: 0.2116 - val_0_accuracy: 0.9298 - val_1_accuracy: 0.9377 - val_2_accuracy: 0.9395\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_multitask_36+18_unsupervised/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'multitask' model...\n",
      "200/200 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"0\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61692065fe5f47ebb21247c1f370ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"1\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d9fd778ee7466389c8231d846a66f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"2\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7ce01583614597b0c83e8ca2fb6e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda53bc8eb404047a32e743d61c388d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 13:54:14.400999: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 406.79MiB (rounded to 426553344)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-13 13:54:14.401242: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *********************_*****************************************************************************_\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/Documents/repos/dl4h-sp23-team27-project/notebooks/../code/mtl_patients.py:1428\u001b[0m, in \u001b[0;36mrun_mortality_prediction_task\u001b[0;34m(model_type, cutoff_hours, gap_hours, save_to_folder, cohort_criteria_to_select, seed, cohort_unsupervised_filename, lstm_layer_size, epochs, learning_rate, use_cohort_inv_freq_weights, bootstrap, num_bootstrapped_samples, sensitivity)\u001b[0m\n\u001b[1;32m   1425\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics_df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohort != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and Cohort != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;66;03m# calculate micro metrics\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m all_auc, all_ppv, all_specificity \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohorts_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bootstrap_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_bootstrapped_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1430\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_auc\n\u001b[1;32m   1431\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPV\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_ppv\n",
      "File \u001b[0;32m~/Documents/repos/dl4h-sp23-team27-project/notebooks/../code/mtl_patients.py:952\u001b[0m, in \u001b[0;36mbootstrap_predict\u001b[0;34m(X_test, y_test, cohorts_test, task, model, tasks, num_bootstrap_samples, sensitivity)\u001b[0m\n\u001b[1;32m    949\u001b[0m     cohorts_bootstrap_sample_task \u001b[38;5;241m=\u001b[39m cohorts_bootstrap_sample\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# run prediction for the bootstrap sample\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m y_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap_sample_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_scores) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_bootstrap_sample_task):\n\u001b[1;32m    954\u001b[0m     y_scores \u001b[38;5;241m=\u001b[39m get_correct_task_mtl_outputs(y_scores, cohorts_bootstrap_sample_task, tasks)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_mtl_36_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=36, gap_hours=18, bootstrap=True,\n",
    "                                                                      cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_36.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd74593-7bef-48c1-ba78-c6114a5ea6b0",
   "metadata": {
    "id": "bfd74593-7bef-48c1-ba78-c6114a5ea6b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_mtl_36_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d467e8-64bd-4760-b740-b2ef4a81a030",
   "metadata": {
    "id": "93d467e8-64bd-4760-b740-b2ef4a81a030"
   },
   "source": [
    "#### 3.1.3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96e341-947e-478f-a0c7-dcee311bf307",
   "metadata": {
    "id": "be96e341-947e-478f-a0c7-dcee311bf307"
   },
   "source": [
    "Similar to Table 4 in paper, the dataframe below summarizes all results. Due to bootstrapping we will get 100 metric (AUC, PPV, or Specificity) values for every combination of experiment (36 hours), cohort type (careunits or unsupervised), and model type (global or multi-task. We will reduce that table in a next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d3f3e-6330-4c78-947f-f8aa3fe2b55b",
   "metadata": {
    "id": "7d6d3f3e-6330-4c78-947f-f8aa3fe2b55b"
   },
   "outputs": [],
   "source": [
    "# Load global and multitask dfs \n",
    "metrics_global_36_careunits_btstrp_df = pd.read_hdf('../data/results/model_global_36+18_careunits_bootstrap-ON.h5')\n",
    "metrics_global_36_unsupervised_btstrp_df = pd.read_hdf('../data/results/model_global_36+18_unsupervised_bootstrap-ON.h5')\n",
    "metrics_mtl_36_careunits_btstrp_df = pd.read_hdf('../data/results/model_multitask_36+18_careunits_bootstrap-ON.h5')\n",
    "metrics_mtl_36_unsupervised_btstrp_df = pd.read_hdf('../data/results/model_multitask_36+18_unsupervised_bootstrap-ON.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a245a-b426-4885-89cc-338aeb3dd619",
   "metadata": {
    "id": "6b8a245a-b426-4885-89cc-338aeb3dd619"
   },
   "outputs": [],
   "source": [
    "summary_a_btstrp_df = metrics_global_36_unsupervised_btstrp_df.reset_index()\n",
    "summary_a_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_a_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_a_btstrp_df['Model'] = 'Global'\n",
    "summary_a_btstrp_df['Experiment'] = '36 hours'\n",
    "\n",
    "summary_b_btstrp_df = metrics_global_36_careunits_btstrp_df.reset_index()\n",
    "summary_b_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_b_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_b_btstrp_df['Model'] = 'Global'\n",
    "summary_b_btstrp_df['Experiment'] = '36 hours'\n",
    "\n",
    "summary_c_btstrp_df = metrics_mtl_36_unsupervised_btstrp_df.reset_index()\n",
    "summary_c_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_c_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_c_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_c_btstrp_df['Experiment'] = '36 hours'\n",
    "\n",
    "summary_d_btstrp_df = metrics_mtl_36_careunits_btstrp_df.reset_index()\n",
    "summary_d_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_d_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_d_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_d_btstrp_df['Experiment'] = '36 hours'\n",
    "\n",
    "summary_36_btstrp_df = pd.concat([summary_a_btstrp_df, summary_b_btstrp_df, summary_c_btstrp_df, summary_d_btstrp_df])\n",
    "\n",
    "summary_btstrp_df = summary_36_btstrp_df\n",
    "\n",
    "# This is a trick using a categorical data type to have Macro and Micro after Cohort names while displaying\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cohort = CategoricalDtype(['0', '1', '2', 'CCU', 'CSRU', 'MICU', 'SICU', 'TSICU', 'Macro', 'Micro'], ordered=True)\n",
    "summary_btstrp_df['Cohort'] = summary_btstrp_df['Cohort'].astype(cohort)\n",
    "summary_btstrp_df = summary_btstrp_df.dropna()\n",
    "\n",
    "summary_btstrp_df = pd.melt(summary_btstrp_df, id_vars=['Cohort', 'Sample', 'Cohort type', 'Model', 'Experiment'], var_name='Metric')\n",
    "summary_btstrp_df = summary_btstrp_df.set_index(['Experiment', 'Cohort type', 'Cohort', 'Sample'])\n",
    "summary_btstrp_df = summary_btstrp_df.pivot(columns=['Metric', 'Model'], values='value')\n",
    "summary_btstrp_df = summary_btstrp_df.round(3)\n",
    "# Now summary_btstrp_df has all bootstrapped samples with right multi-indices for rows and columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dba52d-a5a5-4334-9250-1cce29f55065",
   "metadata": {
    "id": "29dba52d-a5a5-4334-9250-1cce29f55065"
   },
   "source": [
    "##### 3.1.3.1. Mean values of metrics from bootstrapped samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c87f18-b85e-461c-bdb4-0061f800bd91",
   "metadata": {
    "id": "30c87f18-b85e-461c-bdb4-0061f800bd91"
   },
   "source": [
    "Let's get the mean values of the 100 bootstrapped samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d228b-ef74-4685-bfef-9e66109445ee",
   "metadata": {
    "id": "404d228b-ef74-4685-bfef-9e66109445ee"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "summary_df = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).mean().round(3).dropna()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d8c9a-dfd8-402b-9657-15bc85cb0a59",
   "metadata": {
    "id": "e67d8c9a-dfd8-402b-9657-15bc85cb0a59"
   },
   "source": [
    "##### 3.1.3.2 Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3d152-1204-44fb-9d53-750239712492",
   "metadata": {
    "id": "fdf3d152-1204-44fb-9d53-750239712492"
   },
   "source": [
    "Now it is time to apply the Wilcoxon Signed-Rank Test. [This video](https://www.youtube.com/watch?v=v4ZHlTbTOK8) has a very good detailed explanation of the Wilcoxon Signed-Rank Test which is a non-parametric version of the paired t-test used when there are not many samples (which is our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dae71-aa7f-4956-b51a-ea3f51f0aa77",
   "metadata": {
    "id": "a72dae71-aa7f-4956-b51a-ea3f51f0aa77"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def calc_wilcoxon(grp_df, what):\n",
    "    if (what == 'auc'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('AUC', 'Global')]\n",
    "        y = grp_df[('AUC', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    if (what == 'ppv'):\n",
    "        # calculate p-value for PPV using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('PPV', 'Global')]\n",
    "        y = grp_df[('PPV', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "    \n",
    "    if (what == 'specificity'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed=Rank Test\n",
    "        x = grp_df[('Specificity', 'Global')]\n",
    "        y = grp_df[('Specificity', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373080a-62b1-47a2-ae13-bd5dd3433e7e",
   "metadata": {
    "id": "a373080a-62b1-47a2-ae13-bd5dd3433e7e"
   },
   "outputs": [],
   "source": [
    "summary_df.loc[:, ('AUC', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='auc')\n",
    "summary_df.loc[:, ('PPV', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='ppv')\n",
    "summary_df.loc[:, ('Specificity', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='specificity')\n",
    "cols = [('AUC', 'Global'), ('AUC', 'Multi-task'), ('AUC', 'p-value'),\n",
    "        ('PPV', 'Global'), ('PPV', 'Multi-task'), ('PPV', 'p-value'),\n",
    "        ('Specificity', 'Global'), ('Specificity', 'Multi-task'), ('Specificity', 'p-value')]\n",
    "summary_df = summary_df[cols]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9db64-0ea1-430f-bd7c-ad92c01d52d7",
   "metadata": {
    "id": "c7f9db64-0ea1-430f-bd7c-ad92c01d52d7"
   },
   "source": [
    "End time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc3686-2ce2-49db-be67-fb2d5b218ceb",
   "metadata": {
    "id": "3bcc3686-2ce2-49db-be67-fb2d5b218ceb"
   },
   "outputs": [],
   "source": [
    "# store/print end time to measure runtime\n",
    "endtime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f'End time: {endtime}')\n",
    "\n",
    "# store/print run time\n",
    "print(f'This run took {endtime - starttime} hours:min:sec to run')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
