{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cd5f07",
   "metadata": {},
   "source": [
    "# Testing Baseline with Bootstrapping (Global Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025cd50",
   "metadata": {},
   "source": [
    "Importing the functions needed from the `mtl_patients` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531ddfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 17:52:29.255112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "pathname = \"../code/\"\n",
    "if pathname not in sys.path:\n",
    "    sys.path.append(\"../code/\")\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950c754",
   "metadata": {},
   "source": [
    "## `run_mortality_prediction_task()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154f247",
   "metadata": {},
   "source": [
    "Let's run the mortality prediction task for the *global* model without bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "621b79f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n",
      "    Done!\n"
     ]
    }
   ],
   "source": [
    "metrics_df_with_no_bootstrapping = run_mortality_prediction_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f56b5521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCU</th>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.993457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>0.889536</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.997141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.988731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>0.853458</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.991407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>0.866083</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.993679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.860823</td>\n",
       "      <td>0.572829</td>\n",
       "      <td>0.992883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.992433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC       PPV  Specificity\n",
       "CCU    0.866500  0.666667     0.993457\n",
       "CSRU   0.889536  0.333333     0.997141\n",
       "MICU   0.828538  0.661765     0.988731\n",
       "SICU   0.853458  0.619048     0.991407\n",
       "TSICU  0.866083  0.583333     0.993679\n",
       "Macro  0.860823  0.572829     0.992883\n",
       "Micro  0.863960  0.632000     0.992433"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_with_no_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a07a9",
   "metadata": {},
   "source": [
    "Let's run the mortality prediction task for the *global* model with bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e8044cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_df_with_bootstrapping \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mortality_prediction_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My Drive/0 uiuc/CS 598 DLH/project/dl4h-sp23-team27-project/notebooks/../code/mtl_patients.py:1020\u001b[0m, in \u001b[0;36mrun_mortality_prediction_task\u001b[0;34m(model_type, cutoff_hours, gap_hours, save_to_folder, cohort_criteria_to_select, seed, cohort_unsupervised_filename, lstm_layer_size, epochs, learning_rate, use_cohort_inv_freq_weights, bootstrap, num_bootstrapped_samples)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;66;03m# calculate micro AUC\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m     all_auc \u001b[38;5;241m=\u001b[39m bootstrap_predict(X_test, y_test, cohorts_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, model,\n\u001b[1;32m   1019\u001b[0m                                 num_bootstrap_samples\u001b[38;5;241m=\u001b[39mnum_bootstrapped_samples)\n\u001b[0;32m-> 1020\u001b[0m     metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_auc\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# save results\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mto_hdf(results_filename, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1834\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_2d_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1900\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1898\u001b[0m value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;66;03m# setting with a list, re-coerces\u001b[39;00m\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(loc, value[:, i]\u001b[38;5;241m.\u001b[39mtolist(), pi)\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "metrics_df_with_bootstrapping = run_mortality_prediction_task(bootstrap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc3184",
   "metadata": {},
   "source": [
    "## `run_mortality_prediction_task()` step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d1149",
   "metadata": {},
   "source": [
    "### Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ecabcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b0ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtl_patients import set_global_determinism, prepare_data, stratified_split, create_single_task_learning_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ad1ec",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9c7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type='global'\n",
    "cutoff_hours=24\n",
    "gap_hours=12\n",
    "save_to_folder='../data/'\n",
    "cohort_criteria_to_select='careunits'\n",
    "seed=0\n",
    "cohort_unsupervised_filename='../data/unsupervised_clusters.npy'\n",
    "lstm_layer_size=16\n",
    "epochs=30\n",
    "learning_rate=0.0001\n",
    "use_cohort_inv_freq_weights=False\n",
    "bootstrap=False\n",
    "num_bootstrapped_samples=100\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50ebe8",
   "metadata": {},
   "source": [
    "### Code common to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca895b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n"
     ]
    }
   ],
   "source": [
    "# setting the seeds to get reproducible results\n",
    "# taken from https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\n",
    "set_global_determinism(seed=seed)\n",
    "\n",
    "# create folders to store models and results\n",
    "for folder in ['results', 'models']:\n",
    "    if not os.path.exists(os.path.join(save_to_folder, folder)):\n",
    "        os.makedirs(os.path.join(save_to_folder, folder))\n",
    "\n",
    "X, Y, careunits, sapsii_quartile, subject_ids = prepare_data(cutoff_hours=cutoff_hours, gap_hours=gap_hours)\n",
    "Y = Y.astype(int) # Y is originally a boolean\n",
    "\n",
    "print('+' * 80, flush=True)\n",
    "print('Running the Mortality Prediction Task', flush=True)\n",
    "print('-' * 80, flush=True)\n",
    "\n",
    "# fetch right cohort criteria\n",
    "if cohort_criteria_to_select == 'careunits':\n",
    "    cohort_criteria = careunits\n",
    "elif cohort_criteria_to_select == 'sapsii_quartile':\n",
    "    cohort_criteria = sapsii_quartile\n",
    "elif cohort_criteria_to_select == 'unsupervised':\n",
    "    cohort_criteria = np.load(f\"{cohort_unsupervised_filename}\")\n",
    "\n",
    "# Do train/validation/test split using `cohort_criteria` as the cohort classifier\n",
    "print('    Splitting data into train/validation/test sets...', flush=True)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, cohorts_train, cohorts_val, cohorts_test = \\\n",
    "    stratified_split(X, Y, cohort_criteria, train_val_random_seed=seed)\n",
    "\n",
    "# one task by distinct cohort\n",
    "tasks = np.unique(cohorts_train)\n",
    "\n",
    "# calculate number of samples per cohort and its reciprocal\n",
    "# (to be used in sample weight calculation)\n",
    "print('    Calculating number of training samples in cohort...', flush=True)\n",
    "task_weights = {}\n",
    "for cohort in tasks:\n",
    "    num_samples_in_cohort = len(np.where(cohorts_train == cohort)[0])\n",
    "    print(f\"        # of patients in cohort {cohort} is {str(num_samples_in_cohort)}\")\n",
    "    task_weights[cohort] = len(X_train) / num_samples_in_cohort\n",
    "\n",
    "sample_weight = None\n",
    "if use_cohort_inv_freq_weights:\n",
    "    # calculate sample weight as the cohort's inverse frequency corresponding to each sample\n",
    "    sample_weight = np.array([task_weights[cohort] for cohort in cohorts_train])\n",
    "\n",
    "model_filename = f\"{save_to_folder}models/model_{cutoff_hours}+{gap_hours}_{cohort_criteria_to_select}\"\n",
    "filename_part_bootstrap = \"bootstrap-ON\" if bootstrap else \"bootstrap-OFF\"\n",
    "results_filename = f'{save_to_folder}results/model_{cutoff_hours}+{gap_hours}_{cohort_criteria_to_select}_{filename_part_bootstrap}.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b967e8",
   "metadata": {},
   "source": [
    "### Global model common code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4118fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#-----------------------\n",
    "# train the global model\n",
    "\n",
    "print('    ' + '~' * 76)\n",
    "print(f\"    Training '{model_type}' model...\")\n",
    "\n",
    "model = create_single_task_learning_model(lstm_layer_size=lstm_layer_size, input_dims=X_train.shape[1:],\n",
    "                                          output_dims=1, learning_rate=learning_rate)\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=100, sample_weight=sample_weight,\n",
    "          callbacks=[early_stopping], validation_data=(X_val, y_val))\n",
    "model.save(model_filename)\n",
    "\n",
    "print('    ' + '~' * 76)\n",
    "print(f\"    Predicting using '{model_type}' model...\", flush=True)\n",
    "y_scores = np.squeeze(model.predict(X_test))\n",
    "y_pred = (y_scores > 0.5).astype(\"int32\")\n",
    "\n",
    "# calculate AUC, PPV, and Specificity for every cohort\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8156826/\n",
    "# https://stackoverflow.com/questions/56253863/precision-recall-and-confusion-matrix-problems-in-sklearn\n",
    "# https://stackoverflow.com/questions/33275461/specificity-in-scikit-learn\n",
    "# PPV (Predictive Positive Value) is same as precision\n",
    "# Specificity is same as recall of the negative class... using that trick to get it in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d73eae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.21it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[1;32m      8\u001b[0m     all_auc \u001b[38;5;241m=\u001b[39m bootstrap_predict(X_test, y_test, cohorts_test, task, model,\n\u001b[1;32m      9\u001b[0m                                 num_bootstrap_samples\u001b[38;5;241m=\u001b[39mnum_bootstrapped_samples)\n\u001b[0;32m---> 10\u001b[0m     metrics_df\u001b[38;5;241m.\u001b[39mloc[task, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_auc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1834\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_2d_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1900\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1898\u001b[0m value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;66;03m# setting with a list, re-coerces\u001b[39;00m\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(loc, value[:, i]\u001b[38;5;241m.\u001b[39mtolist(), pi)\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "# get `num_bootstrapped_samples` and calculate AUC, PPV, and specificity\n",
    "\n",
    "lst_of_tasks = list(tasks)\n",
    "lst_of_tasks.append('Micro')\n",
    "\n",
    "idx = pd.MultiIndex.from_product([lst_of_tasks, list(np.arange(1, 101))], names=['Cohort', 'Sample'])\n",
    "metrics_df = pd.DataFrame(index=idx, columns=['AUC', 'PPV', 'Specificity'])\n",
    "\n",
    "for task in tasks:\n",
    "    all_auc, all_ppv, all_specificity = bootstrap_predict(X_test, y_test, cohorts_test, task, model,\n",
    "                                num_bootstrap_samples=num_bootstrapped_samples)\n",
    "    metrics_df.loc[task, 'AUC'] = all_auc\n",
    "    metrics_df.loc[task, 'PPV'] = all_ppv\n",
    "    metrics_df.loc[task, 'Specificity'] = all_specificity\n",
    "\n",
    "# calculate macro AUC\n",
    "metrics_df.loc['Macro', :] = metrics_df.query(\"Cohort != 'Micro'\").mean()\n",
    "\n",
    "# calculate micro AUC\n",
    "all_auc, all_ppv, all_specificity = bootstrap_predict(X_test, y_test, cohorts_test, 'all', model,\n",
    "                            num_bootstrap_samples=num_bootstrapped_samples)\n",
    "metrics_df.loc['Micro', 'AUC'] = all_auc\n",
    "metrics_df.loc['Micro', 'PPV'] = all_ppv\n",
    "metrics_df.loc['Micro', 'Specificity'] = all_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b96d4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCU'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ae85377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9924812030075187,\n",
       " 0.9896694214876033,\n",
       " 0.9944629014396457,\n",
       " 0.9916054564533053,\n",
       " 0.9946236559139785,\n",
       " 0.9870689655172413,\n",
       " 0.9945295404814004,\n",
       " 0.9943502824858758,\n",
       " 0.9903640256959315,\n",
       " 0.9947478991596639,\n",
       " 0.9933184855233853,\n",
       " 0.9946409431939979,\n",
       " 0.9924650161463939,\n",
       " 0.9946466809421841,\n",
       " 0.9947916666666666,\n",
       " 0.9896587383660806,\n",
       " 0.9884453781512605,\n",
       " 0.9968553459119497,\n",
       " 0.9935205183585313,\n",
       " 0.9919816723940436,\n",
       " 0.9957582184517497,\n",
       " 0.9957537154989384,\n",
       " 0.9977777777777778,\n",
       " 0.9933847850055126,\n",
       " 0.9925053533190579,\n",
       " 0.9914984059511158,\n",
       " 0.99235807860262,\n",
       " 0.9956188389923329,\n",
       " 0.9954337899543378,\n",
       " 0.9912568306010929,\n",
       " 0.9934065934065934,\n",
       " 0.9945235487404163,\n",
       " 0.9967032967032967,\n",
       " 0.9892933618843683,\n",
       " 0.9933259176863182,\n",
       " 0.9888765294771968,\n",
       " 0.9914163090128756,\n",
       " 0.9935965848452508,\n",
       " 0.990228013029316,\n",
       " 0.9915433403805497,\n",
       " 0.9919908466819222,\n",
       " 0.9920814479638009,\n",
       " 0.9955307262569832,\n",
       " 0.9918981481481481,\n",
       " 0.9935760171306209,\n",
       " 0.995418098510882,\n",
       " 0.992399565689468,\n",
       " 0.9915343915343915,\n",
       " 0.9967602591792657,\n",
       " 0.9922048997772829,\n",
       " 0.9946865037194474,\n",
       " 0.9958333333333333,\n",
       " 0.9920544835414302,\n",
       " 0.992964824120603,\n",
       " 0.9926238145416227,\n",
       " 0.9957761351636748,\n",
       " 0.9967213114754099,\n",
       " 0.9954022988505747,\n",
       " 0.9915700737618546,\n",
       " 0.9911894273127754,\n",
       " 0.9934569247546347,\n",
       " 0.9914346895074947,\n",
       " 0.9922566371681416,\n",
       " 0.9922822491730982,\n",
       " 0.9967069154774972,\n",
       " 0.9884526558891455,\n",
       " 0.9915433403805497,\n",
       " 0.990506329113924,\n",
       " 0.9924406047516199,\n",
       " 0.9947643979057592,\n",
       " 0.98914223669924,\n",
       " 0.9915522703273495,\n",
       " 0.9927385892116183,\n",
       " 0.9957035445757251,\n",
       " 0.9942922374429224,\n",
       " 0.986562150055991,\n",
       " 0.9955801104972376,\n",
       " 0.9947423764458465,\n",
       " 0.9956379498364231,\n",
       " 0.9977246871444824,\n",
       " 0.9923497267759562,\n",
       " 0.9933333333333333,\n",
       " 0.9922651933701657,\n",
       " 0.995656894679696,\n",
       " 0.9925611052072264,\n",
       " 0.9909502262443439,\n",
       " 0.987152034261242,\n",
       " 0.997872340425532,\n",
       " 0.9935205183585313,\n",
       " 0.9928205128205129,\n",
       " 0.9934640522875817,\n",
       " 0.9988998899889989,\n",
       " 0.991332611050921,\n",
       " 0.9922394678492239,\n",
       " 0.9977246871444824,\n",
       " 0.9864300626304802,\n",
       " 0.9890230515916575,\n",
       " 0.9936575052854123,\n",
       " 0.9906868451688009,\n",
       " 0.9977653631284916]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_auc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8ce77066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "5      NaN\n",
       "      ... \n",
       "96     NaN\n",
       "97     NaN\n",
       "98     NaN\n",
       "99     NaN\n",
       "100    NaN\n",
       "Name: AUC, Length: 100, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.loc[task, 'AUC'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0cb74f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Micro</th>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  PPV Specificity\n",
       "Cohort Sample                      \n",
       "CCU    1       NaN  NaN         NaN\n",
       "       2       NaN  NaN         NaN\n",
       "       3       NaN  NaN         NaN\n",
       "       4       NaN  NaN         NaN\n",
       "       5       NaN  NaN         NaN\n",
       "...            ...  ...         ...\n",
       "Micro  96      NaN  NaN         NaN\n",
       "       97      NaN  NaN         NaN\n",
       "       98      NaN  NaN         NaN\n",
       "       99      NaN  NaN         NaN\n",
       "       100     NaN  NaN         NaN\n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffba104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtl_patients import bootstrap_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca230cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCU', 'CSRU', 'MICU', 'SICU', 'TSICU'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2090047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:43<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "task = 'all'\n",
    "all_auc, all_ppv, all_specificity = bootstrap_predict(X_test, y_test, cohorts_test, task, model, num_bootstrap_samples=num_bootstrapped_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0451b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
