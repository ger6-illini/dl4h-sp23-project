{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652e22f4",
   "metadata": {},
   "source": [
    "<h1><center>CS598 Deep Learning for Healthcare Spring 2023<br>Paper Reproduction Project</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5cbba",
   "metadata": {},
   "source": [
    "<h3><center>Gilberto Ramirez and Jay Kakwani<br><span style=\"font-family:monospace;\">{ger6, kakwani2}@illinois.edu</span><br><font color=\"lightgrey\">Group ID: 27 | Paper ID: 181</font></center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e806a3-50ce-4a02-aabc-83b3004868d1",
   "metadata": {},
   "source": [
    "### Ablation Study :  18 hours (cutoff period) + 9 hours (gap period)\n",
    "\n",
    "In this ablation study, we will process and run ablation for 18 hour ICU Stay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cc966",
   "metadata": {},
   "source": [
    "In this project, we aim to reproduce the paper [*Learning Task for Multitask Learning: Heterogeneous Patient Populations in the ICU* by (Suresh et al, 2018)](https://arxiv.org/abs/1806.02878). In this paper, the authors propose a novel two-step pipeline to predict in-hospital mortality across patient populations with different characteristics. The first step of the pipeline divides patients into relevant non-overlapping cohorts in an unsupervised way using a long short-term memory (LSTM) autoencoder followed by a Gaussian Mixture Model (GMM). The second step of the pipeline predicts in-hospital mortality for each patient cohort identified in the previous step using an LSTM based multi-task learning model where every cohort is considered a different task.\n",
    "The paper claims that by applying this pipeline there will be better predictive results when compared to a model applied to the aggregate population using a single task learning model. According to the authors, the better performance given by this pipeline is due to the combination of a multi-task learning model leveraging shared knowledge across distinct patient groups and the way how those groups were created, i.e., identification using a data-driven method rather than relying on domain knowledge or auxiliary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e318a",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58470c",
   "metadata": {},
   "source": [
    "This paper uses the publicly available [MIMIC-III database](https://www.nature.com/articles/sdata201635) which contains clinical data in a critical care setting. After reviewing the paper in detail, we decided to use [MIMIC-Extract](https://arxiv.org/abs/1907.08322), an open source pipeline by (Wang et al., 2020) for transforming the raw EHR data into usable [Pandas](https://pandas.pydata.org/) dataframes containing hourly time series of vitals and laboratory measurements after performing unit conversion, outlier handling, and aggregation of semantically similar features.\n",
    "\n",
    "Unfortunately, the MIMIC-Extract pipeline misses two features the [paper code](https://github.com/mit-caml/multitask-patients) makes use of:\n",
    "* `timecmo_chart` which indicates the timestamp of a patient after being declared in CMO (Comfort Measures Only) state. This feature comes from a MIMIC-III concept table called `code_status`.\n",
    "* `sapsii` which contains the SAPS (Simplified Acute Physiology Score) II for the patient. This feature comes from another MIMIC-III concept table called `sapsii`.\n",
    "\n",
    "As a result, there are three data files needed to run this notebook:\n",
    "* `all_hourly_data.h5`, an HDF file resulting from running the MIMIC-Extract pipeline which is publicly available in GCP using [this link](https://console.cloud.google.com/storage/browser/mimic_extract) and referenced in the [MIMIC-Extract github repo](https://github.com/MLforHealth/MIMIC_Extract).\n",
    "* `code_status.csv`, a CSV file holding the MIMIC concept table `CODE_STATUS` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "* `sapsii.csv`, a CSV file holding the MIMIC concept table `SAPSII` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "\n",
    "The functions used in this notebook assume the three files listed above are in the folder `../data/` by default. However, location can be changed using arguments to the functions that process the data.\n",
    "\n",
    "All code needed to replicate the paper is in [our github repo](https://github.com/ger6-illini/dl4h-sp23-team27-project) inside a Python module called `mtl_patients`.\n",
    "\n",
    "The first function from that module we will start using is `get_summaries()`. This function returns three summaries as dataframes:\n",
    "1. A summary providing some statistics of all patients broken by careunit.\n",
    "2. A summary providing some statistics of all patients broken by SAPS-II score quartile.\n",
    "3. A summary providing some statistics of the 29 distinct physiological measurements used in the paper.\n",
    "\n",
    "These summaries need two arguments to be created:\n",
    "* `cutoff_hours` (default 24) which is the minimum number of hours a patient needs to stay in the ICU to be considered part of a cohort.\n",
    "* `gap_hours` (default 12) which is the number of hours between the end of `cutoff_hours` and the moment a model can start making a mortality prediction.\n",
    "\n",
    "The importance of these two arguments is his impact in the exception criteria used in the paper. In particular, the paper:\n",
    "1. Excludes all patients that met the in-hospital mortality criteria before `cutoff period` + `gap period`.\n",
    "2. Excludes patients that were discharged before `cutoff period` + `gap period`.\n",
    "\n",
    "The in-hospital mortality criteria used in the paper is an extended one and not just considers patients who died but also patients with a CMO (Comfort Measures Only) note. That is considered in the summaries creation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f3462",
   "metadata": {},
   "source": [
    "### 1.1. Summaries, 18 hours (cutoff period) + 9 hours (gap period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493677c",
   "metadata": {},
   "source": [
    "Now let's run the `get_summaries()` function with `cutoff_hours` = 18 and `gap_hours` = 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b6c0d1-0a31-46ce-abcb-2a8c3582dec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:26:50.151339Z",
     "iopub.status.busy": "2023-04-11T03:26:50.149577Z",
     "iopub.status.idle": "2023-04-11T03:26:50.169783Z",
     "shell.execute_reply": "2023-04-11T03:26:50.168430Z",
     "shell.execute_reply.started": "2023-04-11T03:26:50.151339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 11/04/2023 03:26:50\n"
     ]
    }
   ],
   "source": [
    "# store/print start time to measure runtime\n",
    "from datetime import datetime\n",
    "starttime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f'Start time: {starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475bac15-872d-4bac-93f5-598314107b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tables\n",
      "  Downloading tables-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tables) (23.0)\n",
      "Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.9/dist-packages (from tables) (0.29.32)\n",
      "Collecting blosc2~=2.0.0\n",
      "  Downloading blosc2-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numexpr>=2.6.2\n",
      "  Downloading numexpr-2.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (380 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.7/380.7 kB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from tables) (1.23.4)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from blosc2~=2.0.0->tables) (1.0.4)\n",
      "Installing collected packages: py-cpuinfo, numexpr, blosc2, tables\n",
      "Successfully installed blosc2-2.0.0 numexpr-2.8.4 py-cpuinfo-9.0.0 tables-3.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install `pytables` using `pip` if running from Paperspace since TensorFlow image does not have it\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d024700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "pathname = \"../code/\"\n",
    "if pathname not in sys.path:\n",
    "    sys.path.append(\"../code/\")\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "from mtl_patients import get_summaries\n",
    "from mtl_patients import discover_cohorts\n",
    "from mtl_patients import run_mortality_prediction_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04a5c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:27:32.590801Z",
     "iopub.status.busy": "2023-04-11T03:27:32.589747Z",
     "iopub.status.idle": "2023-04-11T03:28:01.694092Z",
     "shell.execute_reply": "2023-04-11T03:28:01.692161Z",
     "shell.execute_reply.started": "2023-04-11T03:27:32.590750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Creating summaries\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Merging dataframes to create X_full...\n",
      "    Creating summary by careunit...\n",
      "    Creating summary by SAPS II score quartile...\n",
      "    Creating summary by vitals/labs...\n",
      "    Done!\n",
      "CPU times: user 17.6 s, sys: 7.63 s, total: 25.3 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pat_summ_18_by_cu_df, pat_summ_18_by_sapsiiq_df, vitals_labs_summ_18_df = get_summaries(cutoff_hours=18, gap_hours=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcc93e",
   "metadata": {},
   "source": [
    "Let's now display the resulting summaries one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48560",
   "metadata": {},
   "source": [
    "#### 1.1.1. Data summary by patients in each intensive care unit (ICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451bdc7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:28:09.359854Z",
     "iopub.status.busy": "2023-04-11T03:28:09.359312Z",
     "iopub.status.idle": "2023-04-11T03:28:09.434898Z",
     "shell.execute_reply": "2023-04-11T03:28:09.433873Z",
     "shell.execute_reply.started": "2023-04-11T03:28:09.359818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>Class Imbalance</th>\n",
       "      <th>Age (Mean)</th>\n",
       "      <th>Gender (Male)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Careunit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCU</th>\n",
       "      <td>5030</td>\n",
       "      <td>365</td>\n",
       "      <td>0.073</td>\n",
       "      <td>82.40</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>7001</td>\n",
       "      <td>151</td>\n",
       "      <td>0.022</td>\n",
       "      <td>69.50</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>11636</td>\n",
       "      <td>1205</td>\n",
       "      <td>0.104</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>5271</td>\n",
       "      <td>443</td>\n",
       "      <td>0.084</td>\n",
       "      <td>72.64</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>4324</td>\n",
       "      <td>315</td>\n",
       "      <td>0.073</td>\n",
       "      <td>67.16</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>33262</td>\n",
       "      <td>2479</td>\n",
       "      <td>0.075</td>\n",
       "      <td>74.53</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              N     n  Class Imbalance  Age (Mean)  Gender (Male)\n",
       "Careunit                                                         \n",
       "CCU        5030   365            0.073       82.40           0.58\n",
       "CSRU       7001   151            0.022       69.50           0.67\n",
       "MICU      11636  1205            0.104       77.75           0.51\n",
       "SICU       5271   443            0.084       72.64           0.52\n",
       "TSICU      4324   315            0.073       67.16           0.60\n",
       "Overall   33262  2479            0.075       74.53           0.57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_summ_18_by_cu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dff829",
   "metadata": {},
   "source": [
    "In the previous summary, patients were broken in groups where each group is one of five careunits where patients were first admitted:\n",
    "* CCU: Coronary Care Unit\n",
    "* CSRU: Cardiac Surgery Recovery Unit\n",
    "* MICU: Medical Intensive Care Unit\n",
    "* SICU: Surgical Intensive Care Unit\n",
    "* TSICU: Trauma Surgical Intensive Care Unit\n",
    "\n",
    "In addition, an overall group was also added. The statistics provided by the summary are:\n",
    "* `N`: The number of samples (patients) in the group.\n",
    "* `n`: The number of samples (patients) meeting the in-hospital mortality criteria defined in the paper: patient died or had a note of \"Do Not Resuscitate\" (DNR) or had a note of \"Comfort Measures Only\" (CMO).\n",
    "* `Class Imbalance`: Ratio of patients meeting the in-hospital mortality criteria defined in the paper, i.e., $\\dfrac{\\text{n}}{\\text{N}}$.\n",
    "* `Age (Mean)`: Mean age of patients for each group in years.\n",
    "* `Gender (Male)`: Ratio of patients that are males.\n",
    "\n",
    "This summary was prepared to match Table 1 in the original paper. There are differences between both that can be attributed to the way how data was preprocessed by MIMIC-Extract when compared to the preprocessing done by the authors back in 2018, before MIMIC-Extract became available, and that was not made available by the authors in [their code](https://github.com/mit-caml/multitask-patients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a8e12",
   "metadata": {},
   "source": [
    "#### 1.1.2. Data summary by patients in each SAPS-II score quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1474f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:28:14.891074Z",
     "iopub.status.busy": "2023-04-11T03:28:14.890439Z",
     "iopub.status.idle": "2023-04-11T03:28:14.978547Z",
     "shell.execute_reply": "2023-04-11T03:28:14.977393Z",
     "shell.execute_reply.started": "2023-04-11T03:28:14.891036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "      <th>Class Imbalance</th>\n",
       "      <th>Age (Mean)</th>\n",
       "      <th>Gender (Male)</th>\n",
       "      <th>SAPS II (Min)</th>\n",
       "      <th>SAPS II (Mean)</th>\n",
       "      <th>SAPS II (Max)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAPS II Quartile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7280</td>\n",
       "      <td>64</td>\n",
       "      <td>0.009</td>\n",
       "      <td>45.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10170</td>\n",
       "      <td>271</td>\n",
       "      <td>0.027</td>\n",
       "      <td>68.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>23</td>\n",
       "      <td>27.74</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8201</td>\n",
       "      <td>575</td>\n",
       "      <td>0.070</td>\n",
       "      <td>86.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>33</td>\n",
       "      <td>36.72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7611</td>\n",
       "      <td>1569</td>\n",
       "      <td>0.206</td>\n",
       "      <td>96.74</td>\n",
       "      <td>0.54</td>\n",
       "      <td>42</td>\n",
       "      <td>51.58</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>33262</td>\n",
       "      <td>2479</td>\n",
       "      <td>0.075</td>\n",
       "      <td>74.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>32.97</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      N     n  Class Imbalance  Age (Mean)  Gender (Male)  \\\n",
       "SAPS II Quartile                                                            \n",
       "0                  7280    64            0.009       45.67           0.61   \n",
       "1                 10170   271            0.027       68.87           0.58   \n",
       "2                  8201   575            0.070       86.57           0.55   \n",
       "3                  7611  1569            0.206       96.74           0.54   \n",
       "Overall           33262  2479            0.075       74.53           0.57   \n",
       "\n",
       "                  SAPS II (Min)  SAPS II (Mean)  SAPS II (Max)  \n",
       "SAPS II Quartile                                                \n",
       "0                             0           16.60             22  \n",
       "1                            23           27.74             32  \n",
       "2                            33           36.72             41  \n",
       "3                            42           51.58            118  \n",
       "Overall                       0           32.97            118  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_summ_18_by_sapsiiq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711c274",
   "metadata": {},
   "source": [
    "In the previous summary, patients were broken based on the quartile of the SAPS-II score assigned to them. As it can be seen, the four quartiles have the ranges $[0, 22], [23, 32], [33, 41], [42, 118] $. This was included in the authors code but not in the paper. It seems the class imbalance might have been the primary reason. As it is evident from the summary, most of the patients are in quartile $3$ since they are in an ICU and is expected their values are on the high side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0959c",
   "metadata": {},
   "source": [
    "#### 1.1.3. Data summary for physiological measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2e18ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:28:18.179944Z",
     "iopub.status.busy": "2023-04-11T03:28:18.179330Z",
     "iopub.status.idle": "2023-04-11T03:28:18.270255Z",
     "shell.execute_reply": "2023-04-11T03:28:18.268764Z",
     "shell.execute_reply.started": "2023-04-11T03:28:18.179899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>N</th>\n",
       "      <th>pres.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anion gap</th>\n",
       "      <td>5.00</td>\n",
       "      <td>13.64</td>\n",
       "      <td>50.00</td>\n",
       "      <td>3.89</td>\n",
       "      <td>180116</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>24.30</td>\n",
       "      <td>53.00</td>\n",
       "      <td>4.69</td>\n",
       "      <td>188876</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood urea nitrogen</th>\n",
       "      <td>0.00</td>\n",
       "      <td>26.07</td>\n",
       "      <td>250.00</td>\n",
       "      <td>21.64</td>\n",
       "      <td>190791</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>50.00</td>\n",
       "      <td>105.19</td>\n",
       "      <td>175.00</td>\n",
       "      <td>6.27</td>\n",
       "      <td>207455</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.39</td>\n",
       "      <td>46.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>191614</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diastolic blood pressure</th>\n",
       "      <td>0.00</td>\n",
       "      <td>60.95</td>\n",
       "      <td>307.00</td>\n",
       "      <td>14.09</td>\n",
       "      <td>1878856</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction inspired oxygen</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>96405</td>\n",
       "      <td>0.0446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glascow coma scale total</th>\n",
       "      <td>3.00</td>\n",
       "      <td>12.58</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3.52</td>\n",
       "      <td>369777</td>\n",
       "      <td>0.1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>33.00</td>\n",
       "      <td>140.15</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>56.60</td>\n",
       "      <td>505609</td>\n",
       "      <td>0.2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart rate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>84.89</td>\n",
       "      <td>300.00</td>\n",
       "      <td>17.16</td>\n",
       "      <td>1939794</td>\n",
       "      <td>0.8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hematocrit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>30.99</td>\n",
       "      <td>71.70</td>\n",
       "      <td>5.32</td>\n",
       "      <td>249595</td>\n",
       "      <td>0.1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>22.10</td>\n",
       "      <td>1.89</td>\n",
       "      <td>201568</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>0.40</td>\n",
       "      <td>2.57</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2.47</td>\n",
       "      <td>58835</td>\n",
       "      <td>0.0272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnesium</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>177836</td>\n",
       "      <td>0.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean blood pressure</th>\n",
       "      <td>14.00</td>\n",
       "      <td>79.44</td>\n",
       "      <td>330.00</td>\n",
       "      <td>15.43</td>\n",
       "      <td>1869606</td>\n",
       "      <td>0.8653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxygen saturation</th>\n",
       "      <td>0.00</td>\n",
       "      <td>96.76</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1854539</td>\n",
       "      <td>0.8583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial thromboplastin time</th>\n",
       "      <td>18.80</td>\n",
       "      <td>41.07</td>\n",
       "      <td>150.00</td>\n",
       "      <td>24.45</td>\n",
       "      <td>132792</td>\n",
       "      <td>0.0615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>6.50</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>196513</td>\n",
       "      <td>0.0910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phosphate</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3.47</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>116166</td>\n",
       "      <td>0.0538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelets</th>\n",
       "      <td>0.00</td>\n",
       "      <td>204.97</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>113.33</td>\n",
       "      <td>183063</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>0.80</td>\n",
       "      <td>4.13</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>231593</td>\n",
       "      <td>0.1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prothrombin time inr</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>88.80</td>\n",
       "      <td>1.22</td>\n",
       "      <td>126270</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prothrombin time pt</th>\n",
       "      <td>2.39</td>\n",
       "      <td>15.93</td>\n",
       "      <td>150.00</td>\n",
       "      <td>6.88</td>\n",
       "      <td>126244</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respiratory rate</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>300.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1909402</td>\n",
       "      <td>0.8837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>50.00</td>\n",
       "      <td>138.59</td>\n",
       "      <td>225.00</td>\n",
       "      <td>5.24</td>\n",
       "      <td>219039</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systolic blood pressure</th>\n",
       "      <td>0.00</td>\n",
       "      <td>121.97</td>\n",
       "      <td>311.00</td>\n",
       "      <td>21.86</td>\n",
       "      <td>1879300</td>\n",
       "      <td>0.8698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>26.00</td>\n",
       "      <td>36.98</td>\n",
       "      <td>42.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>638921</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.00</td>\n",
       "      <td>83.22</td>\n",
       "      <td>250.00</td>\n",
       "      <td>23.39</td>\n",
       "      <td>60567</td>\n",
       "      <td>0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white blood cell count</th>\n",
       "      <td>0.10</td>\n",
       "      <td>11.88</td>\n",
       "      <td>939.00</td>\n",
       "      <td>9.64</td>\n",
       "      <td>175400</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               min     avg      max     std        N   pres.\n",
       "variable                                                                    \n",
       "anion gap                     5.00   13.64    50.00    3.89   180116  0.0834\n",
       "bicarbonate                   0.00   24.30    53.00    4.69   188876  0.0874\n",
       "blood urea nitrogen           0.00   26.07   250.00   21.64   190791  0.0883\n",
       "chloride                     50.00  105.19   175.00    6.27   207455  0.0960\n",
       "creatinine                    0.10    1.39    46.60    1.48   191614  0.0887\n",
       "diastolic blood pressure      0.00   60.95   307.00   14.09  1878856  0.8696\n",
       "fraction inspired oxygen      0.21    0.53     1.00    0.19    96405  0.0446\n",
       "glascow coma scale total      3.00   12.58    15.00    3.52   369777  0.1711\n",
       "glucose                      33.00  140.15  1591.00   56.60   505609  0.2340\n",
       "heart rate                    0.00   84.89   300.00   17.16  1939794  0.8978\n",
       "hematocrit                    0.00   30.99    71.70    5.32   249595  0.1155\n",
       "hemoglobin                    0.00   10.64    22.10    1.89   201568  0.0933\n",
       "lactate                       0.40    2.57    30.00    2.47    58835  0.0272\n",
       "magnesium                     0.00    2.05    20.00    0.41   177836  0.0823\n",
       "mean blood pressure          14.00   79.44   330.00   15.43  1869606  0.8653\n",
       "oxygen saturation             0.00   96.76   100.00    3.45  1854539  0.8583\n",
       "partial thromboplastin time  18.80   41.07   150.00   24.45   132792  0.0615\n",
       "ph                            6.50    7.38     8.40    0.08   196513  0.0910\n",
       "phosphate                     0.50    3.47    20.00    1.40   116166  0.0538\n",
       "platelets                     0.00  204.97  2000.00  113.33   183063  0.0847\n",
       "potassium                     0.80    4.13    12.00    0.64   231593  0.1072\n",
       "prothrombin time inr          0.50    1.51    88.80    1.22   126270  0.0584\n",
       "prothrombin time pt           2.39   15.93   150.00    6.88   126244  0.0584\n",
       "respiratory rate              0.00   19.09   300.00    5.70  1909402  0.8837\n",
       "sodium                       50.00  138.59   225.00    5.24   219039  0.1014\n",
       "systolic blood pressure       0.00  121.97   311.00   21.86  1879300  0.8698\n",
       "temperature                  26.00   36.98    42.22    0.78   638921  0.2957\n",
       "weight                        0.00   83.22   250.00   23.39    60567  0.0280\n",
       "white blood cell count        0.10   11.88   939.00    9.64   175400  0.0812"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitals_labs_summ_18_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cab69",
   "metadata": {},
   "source": [
    "In the previous summary, all vitals and lab measurements selected in the paper (29 in total) are listed with relevant statistics associated to it:\n",
    "* `min` representing the minimum of the measurement observed in the vitals/labs.\n",
    "* `avg` representing the average of the measurement observed in the vitals/labs.\n",
    "* `max` representing the maximum of the measurement observed in the vitals/labs.\n",
    "* `std` representing the standard deviation of the measurement observed in the vitals/labs.\n",
    "* `N` representing the number of non `NaN` samples for the specific vital/lab measurement.\n",
    "* `pres.` representing the portion of all possible hours across all patients, admissions, and ICU stays where at least one of the 104 vitals/labs measurements in the original MIMIC-Extract pipeline was taken.\n",
    "\n",
    "All these measurements are based on the `vitals_labs_mean` dataframe in the MIMIC-Extract pipeline which provides average of vitals/labs on a per hour basis for each patient after going into an ICU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b21a0",
   "metadata": {},
   "source": [
    "## 2. Discovering Patient Cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a385d",
   "metadata": {},
   "source": [
    "The paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the first step of the pipeline, i.e., patient cohort discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac0335",
   "metadata": {},
   "source": [
    "In order to identify meaningful patient cohorts, the paper proposes to process the raw patient data in such a way that the result is a 3D matrix of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features as depicted in the figure below (in blue) which is partially based on Figure 2 of the original paper. All numbers shown in the figure below correspond to a specific experiment published in the paper in which the observation window is limited to the first $24$ hours (cutoff period) after a patient goes into a careunit and there is a gap of $12$ hours (gap period) between the end of the observation window and the beginning of the prediction window where the prediction task is in-hospital mortality.\n",
    "\n",
    "Preparation of the data to get the 3D (blue) matrix is performed by a function called `prepare_data()` inside the `mtl_patients.py` module. This preparation consists of the following transformations taken from the paper and the author's code reference implementation:\n",
    "1. Calculation of the mortality flag (prediction label) and mortality time for every patient in the dataset using an *extended* definition of mortality: death, a note of \"Do Not Resuscitate\" (DNR), or a note of \"Comfort Measures Only\" (CMO). In case any of these conditions are met for a patient, the corresponding mortality label is set to *True* and the corresponding mortality time is considered as the earliest time of any of the three conditions. After reviewing in detail the author's code implementation it seems mortality is based on deathtime and a CMO note but not DNR. However, the calculation of the time of death is based on the earliest time of the three conditions.\n",
    "2. Data used for the prediction is only limited to the first certain amount of hours after a patient goes into the ICU. This amount of hours is called inside the code \"a cutoff period\" (observation window) and defines the period of data used to train all models. In addition, there is another number of hours called inside the code \"the gap period\" which represents the time between the end of the observation window and the beginning of the prediction window to prevent label leakage. All patients that died under the *extended* definition before the cutoff period plus the gap period or stayed less than the cutoff period are excluded from the experiment as part of this step. Also, all patients under the age of 15 are excluded (this is already part of the exclusion criteria of the MIMIC-Extract pipeline).\n",
    "3. There are 29 vitals/labs timeseries selected by the paper. Only data within the cutoff period for vitals/labs is kept and rest is removed. This will be used for the rest of the machine learning pipeline.\n",
    "4. All vitals/labs values are converted to z-scores so they all have zero mean and unit standard deviation. Those z-scores are rounded to the closest integer and clipped between $-4$ and $4$ or set to $9$ in case of `NaN`. This allows to map every vital/lab measurement (a float) to one of ten possible values $[-4, -3, -2, -1, 0, 1, 2, 3, 4, 9]$, so they can be converted to dummy values. After dummifying the vitals/labs, column for the $9$ values (`NaN`) is removed, and the resulting matrix is sparse and containing either $0$s or $1$s.\n",
    "5. Every patient is padded with rows of zeroes for those hours that are missed. For example, if a patient only has vitals/labs for the first ten hours and the cutoff period is 24, code adds fourteen hours (rows) with zeroes for that patient. In the end, the matrix will have a size of $P \\times T \\times F$ as expected by the subsequent models.\n",
    "6. Finally, static data (gender, age, and ethnicity) is converted to integers representing categories and dummified. In case of age, there are four buckets established; $(10, 30), (30, 50), (50, 70), (70, \\infty)$; while ethnicity is broken into five buckets (asian, white, hispanic, black, other).\n",
    "7. Cohort assignments based on first careunit or Simplified Acute Physiology Score (SAPS) II score quartile is calculated for each patient and returned as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d014e8",
   "metadata": {},
   "source": [
    "![Figure 1](../img/paper-181-fig-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a251",
   "metadata": {},
   "source": [
    "The `discover_cohorts()` function inside the `mtl_patients.py` module is the one implementing the pipeline shown in the figure above and then calling the `prepare_data()` function detailed previously as the first step. Once data has been processed, the function will break the data in training, validation, and test data sets in a $70\\%/10\\%/20\\%$ proportion.\n",
    "\n",
    "The training data is used to train an LSTM autoencoder. The main purpose of the LSTM autoencoder is to generate a fixed-length dense representation (embedding) of the sparse inputs trying to retain the most important parts of the inputs. The paper selected embeddings of size $50$ as the optimal dimension (hyperparameter). The purple box in the middle of the diagram above (a 2D matrix) represents the embeddings after the LSTM autoencoder learned the representation of the original 3D matrix of shape $(32537 \\times 24 \\times 232)$ where every row corresponds to a patient.\n",
    "\n",
    "Once the embeddings are calculated, a Gaussian Mixture Model is applied using $3$ clusters (the value the authors considered optimal). The result are the three green boxes representing three cohorts discovered in an unsupervised way and grouping similar patients based on the three static and the 29 time-varying vitals/labs selected from the MIMIC-III database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa284f2-7c60-42ae-a9f7-80b5236438fc",
   "metadata": {},
   "source": [
    "### 2.1. Cohort statistics at 18 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc972ff9-3e4b-4c88-b942-f267162c0b34",
   "metadata": {},
   "source": [
    "The paper runs two experiments. The first experiment uses a cutoff period of 18 hours, a gap period of 9 hours, and three clusters. Let's run this first experiment using the `discover_cohorts()` function and determine the corresponding cohort assignment for every patient that does not meet the exception criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81181566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:28:58.645379Z",
     "iopub.status.busy": "2023-04-11T03:28:58.644999Z",
     "iopub.status.idle": "2023-04-11T03:28:58.706786Z",
     "shell.execute_reply": "2023-04-11T03:28:58.705288Z",
     "shell.execute_reply.started": "2023-04-11T03:28:58.645379Z"
    }
   },
   "outputs": [],
   "source": [
    "from mtl_patients import discover_cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f8b82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T03:29:05.066080Z",
     "iopub.status.busy": "2023-04-11T03:29:05.065077Z",
     "iopub.status.idle": "2023-04-11T03:35:26.303429Z",
     "shell.execute_reply": "2023-04-11T03:35:26.301966Z",
     "shell.execute_reply.started": "2023-04-11T03:29:05.066043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:608: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.loc[:, feature_cols] = X_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:633: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'ethnicity'] = static_to_keep_df['ethnicity'].apply(categorize_ethnicity)\n",
      "/notebooks/notebooks/../code/mtl_patients.py:634: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'age'] = static_to_keep_df['age'].apply(categorize_age)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Discovering cohorts in an unsupervised way\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Training LSTM autoencoder started at 11/04/2023 03:29:55. This will take several minutes (5 to 25). Please be patient...\n",
      "Epoch 1/100\n",
      "182/182 [==============================] - 11s 25ms/step - loss: 0.0425 - val_loss: 0.0368\n",
      "Epoch 2/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0343 - val_loss: 0.0320\n",
      "Epoch 3/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0306 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 5/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 6/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 7/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 8/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0261 - val_loss: 0.0259\n",
      "Epoch 9/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0258 - val_loss: 0.0257\n",
      "Epoch 10/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0255 - val_loss: 0.0255\n",
      "Epoch 11/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0254 - val_loss: 0.0253\n",
      "Epoch 12/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0252 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0251 - val_loss: 0.0250\n",
      "Epoch 14/100\n",
      "182/182 [==============================] - 3s 19ms/step - loss: 0.0250 - val_loss: 0.0249\n",
      "Epoch 15/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0249 - val_loss: 0.0248\n",
      "Epoch 16/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 17/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0247 - val_loss: 0.0246\n",
      "Epoch 18/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0246 - val_loss: 0.0245\n",
      "Epoch 19/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0245 - val_loss: 0.0244\n",
      "Epoch 20/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 21/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0243 - val_loss: 0.0243\n",
      "Epoch 22/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 23/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0241 - val_loss: 0.0241\n",
      "Epoch 24/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 25/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 26/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 27/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0239 - val_loss: 0.0239\n",
      "Epoch 28/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0238 - val_loss: 0.0238\n",
      "Epoch 29/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 30/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 31/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0237 - val_loss: 0.0236\n",
      "Epoch 32/100\n",
      "182/182 [==============================] - 4s 20ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 33/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0236 - val_loss: 0.0236\n",
      "Epoch 34/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 35/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 36/100\n",
      "182/182 [==============================] - 3s 14ms/step - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 37/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 38/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 39/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 40/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0233 - val_loss: 0.0233\n",
      "Epoch 41/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 42/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 43/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 44/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 45/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 46/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 47/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 48/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 49/100\n",
      "182/182 [==============================] - 3s 14ms/step - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 50/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 51/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 52/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0228 - val_loss: 0.0229\n",
      "Epoch 53/100\n",
      "182/182 [==============================] - 3s 14ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 54/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 55/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 56/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 57/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 58/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 59/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 60/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 61/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 62/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 63/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0225 - val_loss: 0.0226\n",
      "Epoch 64/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 65/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 66/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 67/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 68/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0224 - val_loss: 0.0224\n",
      "Epoch 69/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0224 - val_loss: 0.0224\n",
      "Epoch 70/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0224 - val_loss: 0.0224\n",
      "Epoch 71/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 72/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0223 - val_loss: 0.0223\n",
      "Epoch 73/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0223 - val_loss: 0.0223\n",
      "Epoch 74/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0223 - val_loss: 0.0223\n",
      "Epoch 75/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0222 - val_loss: 0.0223\n",
      "Epoch 76/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 77/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 78/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 79/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0221 - val_loss: 0.0222\n",
      "Epoch 80/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 81/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 82/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 83/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 84/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 85/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 86/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 87/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 88/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 89/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0219 - val_loss: 0.0219\n",
      "Epoch 90/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0219 - val_loss: 0.0219\n",
      "Epoch 91/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 92/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 93/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0218 - val_loss: 0.0219\n",
      "Epoch 94/100\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 95/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 96/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 97/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 98/100\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 99/100\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 100/100\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0216 - val_loss: 0.0217\n",
      "    LSTM autoencoder trained!\n",
      "728/728 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 03:35:16.289179: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1111216896 exceeds 10% of free system memory.\n",
      "2023-04-11 03:35:17.454137: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1111216896 exceeds 10% of free system memory.\n",
      "2023-04-11 03:35:18.403166: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1111216896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040/1040 [==============================] - 6s 5ms/step\n",
      "Patient embeddings created! Shape: (33262, 50)\n",
      "    Training Gaussian Mixture Model...\n",
      "    Gaussian Mixture Model applied to embeddings! Results shape: (33262,)\n",
      "    Cluster results saved to '../data/unsupervised_clusters_18.npy'\n",
      "    Done!\n",
      "CPU times: user 6min 24s, sys: 48.1 s, total: 7min 12s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cohort_unsupervised_18 = discover_cohorts(cutoff_hours=18, gap_hours=9, cohort_unsupervised_filename='../data/unsupervised_clusters_18.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d175b6-7a5e-4a1b-9afc-67a94c9a0d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's summarize the results of 18 hour experiment similar to what Table 3 of the paper shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467dec00-4046-44dd-981b-6e6eaccc280f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:608: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.loc[:, feature_cols] = X_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:633: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'ethnicity'] = static_to_keep_df['ethnicity'].apply(categorize_ethnicity)\n",
      "/notebooks/notebooks/../code/mtl_patients.py:634: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'age'] = static_to_keep_df['age'].apply(categorize_age)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "# Let's create the summary for the 18 hour experiment\n",
    "\n",
    "cohort_unsupervised_18 = np.load('../data/unsupervised_clusters_18.npy')\n",
    "\n",
    "from mtl_patients import prepare_data\n",
    "_, Y, _, _, subject_ids = prepare_data(cutoff_hours=18, gap_hours=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c859cfff-9c3a-4135-bf83-52a30982042e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subject_ids = np.array(subject_ids.tolist())\n",
    "cohort_unsupervised_18_df = pd.DataFrame({'subject_id': subject_ids, 'Y': Y, 'Group': cohort_unsupervised_18}, dtype=int)\n",
    "\n",
    "# calculate summaries per cohort (24 hours)\n",
    "table3_a_df = cohort_unsupervised_18_df.groupby('Group').agg(\n",
    "    N=('Y', 'size'),\n",
    "    n=('Y', 'sum'),\n",
    ")\n",
    "table3_a_df.loc[:, 'Experiment'] = '18 hours'\n",
    "table3_a_df.loc[:, 'Cohort Type'] = 'Unsupervised'\n",
    "\n",
    "# calculate overall summary (18 hours)\n",
    "table3_a_overall_df = table3_a_df.groupby(['*'] * len(table3_a_df)).agg(\n",
    "    N=('N', 'sum'),\n",
    "    n=('n', 'sum'),\n",
    ")\n",
    "table3_a_overall_df.index.name = 'Group'\n",
    "table3_a_overall_df.loc[:, 'Experiment'] = '18 hours'\n",
    "table3_a_overall_df.loc[:, 'Cohort Type'] = 'Global'\n",
    "\n",
    "# merge 24 hour tables and make cosmetic changes\n",
    "table3_a_df = pd.concat([table3_a_df, table3_a_overall_df], axis=0)\n",
    "table3_a_df.reset_index(inplace=True)\n",
    "table3_a_df.set_index(['Experiment', 'Cohort Type', 'Group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af29a681-55f8-40db-ab68-51567aa5b1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "# assign\n",
    "table3_df = table3_a_df\n",
    "\n",
    "# calculate class imbalance\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'n'] / table3_df.loc[:, 'N']\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'Class Imbalance'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fcfcf3-9d5b-42e0-be79-29ed32ab4e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>Cohort Type</th>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">18 hours</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Unsupervised</th>\n",
       "      <th>0</th>\n",
       "      <td>14367</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7865</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11030</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <th>*</th>\n",
       "      <td>33262</td>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   N     n\n",
       "Experiment Cohort Type  Group             \n",
       "18 hours   Unsupervised 0      14367  1150\n",
       "                        1       7865   467\n",
       "                        2      11030   862\n",
       "           Global       *      33262  2479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_df = table3_a_df\n",
    "table3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29774c-0fff-481f-8110-161bed1b65a5",
   "metadata": {},
   "source": [
    "Table above is the equivalent to Table 3 in the paper. We can see the results are different. Data from MIMIC-Extract might be different from the data used by the authors.\n",
    "\n",
    "** TO-DO ** Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671387b-6023-49c7-a119-8ae1021d8e08",
   "metadata": {},
   "source": [
    "### 2.2. Visualization of selected lab test and vital signs features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1077e-5513-4da4-a004-bb6e129517db",
   "metadata": {},
   "source": [
    "In this section, we will try to reproduce the results from Figure 4 (section 6.1.1) in the paper. In Figure 4, data from experiment 1 (24 hours) is used to create heatmap plots to determine if patients from different cohorts are physiologically distinct. To do that, we added the function `get_heatmap_data()` to get the mean of all z-scores by patient, by hour in the ICU, by cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901b173-79ad-48d2-bbfe-1777bf4018d3",
   "metadata": {},
   "source": [
    "#### 2.2.1. Heatmap plots for experiment 1 (18 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fcfdf-b0a2-4b96-be22-a6161ac264c0",
   "metadata": {},
   "source": [
    "Let's run the `get_heatmap_data()` function using the cohorts discovered in experiment 1 (18 hour cutoff period and 9 hour gap period):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072de563-acf3-4d8d-9cfa-28cff6c798b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.81 s, sys: 4.76 s, total: 14.6 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import get_heatmap_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labs_df, vitals_df = get_heatmap_data(cutoff_hours=18, gap_hours=9,\n",
    "                                      cohort_unsupervised_filename='../data/unsupervised_clusters_18.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e156d2-30a5-4f54-9223-0a33ac593ac7",
   "metadata": {},
   "source": [
    "Let's plot the heatmaps for the selected lab tests and vitals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b3a472-9588-4bb6-b473-a19df11e1886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x900 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cohorts = len(np.unique(labs_df.index.get_level_values(0)))\n",
    "fig, axs = plt.subplots(nrows=2, ncols=num_cohorts)\n",
    "fig.set_size_inches(24, 12)\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = labs_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[0, i], yticklabels=True if i==0 else False).set(title=f'Lab Tests – Cohort {i}')\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = vitals_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[1, i], yticklabels=True if i==0 else False).set(title=f'Vitals – Cohort {i}')\n",
    "plt.savefig('../img/heatmap_18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c31f21-a203-44cb-b0e7-51b340e8b411",
   "metadata": {},
   "source": [
    "From the heatmap plots there are some trends in the physiological data that seems to show a distinction between cohorts.\n",
    "\n",
    "** TO-DO ** Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db5427-8514-4b98-a260-ba574192e822",
   "metadata": {},
   "source": [
    "## 3. Predicting In-Hospital Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e49cd5-dafc-401c-b946-2be0c4734bfb",
   "metadata": {},
   "source": [
    "As mentioned in the previous section, the paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the second step of the pipeline, i.e., use multi-task learning to make in-hospital mortality predictions for different patient cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68d853-3a48-403e-8ee9-427bb876f783",
   "metadata": {},
   "source": [
    "The second step uses as input the result from the first step which is a series of 3D matrices, one per discovered cohort, of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features. As an example, the 24 hour experiment described by the authors in the paper and reproduced in the previous section resulted in three cohorts (clusters) called group 0, group 1, and group 2 where the shapes of the corresponding 3D matrices are:\n",
    "* $14120 \\times 24 \\times 232$ for group 0,\n",
    "* $10841 \\times 24 \\times 232$ for group 1, and\n",
    "* $7752 \\times 24 \\times 232$ for group 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbd026-c557-41b8-b7ac-f1d11e78aef3",
   "metadata": {},
   "source": [
    "To convert these matrices into predictions, the paper proposes an LSTM for all model configurations including the baseline. In particular, the paper shows results from two specific models: a baseline model that is called *global* and using single-task learning and the multi-task learning model the authors claim as superior to the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f9738-790c-472c-b329-bcc654eaea0a",
   "metadata": {},
   "source": [
    "A diagram of the baseline (*global*) model proposed by the authors is shown below. As it can be seen, this model consists of an LSTM layer of 16 cells using a RELU activation function followed by a *single* dense layer with a sigmoid activation function. The result of the dense (fully-connected) layer is an estimate of the probability of in-hospital mortality for a given patient. This baseline model is trained with all patient samples regardless the cohort, hence the name *global*, and used for per cohort predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07256b-dc0b-4238-8a79-c37ddba39885",
   "metadata": {},
   "source": [
    "![Figure 2](../img/paper-181-fig-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44531b75-a84e-4089-9a2a-3620becfc355",
   "metadata": {},
   "source": [
    "Moving to the second model and the one the authors claim it provides benefits against the baseline is the so called *multi-task learning model*. This model consists of an LSTM layer with same number of cells (16) as the baseline model, to ensure the comparison is fair, connected to as many dense layers as population subgroups (cohorts). Each of these cohorts is considered a *task* and authors propose training these models on multiple tasks simultaneously in contrast to the baseline model with just one dense layer. The benefit of this approach according to the authors is the ability to share knowledge learned from one task (cohort) to rest of tasks under the assumption that the subpopulations used are distinct enough with relation to the outcome learned (mortality) that such shared knowledge truly exists. A representation of the multi-task learning model is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8a713-3999-400d-880d-1c98a8738ab8",
   "metadata": {},
   "source": [
    "![Figure 3](../img/paper-181-fig-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776d05-12aa-4b18-ac87-468f91d79ee1",
   "metadata": {},
   "source": [
    "For benchmarking purposes of the entire pipeline, the authors compared the results from running the pipeline using unsupervised cohort discovery (step one) against cohorts created using the first careunit the patient went into which can be considered an engineered feature. We will show those results in the next subsections.\n",
    "\n",
    "The overall performance of this model is measured using both macro and micro metrics (section 4.3 in the paper) where:\n",
    "* In *micro* metrics all predicted probabilities for all patients are treated as if they come from a single classifier: $\\text{Metric}_\\text{Micro} = \\text{Metric}([\\hat{y}_0, ..., \\hat{y}_k], [y_0, ..., y_K])$.\n",
    "* In *macro* metrics probabilities are evaluated on a *per cohort* basis, and then averaged: $\\text{Metric}_\\text{Macro} = \\dfrac{1}{K} \\displaystyle\\sum_{k=0}^K \\text{Metric}(\\hat{y}_K, y_K)$.\n",
    "\n",
    "Paper suggests that, although micro metrics are the ones typically chosen in the literature, evaluating performance on different subpopulations will benefit from macro metrics instead of micro metrics specially when there is class imbalance in every cohort. All results show macro and micro versions of the metrics for the aggregate performance of the models.\n",
    "\n",
    "All results being used for comparison between models by the paper will use three metrics:\n",
    "* AUC (Area Under the ROC Curve) for every cohort and, for the aggregate performance, macro and micro.\n",
    "* PPV (Positive Predictive Value which is same as Precision) for every cohort and, for the aggregate performance, macro and micro. This PPV is calculated at a sensitivity of 80%, a value selected by the paper authors.\n",
    "* Specificity for every cohort and, for the aggregate performance, macro and micro. This specificity is calculated at a sensitivity of 80%, a value selected by the paper authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec025760-eb01-4aab-8180-304ae4599a38",
   "metadata": {},
   "source": [
    "All in-hospital mortality prediction tasks are implemented using the function `run_mortality_prediction_task()`. This function will call other functions to prepare the data, split the data in training/validation/test data sets, train the corresponding model, predict using the resulting model, and calculate the metrics of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cb1a2-2a44-4b86-82ec-dcdbed9bbfe1",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d4117-f1f1-4d75-aead-36a9c740e9ae",
   "metadata": {},
   "source": [
    "### 3.1. Predictions with Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da524a9c-1d6f-4d2d-b37d-2e0ef4c369b3",
   "metadata": {},
   "source": [
    "In this section all in-hospital mortality predictions across the two models, global and multi-task learning, and for experiment 18 hours, are calculated for the three metrics; AUC, PPV (precision) @80% sensitivity, and Specificity @80% sensitivity; using 100 bootstrapped samples of the test set (20% of the original dataset). The results will be metrics (AUC, PPV, and Specificity) for each bootstrapped sample. This will allow the comparison between the global model and the multi-task learning model using the Wilcoxon signed-rank test as indicated in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28906d07-2252-4ee3-b4c0-536add086263",
   "metadata": {},
   "source": [
    "#### 3.1.1. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 18 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a1bcc-c348-4d61-9ecf-0ee3ab219132",
   "metadata": {},
   "source": [
    "Let's first run the mortality prediction task using the *global* model (baseline) in the 18 hour experiment setting. In this experiment, the cutoff period is 18 hours and the gap period is 9 hours, meaning model can only feed from patient data collected during the first 18 hours of the ICU stay, and predict mortality 27 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eacb099-b8b7-46c2-9d5b-b7bb024edf02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:608: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.loc[:, feature_cols] = X_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:633: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'ethnicity'] = static_to_keep_df['ethnicity'].apply(categorize_ethnicity)\n",
      "/notebooks/notebooks/../code/mtl_patients.py:634: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'age'] = static_to_keep_df['age'].apply(categorize_age)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3522\n",
      "        # of patients in cohort CSRU is 4895\n",
      "        # of patients in cohort MICU is 8183\n",
      "        # of patients in cohort SICU is 3623\n",
      "        # of patients in cohort TSICU is 3059\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"single_task_learning_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                15936     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 7s 23ms/step - loss: 0.3707 - accuracy: 0.9241 - val_loss: 0.2677 - val_accuracy: 0.9255\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2549 - accuracy: 0.9255 - val_loss: 0.2461 - val_accuracy: 0.9255\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2377 - accuracy: 0.9255 - val_loss: 0.2348 - val_accuracy: 0.9255\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.2271 - accuracy: 0.9255 - val_loss: 0.2277 - val_accuracy: 0.9255\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2198 - accuracy: 0.9255 - val_loss: 0.2239 - val_accuracy: 0.9255\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2137 - accuracy: 0.9256 - val_loss: 0.2219 - val_accuracy: 0.9261\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2089 - accuracy: 0.9262 - val_loss: 0.2180 - val_accuracy: 0.9261\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2053 - accuracy: 0.9274 - val_loss: 0.2151 - val_accuracy: 0.9270\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.2012 - accuracy: 0.9283 - val_loss: 0.2134 - val_accuracy: 0.9279\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1984 - accuracy: 0.9285 - val_loss: 0.2116 - val_accuracy: 0.9285\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1957 - accuracy: 0.9290 - val_loss: 0.2111 - val_accuracy: 0.9306\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1938 - accuracy: 0.9299 - val_loss: 0.2109 - val_accuracy: 0.9303\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1915 - accuracy: 0.9304 - val_loss: 0.2094 - val_accuracy: 0.9306\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1899 - accuracy: 0.9305 - val_loss: 0.2111 - val_accuracy: 0.9306\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1884 - accuracy: 0.9309 - val_loss: 0.2088 - val_accuracy: 0.9306\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1868 - accuracy: 0.9319 - val_loss: 0.2070 - val_accuracy: 0.9306\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1853 - accuracy: 0.9319 - val_loss: 0.2074 - val_accuracy: 0.9306\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1838 - accuracy: 0.9327 - val_loss: 0.2074 - val_accuracy: 0.9303\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.1827 - accuracy: 0.9327 - val_loss: 0.2063 - val_accuracy: 0.9315\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.1814 - accuracy: 0.9333 - val_loss: 0.2052 - val_accuracy: 0.9309\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1804 - accuracy: 0.9334 - val_loss: 0.2048 - val_accuracy: 0.9312\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1788 - accuracy: 0.9339 - val_loss: 0.2052 - val_accuracy: 0.9306\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.2056 - val_accuracy: 0.9303\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1764 - accuracy: 0.9348 - val_loss: 0.2045 - val_accuracy: 0.9309\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1757 - accuracy: 0.9345 - val_loss: 0.2050 - val_accuracy: 0.9303\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1746 - accuracy: 0.9351 - val_loss: 0.2051 - val_accuracy: 0.9303\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1736 - accuracy: 0.9361 - val_loss: 0.2051 - val_accuracy: 0.9294\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1727 - accuracy: 0.9357 - val_loss: 0.2069 - val_accuracy: 0.9300\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_global_18+9_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "208/208 [==============================] - 1s 3ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca00f4d957f4826a2b120d82eba98a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aad1086257d4ee0afb746d20acbc8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fe9cfbc0d425896679cde36d82363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a196e6120b9e4a089df8f9b09efa041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1d36c7dba84569bc4aa39cb3ff63b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58555bd7c95641ebb55d177065ee979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 5min 58s, sys: 2min 27s, total: 8min 25s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_global_18_careunits_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=18, gap_hours=9, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f519ff41-0303-4a3f-9ad1-2fd486509878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Macro</th>\n",
       "      <th>96</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "CCU    1       0.845  0.165        0.730\n",
       "       2       0.792  0.172        0.711\n",
       "       3       0.850  0.125        0.738\n",
       "       4       0.848  0.157        0.729\n",
       "       5       0.783  0.134        0.673\n",
       "...              ...    ...          ...\n",
       "Macro  96      0.870  0.203        0.779\n",
       "       97      0.844  0.188        0.757\n",
       "       98      0.857  0.181        0.742\n",
       "       99      0.852  0.195        0.742\n",
       "       100     0.828  0.162        0.671\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 20\n",
    "metrics_global_18_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d00a05-ff33-4b9b-bc34-3b6070b65a9f",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789dbf10-6372-4855-980a-c4bd0a90c4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:608: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.loc[:, feature_cols] = X_words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/../code/mtl_patients.py:633: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'ethnicity'] = static_to_keep_df['ethnicity'].apply(categorize_ethnicity)\n",
      "/notebooks/notebooks/../code/mtl_patients.py:634: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  static_to_keep_df.loc[:, 'age'] = static_to_keep_df['age'].apply(categorize_age)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort 0 is 10104\n",
      "        # of patients in cohort 1 is 5485\n",
      "        # of patients in cohort 2 is 7693\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"single_task_learning_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                15936     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 6s 22ms/step - loss: 0.3707 - accuracy: 0.9241 - val_loss: 0.2677 - val_accuracy: 0.9255\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2549 - accuracy: 0.9255 - val_loss: 0.2461 - val_accuracy: 0.9255\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.2377 - accuracy: 0.9255 - val_loss: 0.2348 - val_accuracy: 0.9255\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2271 - accuracy: 0.9255 - val_loss: 0.2277 - val_accuracy: 0.9255\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2198 - accuracy: 0.9255 - val_loss: 0.2239 - val_accuracy: 0.9255\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.2137 - accuracy: 0.9256 - val_loss: 0.2219 - val_accuracy: 0.9261\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2089 - accuracy: 0.9262 - val_loss: 0.2180 - val_accuracy: 0.9261\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.2053 - accuracy: 0.9274 - val_loss: 0.2151 - val_accuracy: 0.9270\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.2012 - accuracy: 0.9283 - val_loss: 0.2134 - val_accuracy: 0.9279\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.1984 - accuracy: 0.9285 - val_loss: 0.2116 - val_accuracy: 0.9285\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1957 - accuracy: 0.9290 - val_loss: 0.2111 - val_accuracy: 0.9306\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.1938 - accuracy: 0.9299 - val_loss: 0.2109 - val_accuracy: 0.9303\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1915 - accuracy: 0.9304 - val_loss: 0.2094 - val_accuracy: 0.9306\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1899 - accuracy: 0.9305 - val_loss: 0.2111 - val_accuracy: 0.9306\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1884 - accuracy: 0.9309 - val_loss: 0.2088 - val_accuracy: 0.9306\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1868 - accuracy: 0.9319 - val_loss: 0.2070 - val_accuracy: 0.9306\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 4s 19ms/step - loss: 0.1853 - accuracy: 0.9319 - val_loss: 0.2074 - val_accuracy: 0.9306\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1838 - accuracy: 0.9327 - val_loss: 0.2074 - val_accuracy: 0.9303\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1827 - accuracy: 0.9327 - val_loss: 0.2063 - val_accuracy: 0.9315\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1814 - accuracy: 0.9333 - val_loss: 0.2052 - val_accuracy: 0.9309\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1804 - accuracy: 0.9334 - val_loss: 0.2048 - val_accuracy: 0.9312\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1788 - accuracy: 0.9339 - val_loss: 0.2052 - val_accuracy: 0.9306\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.2056 - val_accuracy: 0.9303\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1764 - accuracy: 0.9348 - val_loss: 0.2045 - val_accuracy: 0.9309\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.1757 - accuracy: 0.9345 - val_loss: 0.2050 - val_accuracy: 0.9303\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.1746 - accuracy: 0.9351 - val_loss: 0.2051 - val_accuracy: 0.9303\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 5s 19ms/step - loss: 0.1736 - accuracy: 0.9361 - val_loss: 0.2051 - val_accuracy: 0.9294\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 5s 20ms/step - loss: 0.1727 - accuracy: 0.9357 - val_loss: 0.2069 - val_accuracy: 0.9300\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_global_18+9_unsupervised/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "208/208 [==============================] - 1s 3ms/step\n",
      "    Bootstrap prediction for task \"0\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5a3761ff12487fbd6ea79fbae063b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"1\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f211d54becb4c1581ce753f26ed9d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"2\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1ad77a187f462498e7830fe510d186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269f39f2dfa84ba9814c8657bb2ccd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 5min 35s, sys: 2min 17s, total: 7min 52s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_global_18_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=18, gap_hours=9, bootstrap=True,\n",
    "                                                                         cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_18.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdbd97a-6b01-472b-9461-0277692f0082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Macro</th>\n",
       "      <th>96</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "0      1       0.854  0.257        0.797\n",
       "       2       0.847  0.236        0.770\n",
       "       3       0.833  0.204        0.734\n",
       "       4       0.859  0.252        0.790\n",
       "       5       0.856  0.243        0.776\n",
       "...              ...    ...          ...\n",
       "Macro  96      0.867  0.233        0.768\n",
       "       97      0.879  0.247        0.797\n",
       "       98      0.873  0.226        0.789\n",
       "       99      0.856  0.183        0.739\n",
       "       100     0.874  0.244        0.794\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_global_18_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079b1d-28fd-4a67-9613-f188139cf2f5",
   "metadata": {},
   "source": [
    "#### 3.1.2. In-Hospital Mortality Prediction – Multi-Task Learning Model at 18 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a6085-32a9-411a-82be-a1a48894c36d",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 18 hour experiment setting. In this experiment, the cutoff period is 18 hours and the gap period is 9 hours, meaning model can only feed from patient data collected during the first 18 hours of the ICU stay, and predict mortality 27 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3358dc-8459-4225-abfe-841a8db5b496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3522\n",
      "        # of patients in cohort CSRU is 4895\n",
      "        # of patients in cohort MICU is 8183\n",
      "        # of patients in cohort SICU is 3623\n",
      "        # of patients in cohort TSICU is 3059\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'multitask' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"multitask_learning_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 18, 232)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 16)           15936       ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " CCU (Dense)                    (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " CSRU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " MICU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " SICU (Dense)                   (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " TSICU (Dense)                  (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,021\n",
      "Trainable params: 16,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 14s 43ms/step - loss: 0.4152 - CCU_loss: 0.0657 - CSRU_loss: 0.0569 - MICU_loss: 0.1589 - SICU_loss: 0.0720 - TSICU_loss: 0.0618 - CCU_accuracy: 0.9225 - CSRU_accuracy: 0.9087 - MICU_accuracy: 0.8888 - SICU_accuracy: 0.9038 - TSICU_accuracy: 0.8682 - val_loss: 1.4661 - val_CCU_loss: 0.2888 - val_CSRU_loss: 0.2840 - val_MICU_loss: 0.2876 - val_SICU_loss: 0.3123 - val_TSICU_loss: 0.2933 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9252 - val_MICU_accuracy: 0.9255 - val_SICU_accuracy: 0.9258 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.2652 - CCU_loss: 0.0426 - CSRU_loss: 0.0216 - MICU_loss: 0.1166 - SICU_loss: 0.0483 - TSICU_loss: 0.0360 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9255 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.2750 - val_CCU_loss: 0.2506 - val_CSRU_loss: 0.2504 - val_MICU_loss: 0.2528 - val_SICU_loss: 0.2668 - val_TSICU_loss: 0.2545 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9258 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.2374 - CCU_loss: 0.0381 - CSRU_loss: 0.0198 - MICU_loss: 0.1055 - SICU_loss: 0.0424 - TSICU_loss: 0.0316 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9257 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.2141 - val_CCU_loss: 0.2412 - val_CSRU_loss: 0.2435 - val_MICU_loss: 0.2419 - val_SICU_loss: 0.2460 - val_TSICU_loss: 0.2414 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9261 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.2257 - CCU_loss: 0.0363 - CSRU_loss: 0.0190 - MICU_loss: 0.1009 - SICU_loss: 0.0400 - TSICU_loss: 0.0295 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9260 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.1895 - val_CCU_loss: 0.2383 - val_CSRU_loss: 0.2426 - val_MICU_loss: 0.2356 - val_SICU_loss: 0.2374 - val_TSICU_loss: 0.2357 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9270 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 10s 41ms/step - loss: 0.2192 - CCU_loss: 0.0352 - CSRU_loss: 0.0187 - MICU_loss: 0.0981 - SICU_loss: 0.0387 - TSICU_loss: 0.0285 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9263 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.1846 - val_CCU_loss: 0.2386 - val_CSRU_loss: 0.2500 - val_MICU_loss: 0.2331 - val_SICU_loss: 0.2313 - val_TSICU_loss: 0.2316 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9273 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 10s 41ms/step - loss: 0.2145 - CCU_loss: 0.0345 - CSRU_loss: 0.0184 - MICU_loss: 0.0963 - SICU_loss: 0.0376 - TSICU_loss: 0.0276 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9266 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.1664 - val_CCU_loss: 0.2326 - val_CSRU_loss: 0.2367 - val_MICU_loss: 0.2320 - val_SICU_loss: 0.2323 - val_TSICU_loss: 0.2329 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9282 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.2110 - CCU_loss: 0.0340 - CSRU_loss: 0.0182 - MICU_loss: 0.0947 - SICU_loss: 0.0370 - TSICU_loss: 0.0271 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9268 - SICU_accuracy: 0.9255 - TSICU_accuracy: 0.9255 - val_loss: 1.1687 - val_CCU_loss: 0.2352 - val_CSRU_loss: 0.2492 - val_MICU_loss: 0.2301 - val_SICU_loss: 0.2262 - val_TSICU_loss: 0.2279 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9282 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.2081 - CCU_loss: 0.0335 - CSRU_loss: 0.0180 - MICU_loss: 0.0934 - SICU_loss: 0.0364 - TSICU_loss: 0.0268 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9272 - SICU_accuracy: 0.9256 - TSICU_accuracy: 0.9255 - val_loss: 1.1506 - val_CCU_loss: 0.2297 - val_CSRU_loss: 0.2405 - val_MICU_loss: 0.2270 - val_SICU_loss: 0.2254 - val_TSICU_loss: 0.2280 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9288 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.2051 - CCU_loss: 0.0328 - CSRU_loss: 0.0178 - MICU_loss: 0.0922 - SICU_loss: 0.0359 - TSICU_loss: 0.0264 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9272 - SICU_accuracy: 0.9258 - TSICU_accuracy: 0.9257 - val_loss: 1.1476 - val_CCU_loss: 0.2295 - val_CSRU_loss: 0.2395 - val_MICU_loss: 0.2282 - val_SICU_loss: 0.2234 - val_TSICU_loss: 0.2270 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9255 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9255 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.2029 - CCU_loss: 0.0325 - CSRU_loss: 0.0175 - MICU_loss: 0.0912 - SICU_loss: 0.0355 - TSICU_loss: 0.0261 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9277 - SICU_accuracy: 0.9259 - TSICU_accuracy: 0.9257 - val_loss: 1.1383 - val_CCU_loss: 0.2272 - val_CSRU_loss: 0.2377 - val_MICU_loss: 0.2255 - val_SICU_loss: 0.2222 - val_TSICU_loss: 0.2257 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9294 - val_SICU_accuracy: 0.9264 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.2002 - CCU_loss: 0.0319 - CSRU_loss: 0.0174 - MICU_loss: 0.0901 - SICU_loss: 0.0351 - TSICU_loss: 0.0257 - CCU_accuracy: 0.9255 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9279 - SICU_accuracy: 0.9261 - TSICU_accuracy: 0.9257 - val_loss: 1.1356 - val_CCU_loss: 0.2265 - val_CSRU_loss: 0.2390 - val_MICU_loss: 0.2251 - val_SICU_loss: 0.2201 - val_TSICU_loss: 0.2249 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9264 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1981 - CCU_loss: 0.0315 - CSRU_loss: 0.0172 - MICU_loss: 0.0891 - SICU_loss: 0.0348 - TSICU_loss: 0.0255 - CCU_accuracy: 0.9256 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9286 - SICU_accuracy: 0.9263 - TSICU_accuracy: 0.9256 - val_loss: 1.1358 - val_CCU_loss: 0.2266 - val_CSRU_loss: 0.2439 - val_MICU_loss: 0.2237 - val_SICU_loss: 0.2182 - val_TSICU_loss: 0.2234 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9294 - val_SICU_accuracy: 0.9267 - val_TSICU_accuracy: 0.9258\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 10s 41ms/step - loss: 0.1957 - CCU_loss: 0.0311 - CSRU_loss: 0.0169 - MICU_loss: 0.0883 - SICU_loss: 0.0344 - TSICU_loss: 0.0251 - CCU_accuracy: 0.9257 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9291 - SICU_accuracy: 0.9269 - TSICU_accuracy: 0.9257 - val_loss: 1.1239 - val_CCU_loss: 0.2233 - val_CSRU_loss: 0.2361 - val_MICU_loss: 0.2226 - val_SICU_loss: 0.2171 - val_TSICU_loss: 0.2248 - val_CCU_accuracy: 0.9252 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9297 - val_SICU_accuracy: 0.9273 - val_TSICU_accuracy: 0.9261\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1937 - CCU_loss: 0.0307 - CSRU_loss: 0.0168 - MICU_loss: 0.0872 - SICU_loss: 0.0340 - TSICU_loss: 0.0251 - CCU_accuracy: 0.9260 - CSRU_accuracy: 0.9255 - MICU_accuracy: 0.9295 - SICU_accuracy: 0.9274 - TSICU_accuracy: 0.9255 - val_loss: 1.1334 - val_CCU_loss: 0.2266 - val_CSRU_loss: 0.2439 - val_MICU_loss: 0.2234 - val_SICU_loss: 0.2166 - val_TSICU_loss: 0.2230 - val_CCU_accuracy: 0.9258 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9297 - val_SICU_accuracy: 0.9273 - val_TSICU_accuracy: 0.9255\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.1920 - CCU_loss: 0.0303 - CSRU_loss: 0.0165 - MICU_loss: 0.0866 - SICU_loss: 0.0338 - TSICU_loss: 0.0248 - CCU_accuracy: 0.9264 - CSRU_accuracy: 0.9256 - MICU_accuracy: 0.9299 - SICU_accuracy: 0.9277 - TSICU_accuracy: 0.9256 - val_loss: 1.1125 - val_CCU_loss: 0.2211 - val_CSRU_loss: 0.2326 - val_MICU_loss: 0.2199 - val_SICU_loss: 0.2154 - val_TSICU_loss: 0.2234 - val_CCU_accuracy: 0.9255 - val_CSRU_accuracy: 0.9258 - val_MICU_accuracy: 0.9306 - val_SICU_accuracy: 0.9267 - val_TSICU_accuracy: 0.9249\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1900 - CCU_loss: 0.0300 - CSRU_loss: 0.0164 - MICU_loss: 0.0855 - SICU_loss: 0.0335 - TSICU_loss: 0.0246 - CCU_accuracy: 0.9270 - CSRU_accuracy: 0.9256 - MICU_accuracy: 0.9304 - SICU_accuracy: 0.9282 - TSICU_accuracy: 0.9257 - val_loss: 1.1046 - val_CCU_loss: 0.2174 - val_CSRU_loss: 0.2204 - val_MICU_loss: 0.2221 - val_SICU_loss: 0.2175 - val_TSICU_loss: 0.2273 - val_CCU_accuracy: 0.9267 - val_CSRU_accuracy: 0.9264 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9261 - val_TSICU_accuracy: 0.9249\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1881 - CCU_loss: 0.0297 - CSRU_loss: 0.0163 - MICU_loss: 0.0849 - SICU_loss: 0.0330 - TSICU_loss: 0.0242 - CCU_accuracy: 0.9271 - CSRU_accuracy: 0.9258 - MICU_accuracy: 0.9316 - SICU_accuracy: 0.9284 - TSICU_accuracy: 0.9257 - val_loss: 1.1081 - val_CCU_loss: 0.2203 - val_CSRU_loss: 0.2299 - val_MICU_loss: 0.2194 - val_SICU_loss: 0.2144 - val_TSICU_loss: 0.2240 - val_CCU_accuracy: 0.9267 - val_CSRU_accuracy: 0.9264 - val_MICU_accuracy: 0.9297 - val_SICU_accuracy: 0.9270 - val_TSICU_accuracy: 0.9246\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.1865 - CCU_loss: 0.0294 - CSRU_loss: 0.0161 - MICU_loss: 0.0843 - SICU_loss: 0.0329 - TSICU_loss: 0.0239 - CCU_accuracy: 0.9277 - CSRU_accuracy: 0.9262 - MICU_accuracy: 0.9313 - SICU_accuracy: 0.9286 - TSICU_accuracy: 0.9255 - val_loss: 1.1048 - val_CCU_loss: 0.2207 - val_CSRU_loss: 0.2293 - val_MICU_loss: 0.2196 - val_SICU_loss: 0.2129 - val_TSICU_loss: 0.2223 - val_CCU_accuracy: 0.9267 - val_CSRU_accuracy: 0.9267 - val_MICU_accuracy: 0.9303 - val_SICU_accuracy: 0.9273 - val_TSICU_accuracy: 0.9249\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1849 - CCU_loss: 0.0290 - CSRU_loss: 0.0160 - MICU_loss: 0.0837 - SICU_loss: 0.0327 - TSICU_loss: 0.0236 - CCU_accuracy: 0.9281 - CSRU_accuracy: 0.9267 - MICU_accuracy: 0.9317 - SICU_accuracy: 0.9291 - TSICU_accuracy: 0.9255 - val_loss: 1.1021 - val_CCU_loss: 0.2205 - val_CSRU_loss: 0.2282 - val_MICU_loss: 0.2185 - val_SICU_loss: 0.2126 - val_TSICU_loss: 0.2223 - val_CCU_accuracy: 0.9276 - val_CSRU_accuracy: 0.9264 - val_MICU_accuracy: 0.9297 - val_SICU_accuracy: 0.9273 - val_TSICU_accuracy: 0.9246\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1834 - CCU_loss: 0.0289 - CSRU_loss: 0.0159 - MICU_loss: 0.0828 - SICU_loss: 0.0324 - TSICU_loss: 0.0233 - CCU_accuracy: 0.9283 - CSRU_accuracy: 0.9272 - MICU_accuracy: 0.9320 - SICU_accuracy: 0.9288 - TSICU_accuracy: 0.9258 - val_loss: 1.0944 - val_CCU_loss: 0.2180 - val_CSRU_loss: 0.2225 - val_MICU_loss: 0.2186 - val_SICU_loss: 0.2115 - val_TSICU_loss: 0.2238 - val_CCU_accuracy: 0.9273 - val_CSRU_accuracy: 0.9270 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9276 - val_TSICU_accuracy: 0.9228\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1822 - CCU_loss: 0.0285 - CSRU_loss: 0.0157 - MICU_loss: 0.0825 - SICU_loss: 0.0324 - TSICU_loss: 0.0231 - CCU_accuracy: 0.9284 - CSRU_accuracy: 0.9281 - MICU_accuracy: 0.9327 - SICU_accuracy: 0.9294 - TSICU_accuracy: 0.9258 - val_loss: 1.0860 - val_CCU_loss: 0.2153 - val_CSRU_loss: 0.2161 - val_MICU_loss: 0.2183 - val_SICU_loss: 0.2125 - val_TSICU_loss: 0.2238 - val_CCU_accuracy: 0.9270 - val_CSRU_accuracy: 0.9276 - val_MICU_accuracy: 0.9294 - val_SICU_accuracy: 0.9276 - val_TSICU_accuracy: 0.9231\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1802 - CCU_loss: 0.0283 - CSRU_loss: 0.0155 - MICU_loss: 0.0815 - SICU_loss: 0.0321 - TSICU_loss: 0.0228 - CCU_accuracy: 0.9287 - CSRU_accuracy: 0.9284 - MICU_accuracy: 0.9326 - SICU_accuracy: 0.9296 - TSICU_accuracy: 0.9262 - val_loss: 1.0923 - val_CCU_loss: 0.2178 - val_CSRU_loss: 0.2202 - val_MICU_loss: 0.2201 - val_SICU_loss: 0.2100 - val_TSICU_loss: 0.2241 - val_CCU_accuracy: 0.9267 - val_CSRU_accuracy: 0.9294 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9276 - val_TSICU_accuracy: 0.9231\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1793 - CCU_loss: 0.0281 - CSRU_loss: 0.0154 - MICU_loss: 0.0813 - SICU_loss: 0.0319 - TSICU_loss: 0.0227 - CCU_accuracy: 0.9297 - CSRU_accuracy: 0.9288 - MICU_accuracy: 0.9333 - SICU_accuracy: 0.9301 - TSICU_accuracy: 0.9269 - val_loss: 1.0879 - val_CCU_loss: 0.2163 - val_CSRU_loss: 0.2178 - val_MICU_loss: 0.2196 - val_SICU_loss: 0.2100 - val_TSICU_loss: 0.2242 - val_CCU_accuracy: 0.9282 - val_CSRU_accuracy: 0.9300 - val_MICU_accuracy: 0.9291 - val_SICU_accuracy: 0.9279 - val_TSICU_accuracy: 0.9216\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1778 - CCU_loss: 0.0279 - CSRU_loss: 0.0154 - MICU_loss: 0.0803 - SICU_loss: 0.0318 - TSICU_loss: 0.0225 - CCU_accuracy: 0.9296 - CSRU_accuracy: 0.9294 - MICU_accuracy: 0.9333 - SICU_accuracy: 0.9307 - TSICU_accuracy: 0.9261 - val_loss: 1.0809 - val_CCU_loss: 0.2128 - val_CSRU_loss: 0.2127 - val_MICU_loss: 0.2196 - val_SICU_loss: 0.2102 - val_TSICU_loss: 0.2256 - val_CCU_accuracy: 0.9279 - val_CSRU_accuracy: 0.9300 - val_MICU_accuracy: 0.9279 - val_SICU_accuracy: 0.9285 - val_TSICU_accuracy: 0.9209\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 9s 39ms/step - loss: 0.1768 - CCU_loss: 0.0277 - CSRU_loss: 0.0152 - MICU_loss: 0.0800 - SICU_loss: 0.0316 - TSICU_loss: 0.0222 - CCU_accuracy: 0.9300 - CSRU_accuracy: 0.9296 - MICU_accuracy: 0.9329 - SICU_accuracy: 0.9302 - TSICU_accuracy: 0.9268 - val_loss: 1.0821 - val_CCU_loss: 0.2144 - val_CSRU_loss: 0.2146 - val_MICU_loss: 0.2178 - val_SICU_loss: 0.2094 - val_TSICU_loss: 0.2259 - val_CCU_accuracy: 0.9279 - val_CSRU_accuracy: 0.9294 - val_MICU_accuracy: 0.9288 - val_SICU_accuracy: 0.9279 - val_TSICU_accuracy: 0.9194\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1757 - CCU_loss: 0.0275 - CSRU_loss: 0.0151 - MICU_loss: 0.0796 - SICU_loss: 0.0314 - TSICU_loss: 0.0221 - CCU_accuracy: 0.9306 - CSRU_accuracy: 0.9299 - MICU_accuracy: 0.9336 - SICU_accuracy: 0.9311 - TSICU_accuracy: 0.9265 - val_loss: 1.0870 - val_CCU_loss: 0.2142 - val_CSRU_loss: 0.2136 - val_MICU_loss: 0.2216 - val_SICU_loss: 0.2093 - val_TSICU_loss: 0.2282 - val_CCU_accuracy: 0.9276 - val_CSRU_accuracy: 0.9291 - val_MICU_accuracy: 0.9261 - val_SICU_accuracy: 0.9282 - val_TSICU_accuracy: 0.9185\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1748 - CCU_loss: 0.0273 - CSRU_loss: 0.0151 - MICU_loss: 0.0793 - SICU_loss: 0.0312 - TSICU_loss: 0.0219 - CCU_accuracy: 0.9309 - CSRU_accuracy: 0.9303 - MICU_accuracy: 0.9331 - SICU_accuracy: 0.9313 - TSICU_accuracy: 0.9259 - val_loss: 1.0792 - val_CCU_loss: 0.2137 - val_CSRU_loss: 0.2132 - val_MICU_loss: 0.2178 - val_SICU_loss: 0.2090 - val_TSICU_loss: 0.2255 - val_CCU_accuracy: 0.9276 - val_CSRU_accuracy: 0.9303 - val_MICU_accuracy: 0.9276 - val_SICU_accuracy: 0.9288 - val_TSICU_accuracy: 0.9194\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.1738 - CCU_loss: 0.0271 - CSRU_loss: 0.0149 - MICU_loss: 0.0788 - SICU_loss: 0.0311 - TSICU_loss: 0.0219 - CCU_accuracy: 0.9315 - CSRU_accuracy: 0.9305 - MICU_accuracy: 0.9341 - SICU_accuracy: 0.9317 - TSICU_accuracy: 0.9269 - val_loss: 1.0835 - val_CCU_loss: 0.2155 - val_CSRU_loss: 0.2152 - val_MICU_loss: 0.2178 - val_SICU_loss: 0.2091 - val_TSICU_loss: 0.2259 - val_CCU_accuracy: 0.9279 - val_CSRU_accuracy: 0.9303 - val_MICU_accuracy: 0.9282 - val_SICU_accuracy: 0.9285 - val_TSICU_accuracy: 0.9191\n",
      "Epoch 29/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1726 - CCU_loss: 0.0271 - CSRU_loss: 0.0149 - MICU_loss: 0.0782 - SICU_loss: 0.0308 - TSICU_loss: 0.0215 - CCU_accuracy: 0.9317 - CSRU_accuracy: 0.9305 - MICU_accuracy: 0.9333 - SICU_accuracy: 0.9316 - TSICU_accuracy: 0.9267 - val_loss: 1.0871 - val_CCU_loss: 0.2157 - val_CSRU_loss: 0.2148 - val_MICU_loss: 0.2202 - val_SICU_loss: 0.2089 - val_TSICU_loss: 0.2275 - val_CCU_accuracy: 0.9276 - val_CSRU_accuracy: 0.9300 - val_MICU_accuracy: 0.9267 - val_SICU_accuracy: 0.9282 - val_TSICU_accuracy: 0.9188\n",
      "Epoch 30/30\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.1716 - CCU_loss: 0.0268 - CSRU_loss: 0.0148 - MICU_loss: 0.0779 - SICU_loss: 0.0306 - TSICU_loss: 0.0214 - CCU_accuracy: 0.9324 - CSRU_accuracy: 0.9311 - MICU_accuracy: 0.9336 - SICU_accuracy: 0.9319 - TSICU_accuracy: 0.9266 - val_loss: 1.0845 - val_CCU_loss: 0.2152 - val_CSRU_loss: 0.2129 - val_MICU_loss: 0.2197 - val_SICU_loss: 0.2106 - val_TSICU_loss: 0.2261 - val_CCU_accuracy: 0.9273 - val_CSRU_accuracy: 0.9300 - val_MICU_accuracy: 0.9264 - val_SICU_accuracy: 0.9276 - val_TSICU_accuracy: 0.9188\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_multitask_18+9_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'multitask' model...\n",
      "208/208 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21c18bd45db4716bda0cdcf371aca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172d97a933564dd7a6718a47e054ca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fcb024fe6145b5810c49b5c4fdcf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643e1ffe85f04b81953384bc5a00b9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3583a5f1b1c14e2d855689ce322a0dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17a6abfb0c34198a57a92c6469e9597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n",
      "CPU times: user 10min 29s, sys: 3min 46s, total: 14min 16s\n",
      "Wall time: 12min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_mtl_18_careunits_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=18, gap_hours=9, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef88acf-1368-465d-80b4-79da55c24be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">CSRU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">MICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">SICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.793</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">TSICU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Micro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Macro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "CCU    1       0.859  0.161        0.727\n",
       "       2       0.787  0.133        0.607\n",
       "       3       0.859  0.116        0.714\n",
       "       4       0.845  0.137        0.683\n",
       "       5       0.805  0.115        0.621\n",
       "       6       0.798  0.111        0.676\n",
       "       7       0.870  0.121        0.718\n",
       "       8       0.823  0.136        0.739\n",
       "       9       0.819  0.154        0.733\n",
       "       10      0.754  0.103        0.566\n",
       "       11      0.842  0.144        0.711\n",
       "       12      0.846  0.137        0.691\n",
       "       13      0.817  0.126        0.669\n",
       "       14      0.843  0.153        0.723\n",
       "       15      0.741  0.087        0.559\n",
       "       16      0.842  0.150        0.718\n",
       "       17      0.835  0.115        0.709\n",
       "       18      0.834  0.167        0.724\n",
       "       19      0.816  0.170        0.729\n",
       "       20      0.846  0.141        0.719\n",
       "       21      0.832  0.173        0.704\n",
       "       22      0.850  0.185        0.735\n",
       "       23      0.818  0.161        0.683\n",
       "       24      0.849  0.178        0.826\n",
       "       25      0.805  0.165        0.711\n",
       "       26      0.784  0.113        0.581\n",
       "       27      0.848  0.192        0.773\n",
       "       28      0.822  0.151        0.687\n",
       "       29      0.831  0.169        0.701\n",
       "       30      0.836  0.153        0.712\n",
       "       31      0.839  0.115        0.638\n",
       "       32      0.796  0.160        0.714\n",
       "       33      0.852  0.187        0.816\n",
       "       34      0.847  0.164        0.694\n",
       "       35      0.775  0.127        0.570\n",
       "       36      0.842  0.136        0.725\n",
       "       37      0.814  0.143        0.678\n",
       "       38      0.832  0.148        0.700\n",
       "       39      0.778  0.133        0.715\n",
       "       40      0.813  0.152        0.672\n",
       "       41      0.836  0.173        0.730\n",
       "       42      0.842  0.142        0.677\n",
       "       43      0.882  0.216        0.820\n",
       "       44      0.855  0.198        0.713\n",
       "       45      0.895  0.224        0.817\n",
       "       46      0.797  0.105        0.597\n",
       "       47      0.873  0.188        0.752\n",
       "       48      0.840  0.142        0.695\n",
       "       49      0.791  0.132        0.673\n",
       "       50      0.830  0.133        0.698\n",
       "       51      0.849  0.158        0.729\n",
       "       52      0.856  0.182        0.719\n",
       "       53      0.836  0.128        0.702\n",
       "       54      0.850  0.169        0.733\n",
       "       55      0.849  0.155        0.709\n",
       "       56      0.800  0.152        0.700\n",
       "       57      0.820  0.106        0.624\n",
       "       58      0.816  0.127        0.698\n",
       "       59      0.842  0.179        0.739\n",
       "       60      0.818  0.144        0.682\n",
       "       61      0.818  0.108        0.652\n",
       "       62      0.856  0.189        0.795\n",
       "       63      0.885  0.233        0.843\n",
       "       64      0.825  0.145        0.695\n",
       "       65      0.825  0.134        0.679\n",
       "       66      0.832  0.142        0.686\n",
       "       67      0.803  0.169        0.697\n",
       "       68      0.788  0.099        0.636\n",
       "       69      0.853  0.193        0.739\n",
       "       70      0.842  0.133        0.727\n",
       "       71      0.840  0.159        0.722\n",
       "       72      0.858  0.150        0.717\n",
       "       73      0.845  0.121        0.730\n",
       "       74      0.841  0.155        0.697\n",
       "       75      0.847  0.164        0.726\n",
       "       76      0.830  0.125        0.654\n",
       "       77      0.826  0.146        0.715\n",
       "       78      0.846  0.205        0.748\n",
       "       79      0.845  0.183        0.719\n",
       "       80      0.813  0.135        0.678\n",
       "       81      0.829  0.128        0.703\n",
       "       82      0.867  0.162        0.729\n",
       "       83      0.843  0.188        0.788\n",
       "       84      0.788  0.145        0.649\n",
       "       85      0.857  0.148        0.746\n",
       "       86      0.834  0.153        0.711\n",
       "       87      0.840  0.138        0.718\n",
       "       88      0.758  0.126        0.616\n",
       "       89      0.801  0.133        0.625\n",
       "       90      0.843  0.148        0.716\n",
       "       91      0.866  0.155        0.758\n",
       "       92      0.855  0.239        0.829\n",
       "       93      0.837  0.173        0.730\n",
       "       94      0.787  0.098        0.610\n",
       "       95      0.848  0.182        0.744\n",
       "       96      0.806  0.143        0.707\n",
       "       97      0.830  0.113        0.669\n",
       "       98      0.831  0.123        0.686\n",
       "       99      0.769  0.071        0.540\n",
       "       100     0.841  0.171        0.746\n",
       "CSRU   1       0.914  0.101        0.910\n",
       "       2       0.920  0.086        0.881\n",
       "       3       0.869  0.052        0.751\n",
       "       4       0.857  0.031        0.724\n",
       "       5       0.879  0.099        0.856\n",
       "       6       0.956  0.133        0.918\n",
       "       7       0.833  0.055        0.708\n",
       "       8       0.918  0.114        0.892\n",
       "       9       0.883  0.129        0.867\n",
       "       10      0.887  0.122        0.860\n",
       "       11      0.891  0.103        0.866\n",
       "       12      0.882  0.094        0.866\n",
       "       13      0.916  0.115        0.876\n",
       "       14      0.858  0.063        0.747\n",
       "       15      0.906  0.120        0.886\n",
       "       16      0.878  0.150        0.915\n",
       "       17      0.902  0.129        0.923\n",
       "       18      0.880  0.105        0.863\n",
       "       19      0.845  0.049        0.723\n",
       "       20      0.867  0.092        0.858\n",
       "       21      0.845  0.098        0.863\n",
       "       22      0.767  0.036        0.700\n",
       "       23      0.863  0.042        0.751\n",
       "       24      0.856  0.109        0.878\n",
       "       25      0.872  0.080        0.859\n",
       "       26      0.899  0.090        0.894\n",
       "       27      0.910  0.106        0.882\n",
       "       28      0.891  0.101        0.866\n",
       "       29      0.848  0.063        0.697\n",
       "       30      0.909  0.121        0.909\n",
       "       31      0.828  0.055        0.736\n",
       "       32      0.898  0.109        0.869\n",
       "       33      0.914  0.120        0.887\n",
       "       34      0.890  0.125        0.933\n",
       "       35      0.939  0.206        0.943\n",
       "       36      0.869  0.134        0.905\n",
       "       37      0.909  0.105        0.868\n",
       "       38      0.929  0.120        0.895\n",
       "       39      0.841  0.112        0.860\n",
       "       40      0.906  0.123        0.905\n",
       "       41      0.931  0.063        0.895\n",
       "       42      0.898  0.110        0.863\n",
       "       43      0.896  0.113        0.903\n",
       "       44      0.925  0.200        0.929\n",
       "       45      0.821  0.082        0.864\n",
       "       46      0.876  0.087        0.865\n",
       "       47      0.871  0.093        0.897\n",
       "       48      0.875  0.141        0.904\n",
       "       49      0.917  0.135        0.893\n",
       "       50      0.844  0.050        0.743\n",
       "       51      0.936  0.146        0.894\n",
       "       52      0.841  0.053        0.706\n",
       "       53      0.862  0.075        0.860\n",
       "       54      0.932  0.159        0.906\n",
       "       55      0.900  0.123        0.904\n",
       "       56      0.923  0.123        0.911\n",
       "       57      0.890  0.128        0.884\n",
       "       58      0.930  0.117        0.903\n",
       "       59      0.891  0.126        0.870\n",
       "       60      0.935  0.158        0.906\n",
       "       61      0.879  0.088        0.858\n",
       "       62      0.825  0.055        0.729\n",
       "       63      0.861  0.100        0.861\n",
       "       64      0.896  0.116        0.881\n",
       "       65      0.880  0.127        0.885\n",
       "       66      0.816  0.065        0.721\n",
       "       67      0.903  0.120        0.895\n",
       "       68      0.858  0.052        0.719\n",
       "       69      0.884  0.152        0.900\n",
       "       70      0.913  0.086        0.867\n",
       "       71      0.853  0.047        0.715\n",
       "       72      0.913  0.137        0.909\n",
       "       73      0.888  0.155        0.892\n",
       "       74      0.901  0.081        0.874\n",
       "       75      0.901  0.132        0.906\n",
       "       76      0.928  0.113        0.905\n",
       "       77      0.888  0.113        0.865\n",
       "       78      0.942  0.135        0.909\n",
       "       79      0.863  0.057        0.716\n",
       "       80      0.931  0.117        0.897\n",
       "       81      0.901  0.124        0.906\n",
       "       82      0.835  0.053        0.724\n",
       "       83      0.920  0.065        0.841\n",
       "       84      0.907  0.108        0.843\n",
       "       85      0.882  0.166        0.908\n",
       "       86      0.936  0.151        0.911\n",
       "       87      0.919  0.125        0.906\n",
       "       88      0.903  0.114        0.872\n",
       "       89      0.910  0.155        0.903\n",
       "       90      0.880  0.076        0.845\n",
       "       91      0.897  0.096        0.852\n",
       "       92      0.926  0.123        0.898\n",
       "       93      0.922  0.103        0.891\n",
       "       94      0.919  0.125        0.895\n",
       "       95      0.920  0.130        0.916\n",
       "       96      0.863  0.068        0.846\n",
       "       97      0.935  0.133        0.898\n",
       "       98      0.894  0.137        0.861\n",
       "       99      0.862  0.066        0.745\n",
       "       100     0.811  0.042        0.737\n",
       "MICU   1       0.845  0.254        0.749\n",
       "       2       0.864  0.320        0.781\n",
       "       3       0.847  0.284        0.774\n",
       "       4       0.852  0.282        0.767\n",
       "       5       0.864  0.323        0.800\n",
       "       6       0.845  0.253        0.749\n",
       "       7       0.854  0.297        0.777\n",
       "       8       0.860  0.300        0.782\n",
       "       9       0.861  0.300        0.793\n",
       "       10      0.849  0.259        0.753\n",
       "       11      0.859  0.269        0.764\n",
       "       12      0.864  0.283        0.773\n",
       "       13      0.849  0.288        0.784\n",
       "       14      0.846  0.282        0.774\n",
       "       15      0.845  0.267        0.747\n",
       "       16      0.865  0.315        0.786\n",
       "       17      0.852  0.294        0.785\n",
       "       18      0.858  0.291        0.771\n",
       "       19      0.865  0.289        0.769\n",
       "       20      0.850  0.266        0.773\n",
       "       21      0.831  0.259        0.760\n",
       "       22      0.883  0.309        0.817\n",
       "       23      0.837  0.257        0.737\n",
       "       24      0.841  0.276        0.768\n",
       "       25      0.852  0.302        0.782\n",
       "       26      0.832  0.259        0.763\n",
       "       27      0.865  0.312        0.789\n",
       "       28      0.829  0.265        0.743\n",
       "       29      0.850  0.292        0.769\n",
       "       30      0.867  0.301        0.790\n",
       "       31      0.854  0.279        0.774\n",
       "       32      0.849  0.278        0.761\n",
       "       33      0.880  0.322        0.808\n",
       "       34      0.838  0.274        0.755\n",
       "       35      0.833  0.257        0.732\n",
       "       36      0.857  0.319        0.800\n",
       "       37      0.876  0.321        0.805\n",
       "       38      0.873  0.298        0.784\n",
       "       39      0.858  0.272        0.755\n",
       "       40      0.841  0.252        0.740\n",
       "       41      0.881  0.336        0.808\n",
       "       42      0.870  0.310        0.793\n",
       "       43      0.875  0.311        0.798\n",
       "       44      0.835  0.247        0.746\n",
       "       45      0.865  0.298        0.783\n",
       "       46      0.854  0.257        0.761\n",
       "       47      0.839  0.246        0.740\n",
       "       48      0.833  0.279        0.736\n",
       "       49      0.861  0.257        0.766\n",
       "       50      0.846  0.274        0.773\n",
       "       51      0.855  0.290        0.774\n",
       "       52      0.852  0.296        0.790\n",
       "       53      0.859  0.274        0.774\n",
       "       54      0.871  0.329        0.793\n",
       "       55      0.875  0.324        0.798\n",
       "       56      0.845  0.281        0.764\n",
       "       57      0.848  0.296        0.767\n",
       "       58      0.859  0.278        0.779\n",
       "       59      0.855  0.260        0.754\n",
       "       60      0.855  0.269        0.752\n",
       "       61      0.845  0.266        0.747\n",
       "       62      0.853  0.309        0.785\n",
       "       63      0.862  0.299        0.782\n",
       "       64      0.846  0.269        0.764\n",
       "       65      0.848  0.293        0.768\n",
       "       66      0.862  0.293        0.791\n",
       "       67      0.824  0.245        0.706\n",
       "       68      0.859  0.261        0.755\n",
       "       69      0.857  0.288        0.766\n",
       "       70      0.873  0.341        0.812\n",
       "       71      0.861  0.284        0.780\n",
       "       72      0.862  0.296        0.778\n",
       "       73      0.828  0.249        0.719\n",
       "       74      0.872  0.295        0.787\n",
       "       75      0.870  0.312        0.781\n",
       "       76      0.867  0.339        0.817\n",
       "       77      0.867  0.301        0.795\n",
       "       78      0.845  0.283        0.783\n",
       "       79      0.841  0.272        0.751\n",
       "       80      0.851  0.269        0.753\n",
       "       81      0.819  0.249        0.724\n",
       "       82      0.844  0.281        0.763\n",
       "       83      0.864  0.316        0.790\n",
       "       84      0.868  0.318        0.799\n",
       "       85      0.869  0.313        0.796\n",
       "       86      0.868  0.312        0.809\n",
       "       87      0.859  0.289        0.774\n",
       "       88      0.834  0.282        0.762\n",
       "       89      0.854  0.276        0.784\n",
       "       90      0.850  0.269        0.782\n",
       "       91      0.878  0.289        0.794\n",
       "       92      0.850  0.295        0.779\n",
       "       93      0.840  0.277        0.753\n",
       "       94      0.875  0.312        0.808\n",
       "       95      0.848  0.272        0.747\n",
       "       96      0.836  0.274        0.758\n",
       "       97      0.851  0.274        0.762\n",
       "       98      0.852  0.301        0.785\n",
       "       99      0.868  0.306        0.793\n",
       "       100     0.853  0.259        0.762\n",
       "SICU   1       0.832  0.221        0.703\n",
       "       2       0.809  0.144        0.598\n",
       "       3       0.796  0.164        0.617\n",
       "       4       0.777  0.177        0.586\n",
       "       5       0.837  0.240        0.723\n",
       "       6       0.820  0.232        0.729\n",
       "       7       0.849  0.252        0.773\n",
       "       8       0.819  0.191        0.717\n",
       "       9       0.862  0.267        0.777\n",
       "       10      0.801  0.140        0.590\n",
       "       11      0.785  0.155        0.567\n",
       "       12      0.837  0.238        0.721\n",
       "       13      0.851  0.300        0.815\n",
       "       14      0.809  0.191        0.702\n",
       "       15      0.810  0.169        0.653\n",
       "       16      0.850  0.206        0.712\n",
       "       17      0.848  0.244        0.735\n",
       "       18      0.838  0.245        0.737\n",
       "       19      0.811  0.253        0.717\n",
       "       20      0.856  0.278        0.775\n",
       "       21      0.852  0.246        0.737\n",
       "       22      0.824  0.229        0.721\n",
       "       23      0.830  0.185        0.640\n",
       "       24      0.822  0.237        0.716\n",
       "       25      0.827  0.249        0.735\n",
       "       26      0.840  0.242        0.748\n",
       "       27      0.830  0.238        0.739\n",
       "       28      0.834  0.196        0.669\n",
       "       29      0.834  0.230        0.708\n",
       "       30      0.816  0.234        0.737\n",
       "       31      0.810  0.207        0.725\n",
       "       32      0.820  0.190        0.663\n",
       "       33      0.831  0.227        0.753\n",
       "       34      0.752  0.146        0.531\n",
       "       35      0.765  0.130        0.546\n",
       "       36      0.847  0.215        0.740\n",
       "       37      0.840  0.206        0.725\n",
       "       38      0.793  0.159        0.552\n",
       "       39      0.776  0.150        0.543\n",
       "       40      0.840  0.281        0.763\n",
       "       41      0.867  0.298        0.814\n",
       "       42      0.829  0.242        0.733\n",
       "       43      0.831  0.194        0.668\n",
       "       44      0.808  0.194        0.668\n",
       "       45      0.805  0.214        0.711\n",
       "       46      0.809  0.195        0.726\n",
       "       47      0.853  0.216        0.747\n",
       "       48      0.830  0.224        0.716\n",
       "       49      0.839  0.228        0.747\n",
       "       50      0.800  0.211        0.647\n",
       "       51      0.783  0.154        0.584\n",
       "       52      0.837  0.202        0.711\n",
       "       53      0.824  0.207        0.732\n",
       "       54      0.777  0.173        0.551\n",
       "       55      0.819  0.257        0.732\n",
       "       56      0.864  0.229        0.763\n",
       "       57      0.835  0.225        0.737\n",
       "       58      0.836  0.255        0.742\n",
       "       59      0.851  0.218        0.747\n",
       "       60      0.868  0.347        0.823\n",
       "       61      0.787  0.166        0.592\n",
       "       62      0.781  0.163        0.572\n",
       "       63      0.827  0.245        0.758\n",
       "       64      0.757  0.157        0.510\n",
       "       65      0.834  0.269        0.757\n",
       "       66      0.837  0.251        0.728\n",
       "       67      0.807  0.183        0.616\n",
       "       68      0.805  0.189        0.634\n",
       "       69      0.828  0.230        0.736\n",
       "       70      0.836  0.216        0.733\n",
       "       71      0.782  0.154        0.587\n",
       "       72      0.846  0.289        0.790\n",
       "       73      0.738  0.146        0.538\n",
       "       74      0.864  0.245        0.761\n",
       "       75      0.777  0.174        0.603\n",
       "       76      0.794  0.168        0.546\n",
       "       77      0.816  0.200        0.665\n",
       "       78      0.842  0.241        0.720\n",
       "       79      0.822  0.167        0.650\n",
       "       80      0.831  0.259        0.729\n",
       "       81      0.841  0.247        0.742\n",
       "       82      0.826  0.223        0.707\n",
       "       83      0.786  0.157        0.581\n",
       "       84      0.856  0.195        0.740\n",
       "       85      0.820  0.165        0.656\n",
       "       86      0.806  0.157        0.617\n",
       "       87      0.833  0.231        0.738\n",
       "       88      0.815  0.185        0.627\n",
       "       89      0.808  0.188        0.670\n",
       "       90      0.807  0.203        0.663\n",
       "       91      0.809  0.181        0.647\n",
       "       92      0.787  0.158        0.557\n",
       "       93      0.804  0.186        0.651\n",
       "       94      0.846  0.246        0.739\n",
       "       95      0.847  0.235        0.761\n",
       "       96      0.818  0.245        0.726\n",
       "       97      0.806  0.159        0.588\n",
       "       98      0.781  0.182        0.632\n",
       "       99      0.838  0.227        0.740\n",
       "       100     0.826  0.239        0.687\n",
       "TSICU  1       0.857  0.188        0.781\n",
       "       2       0.867  0.263        0.766\n",
       "       3       0.835  0.142        0.651\n",
       "       4       0.845  0.137        0.663\n",
       "       5       0.891  0.273        0.834\n",
       "       6       0.857  0.154        0.703\n",
       "       7       0.857  0.202        0.778\n",
       "       8       0.872  0.248        0.779\n",
       "       9       0.865  0.163        0.679\n",
       "       10      0.851  0.129        0.662\n",
       "       11      0.845  0.153        0.667\n",
       "       12      0.864  0.229        0.773\n",
       "       13      0.895  0.257        0.810\n",
       "       14      0.843  0.183        0.692\n",
       "       15      0.845  0.180        0.708\n",
       "       16      0.871  0.207        0.772\n",
       "       17      0.864  0.241        0.773\n",
       "       18      0.863  0.220        0.818\n",
       "       19      0.816  0.166        0.661\n",
       "       20      0.870  0.289        0.773\n",
       "       21      0.866  0.233        0.752\n",
       "       22      0.890  0.235        0.807\n",
       "       23      0.865  0.246        0.793\n",
       "       24      0.903  0.265        0.811\n",
       "       25      0.835  0.167        0.658\n",
       "       26      0.866  0.186        0.714\n",
       "       27      0.814  0.148        0.627\n",
       "       28      0.913  0.329        0.870\n",
       "       29      0.826  0.145        0.657\n",
       "       30      0.856  0.166        0.683\n",
       "       31      0.869  0.238        0.790\n",
       "       32      0.893  0.211        0.770\n",
       "       33      0.871  0.251        0.785\n",
       "       34      0.862  0.257        0.774\n",
       "       35      0.880  0.181        0.790\n",
       "       36      0.848  0.214        0.750\n",
       "       37      0.890  0.268        0.821\n",
       "       38      0.877  0.183        0.758\n",
       "       39      0.871  0.217        0.793\n",
       "       40      0.850  0.205        0.756\n",
       "       41      0.858  0.227        0.785\n",
       "       42      0.891  0.269        0.824\n",
       "       43      0.849  0.184        0.688\n",
       "       44      0.834  0.143        0.683\n",
       "       45      0.831  0.132        0.647\n",
       "       46      0.836  0.157        0.683\n",
       "       47      0.901  0.277        0.850\n",
       "       48      0.856  0.175        0.758\n",
       "       49      0.838  0.168        0.689\n",
       "       50      0.818  0.171        0.668\n",
       "       51      0.861  0.227        0.774\n",
       "       52      0.901  0.313        0.866\n",
       "       53      0.887  0.180        0.753\n",
       "       54      0.872  0.226        0.762\n",
       "       55      0.844  0.143        0.676\n",
       "       56      0.865  0.196        0.756\n",
       "       57      0.838  0.217        0.725\n",
       "       58      0.869  0.197        0.797\n",
       "       59      0.864  0.214        0.763\n",
       "       60      0.818  0.146        0.667\n",
       "       61      0.867  0.256        0.802\n",
       "       62      0.837  0.193        0.662\n",
       "       63      0.863  0.255        0.792\n",
       "       64      0.879  0.286        0.858\n",
       "       65      0.882  0.241        0.819\n",
       "       66      0.866  0.236        0.769\n",
       "       67      0.874  0.240        0.815\n",
       "       68      0.845  0.205        0.767\n",
       "       69      0.857  0.254        0.767\n",
       "       70      0.867  0.267        0.800\n",
       "       71      0.864  0.167        0.695\n",
       "       72      0.862  0.180        0.679\n",
       "       73      0.893  0.306        0.849\n",
       "       74      0.858  0.202        0.774\n",
       "       75      0.862  0.217        0.757\n",
       "       76      0.878  0.243        0.774\n",
       "       77      0.896  0.292        0.829\n",
       "       78      0.887  0.246        0.782\n",
       "       79      0.856  0.173        0.687\n",
       "       80      0.846  0.187        0.744\n",
       "       81      0.849  0.154        0.672\n",
       "       82      0.897  0.288        0.816\n",
       "       83      0.870  0.242        0.781\n",
       "       84      0.891  0.311        0.821\n",
       "       85      0.847  0.185        0.686\n",
       "       86      0.844  0.153        0.686\n",
       "       87      0.884  0.276        0.805\n",
       "       88      0.884  0.242        0.785\n",
       "       89      0.823  0.167        0.663\n",
       "       90      0.869  0.180        0.717\n",
       "       91      0.893  0.292        0.826\n",
       "       92      0.830  0.172        0.671\n",
       "       93      0.838  0.187        0.670\n",
       "       94      0.852  0.170        0.691\n",
       "       95      0.877  0.215        0.755\n",
       "       96      0.885  0.243        0.798\n",
       "       97      0.863  0.228        0.791\n",
       "       98      0.874  0.176        0.706\n",
       "       99      0.860  0.205        0.766\n",
       "       100     0.870  0.227        0.770\n",
       "Micro  1       0.862  0.218        0.770\n",
       "       2       0.869  0.228        0.783\n",
       "       3       0.867  0.223        0.777\n",
       "       4       0.857  0.206        0.752\n",
       "       5       0.869  0.219        0.772\n",
       "       6       0.865  0.214        0.764\n",
       "       7       0.865  0.218        0.770\n",
       "       8       0.881  0.270        0.826\n",
       "       9       0.854  0.204        0.751\n",
       "       10      0.870  0.223        0.776\n",
       "       11      0.854  0.200        0.743\n",
       "       12      0.874  0.234        0.790\n",
       "       13      0.864  0.225        0.778\n",
       "       14      0.873  0.249        0.806\n",
       "       15      0.865  0.232        0.787\n",
       "       16      0.877  0.239        0.796\n",
       "       17      0.875  0.238        0.794\n",
       "       18      0.854  0.200        0.743\n",
       "       19      0.857  0.221        0.774\n",
       "       20      0.874  0.239        0.795\n",
       "       21      0.873  0.223        0.776\n",
       "       22      0.862  0.228        0.782\n",
       "       23      0.862  0.221        0.774\n",
       "       24      0.869  0.227        0.783\n",
       "       25      0.881  0.246        0.804\n",
       "       26      0.873  0.233        0.789\n",
       "       27      0.866  0.229        0.783\n",
       "       28      0.852  0.206        0.751\n",
       "       29      0.848  0.204        0.750\n",
       "       30      0.862  0.220        0.772\n",
       "       31      0.866  0.222        0.775\n",
       "       32      0.862  0.206        0.752\n",
       "       33      0.865  0.223        0.777\n",
       "       34      0.882  0.262        0.819\n",
       "       35      0.858  0.219        0.773\n",
       "       36      0.849  0.217        0.769\n",
       "       37      0.863  0.220        0.773\n",
       "       38      0.872  0.266        0.823\n",
       "       39      0.887  0.278        0.833\n",
       "       40      0.866  0.220        0.772\n",
       "       41      0.854  0.201        0.744\n",
       "       42      0.868  0.224        0.778\n",
       "       43      0.871  0.238        0.795\n",
       "       44      0.861  0.214        0.764\n",
       "       45      0.853  0.208        0.757\n",
       "       46      0.863  0.215        0.765\n",
       "       47      0.853  0.209        0.757\n",
       "       48      0.881  0.259        0.816\n",
       "       49      0.863  0.218        0.771\n",
       "       50      0.856  0.219        0.771\n",
       "       51      0.840  0.191        0.728\n",
       "       52      0.862  0.220        0.771\n",
       "       53      0.878  0.243        0.800\n",
       "       54      0.861  0.201        0.745\n",
       "       55      0.862  0.212        0.762\n",
       "       56      0.873  0.232        0.788\n",
       "       57      0.867  0.226        0.780\n",
       "       58      0.859  0.225        0.778\n",
       "       59      0.864  0.227        0.781\n",
       "       60      0.868  0.239        0.796\n",
       "       61      0.870  0.232        0.788\n",
       "       62      0.856  0.218        0.769\n",
       "       63      0.857  0.215        0.766\n",
       "       64      0.869  0.237        0.794\n",
       "       65      0.857  0.201        0.744\n",
       "       66      0.865  0.220        0.772\n",
       "       67      0.861  0.221        0.775\n",
       "       68      0.868  0.231        0.786\n",
       "       69      0.875  0.228        0.783\n",
       "       70      0.857  0.223        0.777\n",
       "       71      0.864  0.224        0.779\n",
       "       72      0.873  0.225        0.778\n",
       "       73      0.873  0.234        0.790\n",
       "       74      0.860  0.209        0.757\n",
       "       75      0.859  0.225        0.779\n",
       "       76      0.872  0.229        0.784\n",
       "       77      0.873  0.228        0.783\n",
       "       78      0.855  0.199        0.742\n",
       "       79      0.873  0.254        0.811\n",
       "       80      0.871  0.239        0.797\n",
       "       81      0.876  0.242        0.798\n",
       "       82      0.867  0.233        0.789\n",
       "       83      0.883  0.256        0.814\n",
       "       84      0.878  0.248        0.804\n",
       "       85      0.867  0.229        0.783\n",
       "       86      0.863  0.229        0.784\n",
       "       87      0.872  0.221        0.773\n",
       "       88      0.868  0.226        0.781\n",
       "       89      0.880  0.271        0.827\n",
       "       90      0.860  0.218        0.770\n",
       "       91      0.867  0.238        0.795\n",
       "       92      0.859  0.211        0.760\n",
       "       93      0.877  0.233        0.789\n",
       "       94      0.881  0.262        0.819\n",
       "       95      0.875  0.231        0.786\n",
       "       96      0.867  0.221        0.773\n",
       "       97      0.867  0.225        0.778\n",
       "       98      0.876  0.254        0.812\n",
       "       99      0.882  0.261        0.818\n",
       "       100     0.867  0.216        0.768\n",
       "Macro  1       0.861  0.185        0.774\n",
       "       2       0.829  0.151        0.686\n",
       "       3       0.840  0.188        0.740\n",
       "       4       0.844  0.165        0.715\n",
       "       5       0.859  0.196        0.765\n",
       "       6       0.866  0.217        0.791\n",
       "       7       0.840  0.175        0.728\n",
       "       8       0.829  0.165        0.711\n",
       "       9       0.861  0.206        0.781\n",
       "       10      0.860  0.205        0.785\n",
       "       11      0.855  0.206        0.783\n",
       "       12      0.830  0.185        0.720\n",
       "       13      0.850  0.189        0.727\n",
       "       14      0.858  0.213        0.779\n",
       "       15      0.845  0.202        0.763\n",
       "       16      0.843  0.199        0.756\n",
       "       17      0.843  0.178        0.721\n",
       "       18      0.854  0.213        0.800\n",
       "       19      0.838  0.192        0.749\n",
       "       20      0.844  0.178        0.740\n",
       "       21      0.853  0.199        0.762\n",
       "       22      0.858  0.208        0.767\n",
       "       23      0.838  0.180        0.706\n",
       "       24      0.841  0.152        0.701\n",
       "       25      0.857  0.195        0.766\n",
       "       26      0.840  0.179        0.732\n",
       "       27      0.851  0.190        0.755\n",
       "       28      0.869  0.222        0.810\n",
       "       29      0.838  0.193        0.738\n",
       "       30      0.838  0.180        0.716\n",
       "       31      0.853  0.204        0.784\n",
       "       32      0.866  0.209        0.780\n",
       "       33      0.861  0.182        0.738\n",
       "       34      0.825  0.177        0.733\n",
       "       35      0.835  0.153        0.685\n",
       "       36      0.850  0.203        0.767\n",
       "       37      0.875  0.219        0.806\n",
       "       38      0.866  0.214        0.778\n",
       "       39      0.867  0.204        0.776\n",
       "       40      0.851  0.197        0.748\n",
       "       41      0.843  0.190        0.764\n",
       "       42      0.834  0.160        0.727\n",
       "       43      0.868  0.204        0.797\n",
       "       44      0.847  0.192        0.762\n",
       "       45      0.849  0.184        0.753\n",
       "       46      0.856  0.210        0.767\n",
       "       47      0.828  0.168        0.706\n",
       "       48      0.857  0.195        0.751\n",
       "       49      0.857  0.209        0.758\n",
       "       50      0.854  0.173        0.764\n",
       "       51      0.860  0.211        0.749\n",
       "       52      0.857  0.200        0.764\n",
       "       53      0.859  0.196        0.779\n",
       "       54      0.846  0.194        0.747\n",
       "       55      0.862  0.195        0.784\n",
       "       56      0.860  0.199        0.775\n",
       "       57      0.855  0.176        0.755\n",
       "       58      0.859  0.213        0.766\n",
       "       59      0.839  0.177        0.730\n",
       "       60      0.830  0.182        0.709\n",
       "       61      0.860  0.226        0.807\n",
       "       62      0.840  0.194        0.742\n",
       "       63      0.854  0.213        0.782\n",
       "       64      0.843  0.197        0.739\n",
       "       65      0.842  0.191        0.746\n",
       "       66      0.831  0.161        0.702\n",
       "       67      0.856  0.224        0.782\n",
       "       68      0.853  0.185        0.751\n",
       "       69      0.866  0.209        0.788\n",
       "       70      0.840  0.162        0.700\n",
       "       71      0.868  0.210        0.775\n",
       "       72      0.838  0.195        0.746\n",
       "       73      0.867  0.195        0.779\n",
       "       74      0.851  0.200        0.755\n",
       "       75      0.860  0.197        0.739\n",
       "       76      0.859  0.210        0.774\n",
       "       77      0.873  0.222        0.788\n",
       "       78      0.846  0.170        0.705\n",
       "       79      0.858  0.198        0.782\n",
       "       80      0.854  0.193        0.760\n",
       "       81      0.848  0.181        0.749\n",
       "       82      0.854  0.201        0.748\n",
       "       83      0.856  0.193        0.756\n",
       "       84      0.862  0.216        0.770\n",
       "       85      0.855  0.195        0.758\n",
       "       86      0.858  0.185        0.747\n",
       "       87      0.867  0.212        0.788\n",
       "       88      0.839  0.190        0.732\n",
       "       89      0.839  0.184        0.729\n",
       "       90      0.858  0.202        0.770\n",
       "       91      0.850  0.175        0.744\n",
       "       92      0.869  0.203        0.775\n",
       "       93      0.850  0.197        0.747\n",
       "       94      0.848  0.185        0.739\n",
       "       95      0.856  0.190        0.749\n",
       "       96      0.868  0.207        0.784\n",
       "       97      0.842  0.195        0.767\n",
       "       98      0.857  0.181        0.742\n",
       "       99      0.846  0.184        0.734\n",
       "       100     0.839  0.175        0.717"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_mtl_18_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00efa1-fc2a-4a82-b443-4b4ced5f7f74",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c8284e-e848-4c66-8217-e33f9badb079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 18]...\n",
      "        New X_discrete.shape: (618101, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 18 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1205 out of 11636\n",
      "        SICU: 443 out of 5271\n",
      "        CCU: 365 out of 5030\n",
      "        CSRU: 151 out of 7001\n",
      "        TSICU: 315 out of 4324\n",
      "    Final shape of X: (33262, 18, 232)\n",
      "    Number of positive samples: 2479\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort 0 is 10104\n",
      "        # of patients in cohort 1 is 5485\n",
      "        # of patients in cohort 2 is 7693\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'multitask' model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"multitask_learning_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 18, 232)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 16)           15936       ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " 0 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " 1 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " 2 (Dense)                      (None, 1)            17          ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,987\n",
      "Trainable params: 15,987\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 11s 39ms/step - loss: 0.3967 - 0_loss: 0.1683 - 1_loss: 0.0866 - 2_loss: 0.1418 - 0_accuracy: 0.9238 - 1_accuracy: 0.9096 - 2_accuracy: 0.8870 - val_loss: 0.8540 - val_0_loss: 0.2784 - val_1_loss: 0.2809 - val_2_loss: 0.2946 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9252 - val_2_accuracy: 0.9255\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.2622 - 0_loss: 0.1188 - 1_loss: 0.0500 - 2_loss: 0.0934 - 0_accuracy: 0.9255 - 1_accuracy: 0.9255 - 2_accuracy: 0.9254 - val_loss: 0.7647 - val_0_loss: 0.2569 - val_1_loss: 0.2520 - val_2_loss: 0.2558 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9255 - val_2_accuracy: 0.9255\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 8s 35ms/step - loss: 0.2415 - 0_loss: 0.1114 - 1_loss: 0.0464 - 2_loss: 0.0838 - 0_accuracy: 0.9255 - 1_accuracy: 0.9255 - 2_accuracy: 0.9255 - val_loss: 0.7245 - val_0_loss: 0.2439 - val_1_loss: 0.2395 - val_2_loss: 0.2411 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9255 - val_2_accuracy: 0.9255\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.2306 - 0_loss: 0.1070 - 1_loss: 0.0445 - 2_loss: 0.0792 - 0_accuracy: 0.9255 - 1_accuracy: 0.9255 - 2_accuracy: 0.9254 - val_loss: 0.7020 - val_0_loss: 0.2362 - val_1_loss: 0.2327 - val_2_loss: 0.2331 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9258 - val_2_accuracy: 0.9252\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 8s 35ms/step - loss: 0.2234 - 0_loss: 0.1041 - 1_loss: 0.0432 - 2_loss: 0.0761 - 0_accuracy: 0.9255 - 1_accuracy: 0.9255 - 2_accuracy: 0.9255 - val_loss: 0.6872 - val_0_loss: 0.2297 - val_1_loss: 0.2276 - val_2_loss: 0.2300 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9258 - val_2_accuracy: 0.9252\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.2178 - 0_loss: 0.1017 - 1_loss: 0.0421 - 2_loss: 0.0739 - 0_accuracy: 0.9255 - 1_accuracy: 0.9256 - 2_accuracy: 0.9257 - val_loss: 0.6830 - val_0_loss: 0.2297 - val_1_loss: 0.2276 - val_2_loss: 0.2257 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9264 - val_2_accuracy: 0.9261\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.2135 - 0_loss: 0.1001 - 1_loss: 0.0413 - 2_loss: 0.0721 - 0_accuracy: 0.9255 - 1_accuracy: 0.9259 - 2_accuracy: 0.9259 - val_loss: 0.6710 - val_0_loss: 0.2234 - val_1_loss: 0.2223 - val_2_loss: 0.2253 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9267 - val_2_accuracy: 0.9267\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.2099 - 0_loss: 0.0986 - 1_loss: 0.0406 - 2_loss: 0.0707 - 0_accuracy: 0.9255 - 1_accuracy: 0.9264 - 2_accuracy: 0.9261 - val_loss: 0.6598 - val_0_loss: 0.2211 - val_1_loss: 0.2191 - val_2_loss: 0.2196 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9267 - val_2_accuracy: 0.9267\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 8s 34ms/step - loss: 0.2062 - 0_loss: 0.0969 - 1_loss: 0.0401 - 2_loss: 0.0692 - 0_accuracy: 0.9255 - 1_accuracy: 0.9269 - 2_accuracy: 0.9265 - val_loss: 0.6548 - val_0_loss: 0.2189 - val_1_loss: 0.2175 - val_2_loss: 0.2183 - val_0_accuracy: 0.9255 - val_1_accuracy: 0.9282 - val_2_accuracy: 0.9279\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.2032 - 0_loss: 0.0954 - 1_loss: 0.0395 - 2_loss: 0.0683 - 0_accuracy: 0.9257 - 1_accuracy: 0.9274 - 2_accuracy: 0.9268 - val_loss: 0.6496 - val_0_loss: 0.2172 - val_1_loss: 0.2159 - val_2_loss: 0.2164 - val_0_accuracy: 0.9252 - val_1_accuracy: 0.9288 - val_2_accuracy: 0.9282\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 8s 34ms/step - loss: 0.1999 - 0_loss: 0.0939 - 1_loss: 0.0389 - 2_loss: 0.0672 - 0_accuracy: 0.9262 - 1_accuracy: 0.9278 - 2_accuracy: 0.9273 - val_loss: 0.6458 - val_0_loss: 0.2148 - val_1_loss: 0.2149 - val_2_loss: 0.2161 - val_0_accuracy: 0.9258 - val_1_accuracy: 0.9297 - val_2_accuracy: 0.9288\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 9s 38ms/step - loss: 0.1972 - 0_loss: 0.0926 - 1_loss: 0.0385 - 2_loss: 0.0662 - 0_accuracy: 0.9270 - 1_accuracy: 0.9286 - 2_accuracy: 0.9281 - val_loss: 0.6434 - val_0_loss: 0.2129 - val_1_loss: 0.2138 - val_2_loss: 0.2167 - val_0_accuracy: 0.9264 - val_1_accuracy: 0.9303 - val_2_accuracy: 0.9285\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1945 - 0_loss: 0.0912 - 1_loss: 0.0380 - 2_loss: 0.0653 - 0_accuracy: 0.9281 - 1_accuracy: 0.9287 - 2_accuracy: 0.9284 - val_loss: 0.6373 - val_0_loss: 0.2116 - val_1_loss: 0.2120 - val_2_loss: 0.2137 - val_0_accuracy: 0.9285 - val_1_accuracy: 0.9300 - val_2_accuracy: 0.9300\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.1921 - 0_loss: 0.0901 - 1_loss: 0.0376 - 2_loss: 0.0644 - 0_accuracy: 0.9286 - 1_accuracy: 0.9287 - 2_accuracy: 0.9291 - val_loss: 0.6423 - val_0_loss: 0.2112 - val_1_loss: 0.2132 - val_2_loss: 0.2179 - val_0_accuracy: 0.9294 - val_1_accuracy: 0.9309 - val_2_accuracy: 0.9309\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1901 - 0_loss: 0.0890 - 1_loss: 0.0374 - 2_loss: 0.0637 - 0_accuracy: 0.9290 - 1_accuracy: 0.9289 - 2_accuracy: 0.9300 - val_loss: 0.6346 - val_0_loss: 0.2106 - val_1_loss: 0.2110 - val_2_loss: 0.2130 - val_0_accuracy: 0.9282 - val_1_accuracy: 0.9288 - val_2_accuracy: 0.9309\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.1880 - 0_loss: 0.0881 - 1_loss: 0.0369 - 2_loss: 0.0629 - 0_accuracy: 0.9301 - 1_accuracy: 0.9295 - 2_accuracy: 0.9305 - val_loss: 0.6389 - val_0_loss: 0.2122 - val_1_loss: 0.2145 - val_2_loss: 0.2122 - val_0_accuracy: 0.9282 - val_1_accuracy: 0.9276 - val_2_accuracy: 0.9306\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.1860 - 0_loss: 0.0872 - 1_loss: 0.0367 - 2_loss: 0.0621 - 0_accuracy: 0.9301 - 1_accuracy: 0.9301 - 2_accuracy: 0.9310 - val_loss: 0.6335 - val_0_loss: 0.2099 - val_1_loss: 0.2116 - val_2_loss: 0.2119 - val_0_accuracy: 0.9288 - val_1_accuracy: 0.9288 - val_2_accuracy: 0.9309\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.1844 - 0_loss: 0.0864 - 1_loss: 0.0365 - 2_loss: 0.0615 - 0_accuracy: 0.9307 - 1_accuracy: 0.9300 - 2_accuracy: 0.9313 - val_loss: 0.6355 - val_0_loss: 0.2094 - val_1_loss: 0.2122 - val_2_loss: 0.2139 - val_0_accuracy: 0.9291 - val_1_accuracy: 0.9294 - val_2_accuracy: 0.9312\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1828 - 0_loss: 0.0856 - 1_loss: 0.0362 - 2_loss: 0.0610 - 0_accuracy: 0.9309 - 1_accuracy: 0.9297 - 2_accuracy: 0.9319 - val_loss: 0.6368 - val_0_loss: 0.2110 - val_1_loss: 0.2129 - val_2_loss: 0.2129 - val_0_accuracy: 0.9282 - val_1_accuracy: 0.9261 - val_2_accuracy: 0.9297\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 8s 35ms/step - loss: 0.1815 - 0_loss: 0.0850 - 1_loss: 0.0360 - 2_loss: 0.0605 - 0_accuracy: 0.9308 - 1_accuracy: 0.9293 - 2_accuracy: 0.9318 - val_loss: 0.6411 - val_0_loss: 0.2100 - val_1_loss: 0.2167 - val_2_loss: 0.2144 - val_0_accuracy: 0.9291 - val_1_accuracy: 0.9267 - val_2_accuracy: 0.9303\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 9s 37ms/step - loss: 0.1804 - 0_loss: 0.0844 - 1_loss: 0.0358 - 2_loss: 0.0602 - 0_accuracy: 0.9317 - 1_accuracy: 0.9297 - 2_accuracy: 0.9317 - val_loss: 0.6427 - val_0_loss: 0.2102 - val_1_loss: 0.2194 - val_2_loss: 0.2131 - val_0_accuracy: 0.9294 - val_1_accuracy: 0.9252 - val_2_accuracy: 0.9303\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_multitask_18+9_unsupervised/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'multitask' model...\n",
      "208/208 [==============================] - 1s 5ms/step\n",
      "    Bootstrap prediction for task \"0\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30db4cc328fe4b268d7dfbee43d03936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"1\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74ac0d160ec4877802fca6cd97ec7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"2\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11112f2ff6834071bdd22d508acb9796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5daf226d4c949c482d2f64a6833a910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 03:01:44.731822: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 211.97MiB (rounded to 222263552)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-12 03:01:44.732130: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***********************_**************************************************************************__\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/Documents/repo/dl4h-sp23-team27-project/notebooks/../code/mtl_patients.py:1428\u001b[0m, in \u001b[0;36mrun_mortality_prediction_task\u001b[0;34m(model_type, cutoff_hours, gap_hours, save_to_folder, cohort_criteria_to_select, seed, cohort_unsupervised_filename, lstm_layer_size, epochs, learning_rate, use_cohort_inv_freq_weights, bootstrap, num_bootstrapped_samples, sensitivity)\u001b[0m\n\u001b[1;32m   1425\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics_df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohort != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and Cohort != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;66;03m# calculate micro metrics\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m all_auc, all_ppv, all_specificity \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohorts_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bootstrap_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_bootstrapped_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1430\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_auc\n\u001b[1;32m   1431\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPV\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_ppv\n",
      "File \u001b[0;32m~/Documents/repo/dl4h-sp23-team27-project/notebooks/../code/mtl_patients.py:952\u001b[0m, in \u001b[0;36mbootstrap_predict\u001b[0;34m(X_test, y_test, cohorts_test, task, model, tasks, num_bootstrap_samples, sensitivity)\u001b[0m\n\u001b[1;32m    949\u001b[0m     cohorts_bootstrap_sample_task \u001b[38;5;241m=\u001b[39m cohorts_bootstrap_sample\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# run prediction for the bootstrap sample\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m y_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap_sample_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_scores) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_bootstrap_sample_task):\n\u001b[1;32m    954\u001b[0m     y_scores \u001b[38;5;241m=\u001b[39m get_correct_task_mtl_outputs(y_scores, cohorts_bootstrap_sample_task, tasks)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_mtl_18_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=18, gap_hours=9, bootstrap=True,\n",
    "                                                                      cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_18.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd74593-7bef-48c1-ba78-c6114a5ea6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.917</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.813</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Micro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"100\" valign=\"top\">Macro</th>\n",
       "      <th>1</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.860</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AUC    PPV  Specificity\n",
       "Cohort Sample                           \n",
       "0      1       0.854  0.257        0.797\n",
       "       2       0.847  0.236        0.770\n",
       "       3       0.833  0.204        0.734\n",
       "       4       0.859  0.252        0.790\n",
       "       5       0.856  0.243        0.776\n",
       "       6       0.850  0.226        0.764\n",
       "       7       0.871  0.281        0.822\n",
       "       8       0.852  0.286        0.829\n",
       "       9       0.877  0.249        0.782\n",
       "       10      0.865  0.268        0.791\n",
       "       11      0.853  0.266        0.803\n",
       "       12      0.869  0.280        0.809\n",
       "       13      0.877  0.310        0.833\n",
       "       14      0.878  0.297        0.832\n",
       "       15      0.859  0.261        0.787\n",
       "       16      0.876  0.274        0.811\n",
       "       17      0.860  0.230        0.764\n",
       "       18      0.859  0.265        0.805\n",
       "       19      0.872  0.278        0.824\n",
       "       20      0.868  0.278        0.804\n",
       "       21      0.864  0.250        0.801\n",
       "       22      0.856  0.239        0.787\n",
       "       23      0.853  0.225        0.771\n",
       "       24      0.881  0.274        0.815\n",
       "       25      0.866  0.277        0.831\n",
       "       26      0.841  0.210        0.740\n",
       "       27      0.849  0.231        0.761\n",
       "       28      0.884  0.288        0.818\n",
       "       29      0.860  0.243        0.783\n",
       "       30      0.859  0.254        0.777\n",
       "       31      0.837  0.208        0.743\n",
       "       32      0.846  0.216        0.752\n",
       "       33      0.875  0.270        0.819\n",
       "       34      0.866  0.276        0.815\n",
       "       35      0.866  0.273        0.801\n",
       "       36      0.859  0.243        0.770\n",
       "       37      0.840  0.238        0.758\n",
       "       38      0.854  0.264        0.804\n",
       "       39      0.834  0.230        0.767\n",
       "       40      0.854  0.257        0.776\n",
       "       41      0.860  0.260        0.801\n",
       "       42      0.868  0.296        0.814\n",
       "       43      0.858  0.222        0.767\n",
       "       44      0.843  0.218        0.764\n",
       "       45      0.848  0.247        0.780\n",
       "       46      0.833  0.213        0.734\n",
       "       47      0.871  0.280        0.804\n",
       "       48      0.861  0.245        0.765\n",
       "       49      0.863  0.264        0.789\n",
       "       50      0.853  0.233        0.764\n",
       "       51      0.850  0.232        0.763\n",
       "       52      0.839  0.259        0.766\n",
       "       53      0.871  0.279        0.808\n",
       "       54      0.853  0.259        0.783\n",
       "       55      0.881  0.282        0.825\n",
       "       56      0.845  0.224        0.755\n",
       "       57      0.865  0.261        0.801\n",
       "       58      0.851  0.247        0.782\n",
       "       59      0.850  0.243        0.770\n",
       "       60      0.855  0.247        0.781\n",
       "       61      0.857  0.227        0.737\n",
       "       62      0.876  0.265        0.815\n",
       "       63      0.864  0.251        0.803\n",
       "       64      0.860  0.251        0.786\n",
       "       65      0.854  0.223        0.758\n",
       "       66      0.859  0.258        0.793\n",
       "       67      0.853  0.246        0.763\n",
       "       68      0.858  0.217        0.769\n",
       "       69      0.850  0.235        0.771\n",
       "       70      0.841  0.217        0.744\n",
       "       71      0.891  0.288        0.816\n",
       "       72      0.864  0.257        0.792\n",
       "       73      0.865  0.284        0.811\n",
       "       74      0.857  0.232        0.774\n",
       "       75      0.861  0.232        0.764\n",
       "       76      0.871  0.274        0.813\n",
       "       77      0.850  0.237        0.770\n",
       "       78      0.856  0.243        0.784\n",
       "       79      0.858  0.252        0.777\n",
       "       80      0.842  0.225        0.757\n",
       "       81      0.846  0.223        0.770\n",
       "       82      0.847  0.236        0.764\n",
       "       83      0.834  0.209        0.722\n",
       "       84      0.852  0.237        0.785\n",
       "       85      0.879  0.309        0.829\n",
       "       86      0.875  0.280        0.818\n",
       "       87      0.862  0.250        0.800\n",
       "       88      0.834  0.247        0.785\n",
       "       89      0.852  0.225        0.750\n",
       "       90      0.866  0.263        0.810\n",
       "       91      0.864  0.261        0.801\n",
       "       92      0.871  0.289        0.816\n",
       "       93      0.849  0.213        0.744\n",
       "       94      0.869  0.252        0.797\n",
       "       95      0.866  0.256        0.795\n",
       "       96      0.867  0.252        0.796\n",
       "       97      0.854  0.239        0.764\n",
       "       98      0.842  0.223        0.756\n",
       "       99      0.855  0.220        0.764\n",
       "       100     0.872  0.315        0.852\n",
       "1      1       0.901  0.268        0.823\n",
       "       2       0.907  0.272        0.822\n",
       "       3       0.929  0.388        0.906\n",
       "       4       0.916  0.299        0.864\n",
       "       5       0.923  0.352        0.888\n",
       "       6       0.890  0.220        0.805\n",
       "       7       0.919  0.285        0.844\n",
       "       8       0.901  0.212        0.801\n",
       "       9       0.886  0.184        0.786\n",
       "       10      0.926  0.244        0.863\n",
       "       11      0.919  0.282        0.873\n",
       "       12      0.895  0.234        0.810\n",
       "       13      0.917  0.284        0.864\n",
       "       14      0.894  0.254        0.818\n",
       "       15      0.911  0.221        0.822\n",
       "       16      0.927  0.296        0.870\n",
       "       17      0.897  0.219        0.802\n",
       "       18      0.924  0.278        0.854\n",
       "       19      0.907  0.335        0.881\n",
       "       20      0.923  0.357        0.890\n",
       "       21      0.876  0.144        0.732\n",
       "       22      0.903  0.246        0.825\n",
       "       23      0.902  0.266        0.835\n",
       "       24      0.905  0.213        0.820\n",
       "       25      0.899  0.246        0.821\n",
       "       26      0.893  0.209        0.788\n",
       "       27      0.905  0.225        0.808\n",
       "       28      0.909  0.300        0.884\n",
       "       29      0.901  0.204        0.788\n",
       "       30      0.907  0.266        0.841\n",
       "       31      0.899  0.235        0.845\n",
       "       32      0.910  0.249        0.835\n",
       "       33      0.925  0.282        0.886\n",
       "       34      0.912  0.303        0.860\n",
       "       35      0.914  0.276        0.843\n",
       "       36      0.928  0.342        0.898\n",
       "       37      0.920  0.328        0.877\n",
       "       38      0.902  0.222        0.804\n",
       "       39      0.906  0.251        0.814\n",
       "       40      0.891  0.220        0.818\n",
       "       41      0.909  0.222        0.818\n",
       "       42      0.897  0.221        0.808\n",
       "       43      0.911  0.269        0.857\n",
       "       44      0.934  0.417        0.917\n",
       "       45      0.891  0.196        0.783\n",
       "       46      0.905  0.269        0.836\n",
       "       47      0.913  0.260        0.841\n",
       "       48      0.921  0.332        0.891\n",
       "       49      0.913  0.218        0.826\n",
       "       50      0.913  0.245        0.838\n",
       "       51      0.898  0.266        0.832\n",
       "       52      0.902  0.236        0.817\n",
       "       53      0.913  0.270        0.859\n",
       "       54      0.925  0.335        0.894\n",
       "       55      0.903  0.235        0.811\n",
       "       56      0.899  0.240        0.812\n",
       "       57      0.892  0.212        0.806\n",
       "       58      0.902  0.226        0.826\n",
       "       59      0.937  0.351        0.912\n",
       "       60      0.898  0.282        0.866\n",
       "       61      0.927  0.323        0.884\n",
       "       62      0.941  0.421        0.918\n",
       "       63      0.907  0.238        0.831\n",
       "       64      0.920  0.252        0.851\n",
       "       65      0.921  0.344        0.884\n",
       "       66      0.894  0.247        0.815\n",
       "       67      0.913  0.272        0.845\n",
       "       68      0.889  0.206        0.801\n",
       "       69      0.908  0.241        0.825\n",
       "       70      0.915  0.276        0.850\n",
       "       71      0.912  0.354        0.884\n",
       "       72      0.921  0.365        0.895\n",
       "       73      0.903  0.235        0.817\n",
       "       74      0.899  0.275        0.857\n",
       "       75      0.904  0.259        0.818\n",
       "       76      0.905  0.331        0.869\n",
       "       77      0.908  0.266        0.848\n",
       "       78      0.899  0.256        0.840\n",
       "       79      0.928  0.314        0.885\n",
       "       80      0.912  0.269        0.848\n",
       "       81      0.904  0.234        0.816\n",
       "       82      0.889  0.243        0.817\n",
       "       83      0.908  0.243        0.846\n",
       "       84      0.916  0.317        0.867\n",
       "       85      0.904  0.219        0.796\n",
       "       86      0.901  0.283        0.852\n",
       "       87      0.913  0.266        0.854\n",
       "       88      0.929  0.332        0.879\n",
       "       89      0.922  0.318        0.880\n",
       "       90      0.920  0.328        0.895\n",
       "       91      0.909  0.281        0.861\n",
       "       92      0.889  0.221        0.800\n",
       "       93      0.903  0.231        0.804\n",
       "       94      0.916  0.288        0.855\n",
       "       95      0.914  0.305        0.879\n",
       "       96      0.924  0.315        0.892\n",
       "       97      0.911  0.245        0.849\n",
       "       98      0.895  0.179        0.790\n",
       "       99      0.920  0.324        0.876\n",
       "       100     0.890  0.206        0.796\n",
       "2      1       0.814  0.154        0.624\n",
       "       2       0.830  0.175        0.711\n",
       "       3       0.855  0.169        0.720\n",
       "       4       0.809  0.136        0.624\n",
       "       5       0.831  0.209        0.746\n",
       "       6       0.836  0.179        0.712\n",
       "       7       0.845  0.222        0.756\n",
       "       8       0.858  0.184        0.738\n",
       "       9       0.838  0.179        0.752\n",
       "       10      0.857  0.173        0.695\n",
       "       11      0.833  0.190        0.719\n",
       "       12      0.839  0.181        0.731\n",
       "       13      0.861  0.221        0.757\n",
       "       14      0.847  0.143        0.640\n",
       "       15      0.837  0.201        0.713\n",
       "       16      0.858  0.165        0.754\n",
       "       17      0.837  0.185        0.732\n",
       "       18      0.823  0.152        0.676\n",
       "       19      0.811  0.179        0.727\n",
       "       20      0.826  0.138        0.675\n",
       "       21      0.813  0.149        0.626\n",
       "       22      0.870  0.198        0.786\n",
       "       23      0.825  0.144        0.671\n",
       "       24      0.838  0.171        0.699\n",
       "       25      0.851  0.217        0.741\n",
       "       26      0.845  0.171        0.718\n",
       "       27      0.852  0.168        0.748\n",
       "       28      0.797  0.134        0.625\n",
       "       29      0.837  0.195        0.714\n",
       "       30      0.863  0.220        0.768\n",
       "       31      0.848  0.195        0.746\n",
       "       32      0.828  0.151        0.677\n",
       "       33      0.852  0.190        0.745\n",
       "       34      0.804  0.158        0.615\n",
       "       35      0.871  0.215        0.763\n",
       "       36      0.838  0.193        0.733\n",
       "       37      0.832  0.175        0.718\n",
       "       38      0.853  0.169        0.748\n",
       "       39      0.861  0.199        0.757\n",
       "       40      0.815  0.165        0.709\n",
       "       41      0.858  0.193        0.768\n",
       "       42      0.832  0.164        0.699\n",
       "       43      0.834  0.171        0.708\n",
       "       44      0.829  0.138        0.618\n",
       "       45      0.828  0.167        0.691\n",
       "       46      0.821  0.150        0.685\n",
       "       47      0.827  0.183        0.728\n",
       "       48      0.842  0.204        0.740\n",
       "       49      0.864  0.209        0.751\n",
       "       50      0.839  0.179        0.689\n",
       "       51      0.822  0.168        0.696\n",
       "       52      0.843  0.186        0.708\n",
       "       53      0.846  0.200        0.745\n",
       "       54      0.843  0.179        0.719\n",
       "       55      0.850  0.196        0.741\n",
       "       56      0.816  0.153        0.684\n",
       "       57      0.869  0.221        0.780\n",
       "       58      0.838  0.168        0.686\n",
       "       59      0.835  0.176        0.719\n",
       "       60      0.871  0.230        0.778\n",
       "       61      0.817  0.148        0.630\n",
       "       62      0.822  0.176        0.694\n",
       "       63      0.844  0.172        0.729\n",
       "       64      0.852  0.183        0.755\n",
       "       65      0.860  0.186        0.753\n",
       "       66      0.854  0.176        0.751\n",
       "       67      0.803  0.135        0.618\n",
       "       68      0.852  0.211        0.745\n",
       "       69      0.863  0.202        0.778\n",
       "       70      0.854  0.204        0.744\n",
       "       71      0.853  0.194        0.754\n",
       "       72      0.856  0.188        0.744\n",
       "       73      0.816  0.157        0.691\n",
       "       74      0.864  0.203        0.756\n",
       "       75      0.861  0.198        0.766\n",
       "       76      0.830  0.182        0.714\n",
       "       77      0.851  0.173        0.721\n",
       "       78      0.876  0.214        0.780\n",
       "       79      0.840  0.171        0.733\n",
       "       80      0.829  0.171        0.693\n",
       "       81      0.835  0.189        0.741\n",
       "       82      0.830  0.189        0.745\n",
       "       83      0.867  0.221        0.783\n",
       "       84      0.825  0.173        0.708\n",
       "       85      0.835  0.172        0.681\n",
       "       86      0.827  0.168        0.721\n",
       "       87      0.841  0.206        0.756\n",
       "       88      0.840  0.191        0.715\n",
       "       89      0.831  0.148        0.636\n",
       "       90      0.845  0.185        0.750\n",
       "       91      0.845  0.200        0.750\n",
       "       92      0.852  0.183        0.734\n",
       "       93      0.839  0.196        0.728\n",
       "       94      0.844  0.196        0.753\n",
       "       95      0.822  0.138        0.630\n",
       "       96      0.845  0.174        0.702\n",
       "       97      0.855  0.195        0.753\n",
       "       98      0.831  0.148        0.671\n",
       "       99      0.848  0.188        0.742\n",
       "       100     0.818  0.181        0.707\n",
       "Micro  1       0.861  0.216        0.767\n",
       "       2       0.864  0.220        0.773\n",
       "       3       0.866  0.231        0.786\n",
       "       4       0.860  0.221        0.775\n",
       "       5       0.873  0.224        0.777\n",
       "       6       0.857  0.206        0.752\n",
       "       7       0.870  0.228        0.783\n",
       "       8       0.862  0.216        0.767\n",
       "       9       0.877  0.257        0.814\n",
       "       10      0.861  0.218        0.770\n",
       "       11      0.861  0.225        0.778\n",
       "       12      0.855  0.209        0.757\n",
       "       13      0.880  0.239        0.796\n",
       "       14      0.869  0.217        0.768\n",
       "       15      0.856  0.208        0.754\n",
       "       16      0.871  0.232        0.788\n",
       "       17      0.867  0.226        0.780\n",
       "       18      0.870  0.224        0.778\n",
       "       19      0.869  0.214        0.763\n",
       "       20      0.869  0.225        0.778\n",
       "       21      0.878  0.257        0.815\n",
       "       22      0.879  0.246        0.803\n",
       "       23      0.872  0.246        0.803\n",
       "       24      0.871  0.230        0.785\n",
       "       25      0.869  0.224        0.778\n",
       "       26      0.868  0.225        0.779\n",
       "       27      0.862  0.197        0.738\n",
       "       28      0.870  0.225        0.778\n",
       "       29      0.862  0.212        0.762\n",
       "       30      0.859  0.216        0.766\n",
       "       31      0.858  0.211        0.762\n",
       "       32      0.867  0.223        0.776\n",
       "       33      0.882  0.248        0.805\n",
       "       34      0.848  0.203        0.747\n",
       "       35      0.863  0.231        0.786\n",
       "       36      0.867  0.223        0.776\n",
       "       37      0.872  0.227        0.782\n",
       "       38      0.844  0.195        0.734\n",
       "       39      0.868  0.243        0.800\n",
       "       40      0.863  0.226        0.779\n",
       "       41      0.882  0.246        0.803\n",
       "       42      0.876  0.240        0.796\n",
       "       43      0.887  0.247        0.805\n",
       "       44      0.857  0.206        0.752\n",
       "       45      0.858  0.219        0.772\n",
       "       46      0.856  0.216        0.767\n",
       "       47      0.881  0.252        0.809\n",
       "       48      0.861  0.211        0.759\n",
       "       49      0.861  0.217        0.768\n",
       "       50      0.856  0.219        0.772\n",
       "       51      0.852  0.215        0.765\n",
       "       52      0.872  0.221        0.774\n",
       "       53      0.874  0.232        0.789\n",
       "       54      0.846  0.197        0.739\n",
       "       55      0.874  0.236        0.793\n",
       "       56      0.874  0.224        0.777\n",
       "       57      0.870  0.226        0.781\n",
       "       58      0.851  0.213        0.763\n",
       "       59      0.870  0.228        0.783\n",
       "       60      0.879  0.248        0.805\n",
       "       61      0.855  0.212        0.761\n",
       "       62      0.846  0.201        0.745\n",
       "       63      0.867  0.222        0.775\n",
       "       64      0.854  0.215        0.766\n",
       "       65      0.863  0.212        0.761\n",
       "       66      0.874  0.232        0.787\n",
       "       67      0.862  0.211        0.759\n",
       "       68      0.866  0.219        0.771\n",
       "       69      0.878  0.238        0.794\n",
       "       70      0.870  0.217        0.768\n",
       "       71      0.851  0.197        0.739\n",
       "       72      0.876  0.243        0.800\n",
       "       73      0.845  0.198        0.740\n",
       "       74      0.877  0.237        0.794\n",
       "       75      0.849  0.201        0.744\n",
       "       76      0.864  0.219        0.771\n",
       "       77      0.863  0.224        0.777\n",
       "       78      0.865  0.231        0.787\n",
       "       79      0.877  0.243        0.801\n",
       "       80      0.866  0.221        0.773\n",
       "       81      0.856  0.213        0.764\n",
       "       82      0.864  0.226        0.781\n",
       "       83      0.858  0.214        0.764\n",
       "       84      0.860  0.216        0.767\n",
       "       85      0.871  0.225        0.779\n",
       "       86      0.859  0.210        0.758\n",
       "       87      0.866  0.230        0.785\n",
       "       88      0.864  0.209        0.757\n",
       "       89      0.865  0.225        0.779\n",
       "       90      0.850  0.211        0.760\n",
       "       91      0.864  0.218        0.770\n",
       "       92      0.857  0.221        0.774\n",
       "       93      0.865  0.234        0.790\n",
       "       94      0.873  0.235        0.793\n",
       "       95      0.868  0.219        0.772\n",
       "       96      0.871  0.229        0.785\n",
       "       97      0.864  0.224        0.777\n",
       "       98      0.859  0.218        0.770\n",
       "       99      0.871  0.227        0.781\n",
       "       100     0.866  0.229        0.784\n",
       "Macro  1       0.857  0.226        0.748\n",
       "       2       0.883  0.228        0.783\n",
       "       3       0.860  0.234        0.785\n",
       "       4       0.868  0.246        0.798\n",
       "       5       0.868  0.232        0.783\n",
       "       6       0.885  0.272        0.818\n",
       "       7       0.873  0.231        0.763\n",
       "       8       0.869  0.228        0.774\n",
       "       9       0.887  0.245        0.812\n",
       "       10      0.865  0.211        0.766\n",
       "       11      0.869  0.232        0.778\n",
       "       12      0.863  0.264        0.811\n",
       "       13      0.862  0.228        0.768\n",
       "       14      0.872  0.257        0.789\n",
       "       15      0.851  0.181        0.720\n",
       "       16      0.876  0.227        0.799\n",
       "       17      0.860  0.212        0.759\n",
       "       18      0.874  0.219        0.778\n",
       "       19      0.872  0.247        0.798\n",
       "       20      0.860  0.197        0.748\n",
       "       21      0.868  0.208        0.772\n",
       "       22      0.863  0.241        0.776\n",
       "       23      0.866  0.214        0.762\n",
       "       24      0.872  0.254        0.787\n",
       "       25      0.876  0.247        0.796\n",
       "       26      0.861  0.213        0.778\n",
       "       27      0.861  0.205        0.755\n",
       "       28      0.884  0.247        0.816\n",
       "       29      0.860  0.246        0.763\n",
       "       30      0.883  0.255        0.802\n",
       "       31      0.875  0.259        0.800\n",
       "       32      0.864  0.247        0.784\n",
       "       33      0.869  0.218        0.785\n",
       "       34      0.867  0.226        0.779\n",
       "       35      0.861  0.229        0.759\n",
       "       36      0.853  0.214        0.768\n",
       "       37      0.876  0.225        0.796\n",
       "       38      0.866  0.227        0.774\n",
       "       39      0.868  0.221        0.777\n",
       "       40      0.869  0.258        0.766\n",
       "       41      0.856  0.203        0.751\n",
       "       42      0.853  0.211        0.752\n",
       "       43      0.871  0.241        0.791\n",
       "       44      0.875  0.260        0.799\n",
       "       45      0.880  0.230        0.789\n",
       "       46      0.870  0.268        0.803\n",
       "       47      0.868  0.219        0.764\n",
       "       48      0.857  0.222        0.764\n",
       "       49      0.861  0.227        0.764\n",
       "       50      0.877  0.250        0.804\n",
       "       51      0.874  0.258        0.799\n",
       "       52      0.878  0.238        0.792\n",
       "       53      0.853  0.206        0.750\n",
       "       54      0.875  0.231        0.796\n",
       "       55      0.863  0.214        0.765\n",
       "       56      0.874  0.257        0.800\n",
       "       57      0.859  0.208        0.760\n",
       "       58      0.875  0.253        0.808\n",
       "       59      0.867  0.233        0.750\n",
       "       60      0.879  0.287        0.809\n",
       "       61      0.872  0.220        0.788\n",
       "       62      0.877  0.228        0.797\n",
       "       63      0.878  0.251        0.799\n",
       "       64      0.869  0.227        0.786\n",
       "       65      0.856  0.218        0.742\n",
       "       66      0.866  0.211        0.771\n",
       "       67      0.873  0.226        0.791\n",
       "       68      0.879  0.263        0.807\n",
       "       69      0.870  0.233        0.779\n",
       "       70      0.885  0.279        0.818\n",
       "       71      0.880  0.270        0.810\n",
       "       72      0.862  0.225        0.773\n",
       "       73      0.873  0.237        0.796\n",
       "       74      0.875  0.230        0.783\n",
       "       75      0.869  0.262        0.799\n",
       "       76      0.870  0.225        0.780\n",
       "       77      0.877  0.238        0.801\n",
       "       78      0.875  0.246        0.798\n",
       "       79      0.871  0.228        0.789\n",
       "       80      0.861  0.222        0.766\n",
       "       81      0.862  0.215        0.775\n",
       "       82      0.855  0.223        0.775\n",
       "       83      0.870  0.224        0.784\n",
       "       84      0.864  0.242        0.787\n",
       "       85      0.873  0.233        0.769\n",
       "       86      0.868  0.243        0.797\n",
       "       87      0.872  0.241        0.803\n",
       "       88      0.867  0.256        0.793\n",
       "       89      0.868  0.230        0.756\n",
       "       90      0.867  0.204        0.773\n",
       "       91      0.877  0.259        0.818\n",
       "       92      0.873  0.247        0.804\n",
       "       93      0.870  0.231        0.783\n",
       "       94      0.864  0.213        0.758\n",
       "       95      0.876  0.246        0.802\n",
       "       96      0.867  0.233        0.768\n",
       "       97      0.879  0.247        0.797\n",
       "       98      0.873  0.226        0.789\n",
       "       99      0.856  0.183        0.739\n",
       "       100     0.874  0.244        0.794"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_mtl_18_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d467e8-64bd-4760-b740-b2ef4a81a030",
   "metadata": {},
   "source": [
    "#### 3.1.3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96e341-947e-478f-a0c7-dcee311bf307",
   "metadata": {},
   "source": [
    "Similar to Table 4 in paper, the dataframe below summarizes all results. Due to bootstrapping we will get 100 metric (AUC, PPV, or Specificity) values for every combination of experiment (24 hours or 48 hours), cohort type (careunits or unsupervised), and model type (global or multi-task. We will reduce that table in a next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6d3f3e-6330-4c78-947f-f8aa3fe2b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multitask dfs if required\n",
    "metrics_global_18_careunits_btstrp_df = pd.read_hdf('../data/results/model_global_18+9_careunits_bootstrap-ON.h5')\n",
    "metrics_global_18_unsupervised_btstrp_df = pd.read_hdf('../data/results/model_global_18+9_unsupervised_bootstrap-ON.h5')\n",
    "metrics_mtl_18_careunits_btstrp_df = pd.read_hdf('../data/results/model_multitask_18+9_careunits_bootstrap-ON.h5')\n",
    "metrics_mtl_18_unsupervised_btstrp_df = pd.read_hdf('../data/results/model_multitask_18+9_unsupervised_bootstrap-ON.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8a245a-b426-4885-89cc-338aeb3dd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_a_btstrp_df = metrics_global_18_unsupervised_btstrp_df.reset_index()\n",
    "summary_a_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_a_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_a_btstrp_df['Model'] = 'Global'\n",
    "summary_a_btstrp_df['Experiment'] = '18 hours'\n",
    "\n",
    "summary_b_btstrp_df = metrics_global_18_careunits_btstrp_df.reset_index()\n",
    "summary_b_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_b_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_b_btstrp_df['Model'] = 'Global'\n",
    "summary_b_btstrp_df['Experiment'] = '18 hours'\n",
    "\n",
    "summary_c_btstrp_df = metrics_mtl_18_unsupervised_btstrp_df.reset_index()\n",
    "summary_c_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_c_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_c_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_c_btstrp_df['Experiment'] = '18 hours'\n",
    "\n",
    "summary_d_btstrp_df = metrics_mtl_18_careunits_btstrp_df.reset_index()\n",
    "summary_d_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_d_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_d_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_d_btstrp_df['Experiment'] = '18 hours'\n",
    "\n",
    "summary_18_btstrp_df = pd.concat([summary_a_btstrp_df, summary_b_btstrp_df, summary_c_btstrp_df, summary_d_btstrp_df])\n",
    "\n",
    "# summary_e_btstrp_df = metrics_global_48_unsupervised_btstrp_df.reset_index()\n",
    "# summary_e_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "# summary_e_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "# summary_e_btstrp_df['Model'] = 'Global'\n",
    "# summary_e_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "# summary_f_btstrp_df = metrics_global_48_careunits_btstrp_df.reset_index()\n",
    "# summary_f_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "# summary_f_btstrp_df['Cohort type'] = 'Careunits'\n",
    "# summary_f_btstrp_df['Model'] = 'Global'\n",
    "# summary_f_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "# summary_g_btstrp_df = metrics_mtl_48_unsupervised_btstrp_df.reset_index()\n",
    "# summary_g_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "# summary_g_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "# summary_g_btstrp_df['Model'] = 'Multi-task'\n",
    "# summary_g_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "# summary_h_btstrp_df = metrics_mtl_48_careunits_btstrp_df.reset_index()\n",
    "# summary_h_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "# summary_h_btstrp_df['Cohort type'] = 'Careunits'\n",
    "# summary_h_btstrp_df['Model'] = 'Multi-task'\n",
    "# summary_h_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "# summary_48_btstrp_df = pd.concat([summary_e_btstrp_df, summary_f_btstrp_df, summary_g_btstrp_df, summary_h_btstrp_df])\n",
    "\n",
    "# summary_btstrp_df = pd.concat([summary_24_btstrp_df, summary_48_btstrp_df])\n",
    "\n",
    "summary_btstrp_df = summary_18_btstrp_df\n",
    "\n",
    "# This is a trick using a categorical data type to have Macro and Micro after Cohort names while displaying\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cohort = CategoricalDtype(['0', '1', '2', 'CCU', 'CSRU', 'MICU', 'SICU', 'TSICU', 'Macro', 'Micro'], ordered=True)\n",
    "summary_btstrp_df['Cohort'] = summary_btstrp_df['Cohort'].astype(cohort)\n",
    "summary_btstrp_df = summary_btstrp_df.dropna()\n",
    "\n",
    "summary_btstrp_df = pd.melt(summary_btstrp_df, id_vars=['Cohort', 'Sample', 'Cohort type', 'Model', 'Experiment'], var_name='Metric')\n",
    "summary_btstrp_df = summary_btstrp_df.set_index(['Experiment', 'Cohort type', 'Cohort', 'Sample'])\n",
    "summary_btstrp_df = summary_btstrp_df.pivot(columns=['Metric', 'Model'], values='value')\n",
    "summary_btstrp_df = summary_btstrp_df.round(3)\n",
    "# Now summary_btstrp_df has all bootstrapped samples with right multi-indices for rows and columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dba52d-a5a5-4334-9250-1cce29f55065",
   "metadata": {},
   "source": [
    "##### 3.1.3.1. Mean values of metrics from bootstrapped samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c87f18-b85e-461c-bdb4-0061f800bd91",
   "metadata": {},
   "source": [
    "Let's get the mean values of the 100 bootstrapped samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "404d228b-ef74-4685-bfef-9e66109445ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AUC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PPV</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>Cohort type</th>\n",
       "      <th>Cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">18 hours</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">Careunits</th>\n",
       "      <th>CCU</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Unsupervised</th>\n",
       "      <th>0</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric                            AUC               PPV             \\\n",
       "Model                          Global Multi-task Global Multi-task   \n",
       "Experiment Cohort type  Cohort                                       \n",
       "18 hours   Careunits    CCU     0.826      0.830  0.162      0.150   \n",
       "                        CSRU    0.904      0.889  0.137      0.105   \n",
       "                        MICU    0.855      0.854  0.281      0.287   \n",
       "                        SICU    0.809      0.820  0.190      0.211   \n",
       "                        TSICU   0.871      0.863  0.218      0.213   \n",
       "                        Macro   0.853      0.851  0.198      0.193   \n",
       "                        Micro   0.865      0.866  0.224      0.227   \n",
       "           Unsupervised 0       0.858      0.854  0.251      0.229   \n",
       "                        1       0.909      0.903  0.269      0.253   \n",
       "                        2       0.840      0.844  0.180      0.186   \n",
       "                        Macro   0.869      0.867  0.234      0.223   \n",
       "                        Micro   0.865      0.863  0.223      0.216   \n",
       "\n",
       "Metric                         Specificity             \n",
       "Model                               Global Multi-task  \n",
       "Experiment Cohort type  Cohort                         \n",
       "18 hours   Careunits    CCU          0.728      0.702  \n",
       "                        CSRU         0.889      0.856  \n",
       "                        MICU         0.765      0.773  \n",
       "                        SICU         0.643      0.687  \n",
       "                        TSICU        0.751      0.750  \n",
       "                        Macro        0.755      0.754  \n",
       "                        Micro        0.777      0.780  \n",
       "           Unsupervised 0            0.785      0.758  \n",
       "                        1            0.843      0.830  \n",
       "                        2            0.718      0.729  \n",
       "                        Macro        0.782      0.772  \n",
       "                        Micro        0.775      0.765  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "summary_df = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).mean().round(3).dropna()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d8c9a-dfd8-402b-9657-15bc85cb0a59",
   "metadata": {},
   "source": [
    "##### 3.1.3.2 Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3d152-1204-44fb-9d53-750239712492",
   "metadata": {},
   "source": [
    "Now it is time to apply the Wilcoxon Signed-Rank Test. [This video](https://www.youtube.com/watch?v=v4ZHlTbTOK8) has a very good detailed explanation of the Wilcoxon Signed-Rank Test which is a non-parametric version of the paired t-test used when there are not many samples (which is our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72dae71-aa7f-4956-b51a-ea3f51f0aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def calc_wilcoxon(grp_df, what):\n",
    "    if (what == 'auc'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('AUC', 'Global')]\n",
    "        y = grp_df[('AUC', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    if (what == 'ppv'):\n",
    "        # calculate p-value for PPV using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('PPV', 'Global')]\n",
    "        y = grp_df[('PPV', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "    \n",
    "    if (what == 'specificity'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed=Rank Test\n",
    "        x = grp_df[('Specificity', 'Global')]\n",
    "        y = grp_df[('Specificity', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a373080a-62b1-47a2-ae13-bd5dd3433e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AUC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PPV</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Global</th>\n",
       "      <th>Multi-task</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>Cohort type</th>\n",
       "      <th>Cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">18 hours</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">Careunits</th>\n",
       "      <th>CCU</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.830</td>\n",
       "      <td>9.489908e-04</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.150</td>\n",
       "      <td>2.967098e-09</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.702</td>\n",
       "      <td>2.650068e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.889</td>\n",
       "      <td>4.991461e-13</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.105</td>\n",
       "      <td>3.537771e-13</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.856</td>\n",
       "      <td>3.373683e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.854</td>\n",
       "      <td>2.216654e-01</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.287</td>\n",
       "      <td>2.029032e-03</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.773</td>\n",
       "      <td>4.890382e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.134823e-13</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.211</td>\n",
       "      <td>2.863070e-11</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.687</td>\n",
       "      <td>5.806411e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.863</td>\n",
       "      <td>2.085378e-07</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.213</td>\n",
       "      <td>6.387350e-01</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.750</td>\n",
       "      <td>9.958226e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.851</td>\n",
       "      <td>6.278749e-03</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.193</td>\n",
       "      <td>1.054349e-02</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.754</td>\n",
       "      <td>3.179575e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.866</td>\n",
       "      <td>5.162135e-02</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.227</td>\n",
       "      <td>3.897671e-02</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.780</td>\n",
       "      <td>4.271698e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Unsupervised</th>\n",
       "      <th>0</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.854</td>\n",
       "      <td>1.182891e-11</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.229</td>\n",
       "      <td>1.141195e-15</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.758</td>\n",
       "      <td>9.176448e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.903</td>\n",
       "      <td>1.276206e-12</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.253</td>\n",
       "      <td>6.182637e-06</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.830</td>\n",
       "      <td>3.294358e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.097263e-08</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.186</td>\n",
       "      <td>6.627003e-05</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.729</td>\n",
       "      <td>9.112084e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.191810e-07</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.223</td>\n",
       "      <td>2.053781e-11</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.772</td>\n",
       "      <td>5.655456e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.863</td>\n",
       "      <td>2.511418e-11</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.360714e-10</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.765</td>\n",
       "      <td>7.391128e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric                            AUC                             PPV  \\\n",
       "Model                          Global Multi-task       p-value Global   \n",
       "Experiment Cohort type  Cohort                                          \n",
       "18 hours   Careunits    CCU     0.826      0.830  9.489908e-04  0.162   \n",
       "                        CSRU    0.904      0.889  4.991461e-13  0.137   \n",
       "                        MICU    0.855      0.854  2.216654e-01  0.281   \n",
       "                        SICU    0.809      0.820  1.134823e-13  0.190   \n",
       "                        TSICU   0.871      0.863  2.085378e-07  0.218   \n",
       "                        Macro   0.853      0.851  6.278749e-03  0.198   \n",
       "                        Micro   0.865      0.866  5.162135e-02  0.224   \n",
       "           Unsupervised 0       0.858      0.854  1.182891e-11  0.251   \n",
       "                        1       0.909      0.903  1.276206e-12  0.269   \n",
       "                        2       0.840      0.844  1.097263e-08  0.180   \n",
       "                        Macro   0.869      0.867  1.191810e-07  0.234   \n",
       "                        Micro   0.865      0.863  2.511418e-11  0.223   \n",
       "\n",
       "Metric                                                  Specificity  \\\n",
       "Model                          Multi-task       p-value      Global   \n",
       "Experiment Cohort type  Cohort                                        \n",
       "18 hours   Careunits    CCU         0.150  2.967098e-09       0.728   \n",
       "                        CSRU        0.105  3.537771e-13       0.889   \n",
       "                        MICU        0.287  2.029032e-03       0.765   \n",
       "                        SICU        0.211  2.863070e-11       0.643   \n",
       "                        TSICU       0.213  6.387350e-01       0.751   \n",
       "                        Macro       0.193  1.054349e-02       0.755   \n",
       "                        Micro       0.227  3.897671e-02       0.777   \n",
       "           Unsupervised 0           0.229  1.141195e-15       0.785   \n",
       "                        1           0.253  6.182637e-06       0.843   \n",
       "                        2           0.186  6.627003e-05       0.718   \n",
       "                        Macro       0.223  2.053781e-11       0.782   \n",
       "                        Micro       0.216  1.360714e-10       0.775   \n",
       "\n",
       "Metric                                                   \n",
       "Model                          Multi-task       p-value  \n",
       "Experiment Cohort type  Cohort                           \n",
       "18 hours   Careunits    CCU         0.702  2.650068e-09  \n",
       "                        CSRU        0.856  3.373683e-12  \n",
       "                        MICU        0.773  4.890382e-04  \n",
       "                        SICU        0.687  5.806411e-11  \n",
       "                        TSICU       0.750  9.958226e-01  \n",
       "                        Macro       0.754  3.179575e-01  \n",
       "                        Micro       0.780  4.271698e-02  \n",
       "           Unsupervised 0           0.758  9.176448e-16  \n",
       "                        1           0.830  3.294358e-06  \n",
       "                        2           0.729  9.112084e-05  \n",
       "                        Macro       0.772  5.655456e-10  \n",
       "                        Micro       0.765  7.391128e-11  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.loc[:, ('AUC', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='auc')\n",
    "summary_df.loc[:, ('PPV', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='ppv')\n",
    "summary_df.loc[:, ('Specificity', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='specificity')\n",
    "cols = [('AUC', 'Global'), ('AUC', 'Multi-task'), ('AUC', 'p-value'),\n",
    "        ('PPV', 'Global'), ('PPV', 'Multi-task'), ('PPV', 'p-value'),\n",
    "        ('Specificity', 'Global'), ('Specificity', 'Multi-task'), ('Specificity', 'p-value')]\n",
    "summary_df = summary_df[cols]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9db64-0ea1-430f-bd7c-ad92c01d52d7",
   "metadata": {},
   "source": [
    "End time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bcc3686-2ce2-49db-be67-fb2d5b218ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# store/print end time to measure runtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m endtime \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# store/print run time\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# store/print end time to measure runtime\n",
    "endtime = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(f'End time: {endtime}')\n",
    "\n",
    "# store/print run time\n",
    "print(f'This run took {endtime - starttime} hours:min:sec to run')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
