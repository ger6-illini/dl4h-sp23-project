{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652e22f4",
   "metadata": {},
   "source": [
    "<h1><center>CS598 Deep Learning for Healthcare Spring 2023<br>Paper Reproduction Project</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5cbba",
   "metadata": {},
   "source": [
    "<h3><center>Gilberto Ramirez and Jay Kakwani<br><span style=\"font-family:monospace;\">{ger6, kakwani2}@illinois.edu</span><br><font color=\"lightgrey\">Group ID: 27 | Paper ID: 181</font></center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cc966",
   "metadata": {},
   "source": [
    "In this project, we aim to reproduce the paper [*Learning Task for Multitask Learning: Heterogeneous Patient Populations in the ICU* by (Suresh et al, 2018)](https://arxiv.org/abs/1806.02878). In this paper, the authors propose a novel two-step pipeline to predict in-hospital mortality across patient populations with different characteristics. The first step of the pipeline divides patients into relevant non-overlapping cohorts in an unsupervised way using a long short-term memory (LSTM) autoencoder followed by a Gaussian Mixture Model (GMM). The second step of the pipeline predicts in-hospital mortality for each patient cohort identified in the previous step using an LSTM based multi-task learning model where every cohort is considered a different task.\n",
    "The paper claims that by applying this pipeline there will be better predictive results when compared to a model applied to the aggregate population using a single task learning model. According to the authors, the better performance given by this pipeline is due to the combination of a multi-task learning model leveraging shared knowledge across distinct patient groups and the way how those groups were created, i.e., identification using a data-driven method rather than relying on domain knowledge or auxiliary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e318a",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58470c",
   "metadata": {},
   "source": [
    "This paper uses the publicly available [MIMIC-III database](https://www.nature.com/articles/sdata201635) which contains clinical data in a critical care setting. After reviewing the paper in detail, we decided to use [MIMIC-Extract](https://arxiv.org/abs/1907.08322), an open source pipeline by (Wang et al., 2020) for transforming the raw EHR data into usable [Pandas](https://pandas.pydata.org/) dataframes containing hourly time series of vitals and laboratory measurements after performing unit conversion, outlier handling, and aggregation of semantically similar features.\n",
    "\n",
    "Unfortunately, the MIMIC-Extract pipeline misses two features the [paper code](https://github.com/mit-caml/multitask-patients) makes use of:\n",
    "* `timecmo_chart` which indicates the timestamp of a patient after being declared in CMO (Comfort Measures Only) state. This feature comes from a MIMIC-III concept table called `code_status`.\n",
    "* `sapsii` which contains the SAPS (Simplified Acute Physiology Score) II for the patient. This feature comes from another MIMIC-III concept table called `sapsii`.\n",
    "\n",
    "As a result, there are three data files needed to run this notebook:\n",
    "* `all_hourly_data.h5`, an HDF file resulting from running the MIMIC-Extract pipeline which is publicly available in GCP using [this link](https://console.cloud.google.com/storage/browser/mimic_extract) and referenced in the [MIMIC-Extract github repo](https://github.com/MLforHealth/MIMIC_Extract).\n",
    "* `code_status.csv`, a CSV file holding the MIMIC concept table `CODE_STATUS` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "* `sapsii.csv`, a CSV file holding the MIMIC concept table `SAPSII` that can be generated following the instructions in [this link within the MIT-LCP github repo](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts#generating-the-concepts-in-postgresql).\n",
    "\n",
    "The functions used in this notebook assume the three files listed above are in the folder `../data/` by default. However, location can be changed using arguments to the functions that process the data.\n",
    "\n",
    "All code needed to replicate the paper is in [our github repo](https://github.com/ger6-illini/dl4h-sp23-team27-project) inside a Python module called `mtl_patients`.\n",
    "\n",
    "The first function from that module we will start using is `get_summaries()`. This function returns three summaries as dataframes:\n",
    "1. A summary providing some statistics of all patients broken by careunit.\n",
    "2. A summary providing some statistics of all patients broken by SAPS-II score quartile.\n",
    "3. A summary providing some statistics of the 29 distinct physiological measurements used in the paper.\n",
    "\n",
    "These summaries need two arguments to be created:\n",
    "* `cutoff_hours` (default 24) which is the minimum number of hours a patient needs to stay in the ICU to be considered part of a cohort.\n",
    "* `gap_hours` (default 12) which is the number of hours between the end of `cutoff_hours` and the moment a model can start making a mortality prediction.\n",
    "\n",
    "The importance of these two arguments is his impact in the exception criteria used in the paper. In particular, the paper:\n",
    "1. Excludes all patients that met the in-hospital mortality criteria before `cutoff period` + `gap period`.\n",
    "2. Excludes patients that were discharged before `cutoff period` + `gap period`.\n",
    "\n",
    "The in-hospital mortality criteria used in the paper is an extended one and not just considers patients who died but also patients with a CMO (Comfort Measures Only) note. That is considered in the summaries creation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f3462",
   "metadata": {},
   "source": [
    "### 1.1. Summaries, 24 hours (cutoff period) + 12 hours (gap period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493677c",
   "metadata": {},
   "source": [
    "Now let's run the `get_summaries()` function with `cutoff_hours` = 24 and `gap_hours` = 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d024700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 20:07:19.524863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "pathname = \"../code/\"\n",
    "if pathname not in sys.path:\n",
    "    sys.path.append(\"../code/\")\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "from mtl_patients import get_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pat_summ_24_by_cu_df, pat_summ_24_by_sapsiiq_df, vitals_labs_summ_24_df = get_summaries(cutoff_hours=24, gap_hours=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcc93e",
   "metadata": {},
   "source": [
    "Let's now display the resulting summaries one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b48560",
   "metadata": {},
   "source": [
    "#### 1.1.1. Data summary by patients in each intensive care unit (ICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_summ_24_by_cu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dff829",
   "metadata": {},
   "source": [
    "In the previous summary, patients were broken in groups where each group is one of five careunits where patients were first admitted:\n",
    "* CCU: Coronary Care Unit\n",
    "* CSRU: Cardiac Surgery Recovery Unit\n",
    "* MICU: Medical Intensive Care Unit\n",
    "* SICU: Surgical Intensive Care Unit\n",
    "* TSICU: Trauma Surgical Intensive Care Unit\n",
    "\n",
    "In addition, an overall group was also added. The statistics provided by the summary are:\n",
    "* `N`: The number of samples (patients) in the group.\n",
    "* `n`: The number of samples (patients) meeting the in-hospital mortality criteria defined in the paper: patient died or had a note of \"Do Not Resuscitate\" (DNR) or had a note of \"Comfort Measures Only\" (CMO).\n",
    "* `Class Imbalance`: Ratio of patients meeting the in-hospital mortality criteria defined in the paper, i.e., $\\dfrac{\\text{n}}{\\text{N}}$.\n",
    "* `Age (Mean)`: Mean age of patients for each group in years.\n",
    "* `Gender (Male)`: Ratio of patients that are males.\n",
    "\n",
    "This summary was prepared to match Table 1 in the original paper. There are differences between both that can be attributed to the way how data was preprocessed by MIMIC-Extract when compared to the preprocessing done by the authors back in 2018, before MIMIC-Extract became available, and that was not made available by the authors in [their code](https://github.com/mit-caml/multitask-patients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a8e12",
   "metadata": {},
   "source": [
    "#### 1.1.2. Data summary by patients in each SAPS-II score quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1474f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_summ_24_by_sapsiiq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711c274",
   "metadata": {},
   "source": [
    "In the previous summary, patients were broken based on the quartile of the SAPS-II score assigned to them. As it can be seen, the four quartiles have the ranges $[0, 22], [23, 32], [33, 41], [42, 118] $. This was included in the authors code but not in the paper. It seems the class imbalance might have been the primary reason. As it is evident from the summary, most of the patients are in quartile $3$ since they are in an ICU and is expected their values are on the high side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0959c",
   "metadata": {},
   "source": [
    "#### 1.1.3. Data summary for physiological measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_labs_summ_24_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cab69",
   "metadata": {},
   "source": [
    "In the previous summary, all vitals and lab measurements selected in the paper (29 in total) are listed with relevant statistics associated to it:\n",
    "* `min` representing the minimum of the measurement observed in the vitals/labs.\n",
    "* `avg` representing the average of the measurement observed in the vitals/labs.\n",
    "* `max` representing the maximum of the measurement observed in the vitals/labs.\n",
    "* `std` representing the standard deviation of the measurement observed in the vitals/labs.\n",
    "* `N` representing the number of non `NaN` samples for the specific vital/lab measurement.\n",
    "* `pres.` representing the portion of all possible hours across all patients, admissions, and ICU stays where at least one of the 104 vitals/labs measurements in the original MIMIC-Extract pipeline was taken.\n",
    "\n",
    "All these measurements are based on the `vitals_labs_mean` dataframe in the MIMIC-Extract pipeline which provides average of vitals/labs on a per hour basis for each patient after going into an ICU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8f61d-ff14-4a78-99cf-5a3978928b1c",
   "metadata": {},
   "source": [
    "### 1.2. Summaries, 48 hours (cutoff period) + 24 hours (gap period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0fefb8-65b8-4fcc-b684-c61322f7b1a0",
   "metadata": {},
   "source": [
    "Now let's run the `get_summaries()` function with `cutoff_hours` = 48 and `gap_hours` = 24:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a66b1-28ca-4d53-933e-8af1d315d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pat_summ_48_by_cu_df, pat_summ_48_by_sapsiiq_df, vitals_labs_summ_48_df = get_summaries(cutoff_hours=48, gap_hours=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979827e-4d1e-43a6-a3b4-76704e8c26bd",
   "metadata": {},
   "source": [
    "#### 1.2.1. Data summary by patients in each intensive care unit (ICU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce01e95-88b5-46e0-a092-1018bb899348",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_summ_48_by_cu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31beb618-466e-4fc0-81ac-d6ddb6e232d8",
   "metadata": {},
   "source": [
    "#### 1.2.2. Data summary by patients in each SAPS-II score quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13fa0c-b0ac-4a86-a27d-1f193979e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_summ_48_by_sapsiiq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db5e52-71ea-4571-8116-c3dff285eb51",
   "metadata": {},
   "source": [
    "#### 1.2.3. Data summary for physiological measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68ecc9-108d-437c-94ee-c401787a1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_labs_summ_48_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b21a0",
   "metadata": {},
   "source": [
    "## 2. Discovering Patient Cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a385d",
   "metadata": {},
   "source": [
    "The paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the first step of the pipeline, i.e., patient cohort discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac0335",
   "metadata": {},
   "source": [
    "In order to identify meaningful patient cohorts, the paper proposes to process the raw patient data in such a way that the result is a 3D matrix of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features as depicted in the figure below (in blue) which is partially based on Figure 2 of the original paper. All numbers shown in the figure below correspond to a specific experiment published in the paper in which the observation window is limited to the first $24$ hours (cutoff period) after a patient goes into a careunit and there is a gap of $12$ hours (gap period) between the end of the observation window and the beginning of the prediction window where the prediction task is in-hospital mortality.\n",
    "\n",
    "Preparation of the data to get the 3D (blue) matrix is performed by a function called `prepare_data()` inside the `mtl_patients.py` module. This preparation consists of the following transformations taken from the paper and the author's code reference implementation:\n",
    "1. Calculation of the mortality flag (prediction label) and mortality time for every patient in the dataset using an *extended* definition of mortality: death, a note of \"Do Not Resuscitate\" (DNR), or a note of \"Comfort Measures Only\" (CMO). In case any of these conditions are met for a patient, the corresponding mortality label is set to *True* and the corresponding mortality time is considered as the earliest time of any of the three conditions. After reviewing in detail the author's code implementation it seems mortality is based on deathtime and a CMO note but not DNR. However, the calculation of the time of death is based on the earliest time of the three conditions.\n",
    "2. Data used for the prediction is only limited to the first certain amount of hours after a patient goes into the ICU. This amount of hours is called inside the code \"a cutoff period\" (observation window) and defines the period of data used to train all models. In addition, there is another number of hours called inside the code \"the gap period\" which represents the time between the end of the observation window and the beginning of the prediction window to prevent label leakage. All patients that died under the *extended* definition before the cutoff period plus the gap period or stayed less than the cutoff period are excluded from the experiment as part of this step. Also, all patients under the age of 15 are excluded (this is already part of the exclusion criteria of the MIMIC-Extract pipeline).\n",
    "3. There are 29 vitals/labs timeseries selected by the paper. Only data within the cutoff period for vitals/labs is kept and rest is removed. This will be used for the rest of the machine learning pipeline.\n",
    "4. All vitals/labs values are converted to z-scores so they all have zero mean and unit standard deviation. Those z-scores are rounded to the closest integer and clipped between $-4$ and $4$ or set to $9$ in case of `NaN`. This allows to map every vital/lab measurement (a float) to one of ten possible values $[-4, -3, -2, -1, 0, 1, 2, 3, 4, 9]$, so they can be converted to dummy values. After dummifying the vitals/labs, column for the $9$ values (`NaN`) is removed, and the resulting matrix is sparse and containing either $0$s or $1$s.\n",
    "5. Every patient is padded with rows of zeroes for those hours that are missed. For example, if a patient only has vitals/labs for the first ten hours and the cutoff period is 24, code adds fourteen hours (rows) with zeroes for that patient. In the end, the matrix will have a size of $P \\times T \\times F$ as expected by the subsequent models.\n",
    "6. Finally, static data (gender, age, and ethnicity) is converted to integers representing categories and dummified. In case of age, there are four buckets established; $(10, 30), (30, 50), (50, 70), (70, \\infty)$; while ethnicity is broken into five buckets (asian, white, hispanic, black, other).\n",
    "7. Cohort assignments based on first careunit or Simplified Acute Physiology Score (SAPS) II score quartile is calculated for each patient and returned as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d014e8",
   "metadata": {},
   "source": [
    "![Figure 1](../img/paper-181-fig-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a251",
   "metadata": {},
   "source": [
    "The `discover_cohorts()` function inside the `mtl_patients.py` module is the one implementing the pipeline shown in the figure above and then calling the `prepare_data()` function detailed previously as the first step. Once data has been processed, the function will break the data in training, validation, and test data sets in a $70\\%/10\\%/20\\%$ proportion.\n",
    "\n",
    "The training data is used to train an LSTM autoencoder. The main purpose of the LSTM autoencoder is to generate a fixed-length dense representation (embedding) of the sparse inputs trying to retain the most important parts of the inputs. The paper selected embeddings of size $50$ as the optimal dimension (hyperparameter). The purple box in the middle of the diagram above (a 2D matrix) represents the embeddings after the LSTM autoencoder learned the representation of the original 3D matrix of shape $(32537 \\times 24 \\times 232)$ where every row corresponds to a patient.\n",
    "\n",
    "Once the embeddings are calculated, a Gaussian Mixture Model is applied using $3$ clusters (the value the authors considered optimal). The result are the three green boxes representing three cohorts discovered in an unsupervised way and grouping similar patients based on the three static and the 29 time-varying vitals/labs selected from the MIMIC-III database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa284f2-7c60-42ae-a9f7-80b5236438fc",
   "metadata": {},
   "source": [
    "### 2.1. Cohort statistics at 24 hours and 48 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc972ff9-3e4b-4c88-b942-f267162c0b34",
   "metadata": {},
   "source": [
    "The paper runs two experiments. The first experiment uses a cutoff period of 24 hours, a gap period of 12 hours, and three clusters. Let's run this first experiment using the `discover_cohorts()` function and determine the corresponding cohort assignment for every patient that does not meet the exception criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81181566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtl_patients import discover_cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cohort_unsupervised_24 = discover_cohorts(cutoff_hours=24, gap_hours=12, cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bb614-d19b-4781-ba6f-f3eefb7771d0",
   "metadata": {},
   "source": [
    "The second experiment uses a cutoff period of 48 hours, a gap period of 24 hours, and two instead of three clusters. The reduction in the number of clusters is proposed by the authors (Table 3 of the paper). Let's run now this second experiment using the `discover_cohorts()` function and determine the corresponding cohort assignment for every patient that does not meet the exception criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f8df9-ec81-4d57-8e45-6a7f3348beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cohort_unsupervised_48 = discover_cohorts(cutoff_hours=48, gap_hours=24, num_clusters=2, cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d175b6-7a5e-4a1b-9afc-67a94c9a0d6b",
   "metadata": {},
   "source": [
    "Let's summarize the results of the 24 hour and 48 hour experiments similar to what Table 3 of the paper shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dec00-4046-44dd-981b-6e6eaccc280f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Let's create the summary for the 24 hour experiment\n",
    "\n",
    "cohort_unsupervised_24 = np.load('../data/unsupervised_clusters_24.npy')\n",
    "\n",
    "from mtl_patients import prepare_data\n",
    "_, Y, _, _, subject_ids = prepare_data(cutoff_hours=24, gap_hours=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859cfff-9c3a-4135-bf83-52a30982042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = np.array(subject_ids.tolist())\n",
    "cohort_unsupervised_24_df = pd.DataFrame({'subject_id': subject_ids, 'Y': Y, 'Group': cohort_unsupervised_24}, dtype=int)\n",
    "\n",
    "# calculate summaries per cohort (24 hours)\n",
    "table3_a_df = cohort_unsupervised_24_df.groupby('Group').agg(\n",
    "    N=('Y', 'size'),\n",
    "    n=('Y', 'sum'),\n",
    ")\n",
    "table3_a_df.loc[:, 'Experiment'] = '24 hours'\n",
    "table3_a_df.loc[:, 'Cohort Type'] = 'Unsupervised'\n",
    "\n",
    "# calculate overall summary (24 hours)\n",
    "table3_a_overall_df = table3_a_df.groupby(['*'] * len(table3_a_df)).agg(\n",
    "    N=('N', 'sum'),\n",
    "    n=('n', 'sum'),\n",
    ")\n",
    "table3_a_overall_df.index.name = 'Group'\n",
    "table3_a_overall_df.loc[:, 'Experiment'] = '24 hours'\n",
    "table3_a_overall_df.loc[:, 'Cohort Type'] = 'Global'\n",
    "\n",
    "# merge 24 hour tables and make cosmetic changes\n",
    "table3_a_df = pd.concat([table3_a_df, table3_a_overall_df], axis=0)\n",
    "table3_a_df.reset_index(inplace=True)\n",
    "table3_a_df.set_index(['Experiment', 'Cohort Type', 'Group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb404fc8-afc2-4f6a-a1e6-321790d129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Let's create the summary for the 48 hour experiment\n",
    "\n",
    "cohort_unsupervised_48 = np.load('../data/unsupervised_clusters_48.npy')\n",
    "\n",
    "_, Y, _, _, subject_ids = prepare_data(cutoff_hours=48, gap_hours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fa092-f43d-41e2-935f-2998c2ccd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = np.array(subject_ids.tolist())\n",
    "cohort_unsupervised_48_df = pd.DataFrame({'subject_id': subject_ids, 'Y': Y, 'Group': cohort_unsupervised_48}, dtype=int)\n",
    "\n",
    "# calculate summaries per cohort (48 hours)\n",
    "table3_b_df = cohort_unsupervised_48_df.groupby('Group').agg(\n",
    "    N=('Y', 'size'),\n",
    "    n=('Y', 'sum'),\n",
    ")\n",
    "table3_b_df.loc[:, 'Experiment'] = '48 hours'\n",
    "table3_b_df.loc[:, 'Cohort Type'] = 'Unsupervised'\n",
    "\n",
    "# calculate overall summary (48 hours)\n",
    "table3_b_overall_df = table3_b_df.groupby(['*'] * len(table3_b_df)).agg(\n",
    "    N=('N', 'sum'),\n",
    "    n=('n', 'sum'),\n",
    ")\n",
    "table3_b_overall_df.index.name = 'Group'\n",
    "table3_b_overall_df.loc[:, 'Experiment'] = '48 hours'\n",
    "table3_b_overall_df.loc[:, 'Cohort Type'] = 'Global'\n",
    "\n",
    "# merge 48 hour tables and make cosmetic changes\n",
    "table3_b_df = pd.concat([table3_b_df, table3_b_overall_df], axis=0)\n",
    "table3_b_df.reset_index(inplace=True)\n",
    "table3_b_df.set_index(['Experiment', 'Cohort Type', 'Group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29a681-55f8-40db-ab68-51567aa5b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# Now let's merge results for 24 and 48 hour experiments in one table\n",
    "\n",
    "# merge 24 hour and 48 hour tables\n",
    "table3_df = pd.concat([table3_a_df, table3_b_df], axis=0)\n",
    "\n",
    "# calculate class imbalance\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'n'] / table3_df.loc[:, 'N']\n",
    "table3_df.loc[:, 'Class Imbalance'] = table3_df.loc[:, 'Class Imbalance'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcfcf3-9d5b-42e0-be79-29ed32ab4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29774c-0fff-481f-8110-161bed1b65a5",
   "metadata": {},
   "source": [
    "Table above is the equivalent to Table 3 in the paper. We can see the results are different. Data from MIMIC-Extract might be different from the data used by the authors.\n",
    "\n",
    "For the 24 hours experiment, size of the clusters are different and mortality as well. For instance, clusters 0 and 1 are smaller compared to cluster 2 but the mortality rate is significantly higher (9.27% and 10.15% versus 4.49%). For the 48 hours experiment, size and mortality of the two resulting clusters are closer when compared to the results from the 24 hour experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671387b-6023-49c7-a119-8ae1021d8e08",
   "metadata": {},
   "source": [
    "### 2.2. Visualization of selected lab test and vital signs features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1077e-5513-4da4-a004-bb6e129517db",
   "metadata": {},
   "source": [
    "In this section, we will try to reproduce the results from Figure 4 (section 6.1.1) in the paper. In Figure 4, data from experiment 1 (24 hours) is used to create heatmap plots to determine if patients from different cohorts are physiologically distinct. To do that, we added the function `get_heatmap_data()` to get the mean of all z-scores by patient, by hour in the ICU, by cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901b173-79ad-48d2-bbfe-1777bf4018d3",
   "metadata": {},
   "source": [
    "#### 2.2.1. Heatmap plots for experiment 1 (24 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fcfdf-b0a2-4b96-be22-a6161ac264c0",
   "metadata": {},
   "source": [
    "Let's run the `get_heatmap_data()` function using the cohorts discovered in experiment 1 (24 hour cutoff period and 12 hour gap period):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072de563-acf3-4d8d-9cfa-28cff6c798b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import get_heatmap_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labs_df, vitals_df = get_heatmap_data(cutoff_hours=24, gap_hours=12,\n",
    "                                      cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e156d2-30a5-4f54-9223-0a33ac593ac7",
   "metadata": {},
   "source": [
    "Let's plot the heatmaps for the selected lab tests and vitals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3a472-9588-4bb6-b473-a19df11e1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cohorts = len(np.unique(labs_df.index.get_level_values(0)))\n",
    "fig, axs = plt.subplots(nrows=2, ncols=num_cohorts)\n",
    "fig.set_size_inches(24, 12)\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = labs_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[0, i], yticklabels=True if i==0 else False).set(title=f'Lab Tests – Cohort {i}')\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = vitals_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[1, i], yticklabels=True if i==0 else False).set(title=f'Vitals – Cohort {i}')\n",
    "plt.savefig('../img/heatmap_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c31f21-a203-44cb-b0e7-51b340e8b411",
   "metadata": {},
   "source": [
    "From the heatmap plots there are some trends in the physiological data that seems to show a distinction between cohorts. In case of labs glucose and blood area nitrogen seems to be different between the three cohorts. However, some of the vitals definitely show different trends in some cases. Blood pressure across the different cohorts is different. When cohort 0 patients have a diastolic blood pressure that tends to drop the longer the patient stays, patients from cohort 2 have a diastolic blood pressure that tends to increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364d425-2928-4535-bbaa-2a2eb54315fc",
   "metadata": {},
   "source": [
    "#### 2.2.2. Heatmap plots for experiment 2 (48 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99947e0-411d-4a2f-8693-a6e4d2b4e9c5",
   "metadata": {},
   "source": [
    "Let's run the `get_heatmap_data()` function using the cohorts discovered in experiment 2 (48 hour cutoff period and 24 hour gap period):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f6a0a-42f2-4dba-8d90-c5c7b27c9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labs_df, vitals_df = get_heatmap_data(cutoff_hours=48, gap_hours=24,\n",
    "                                      cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a7b3a-a09b-4bf7-9b6a-7a332a01db72",
   "metadata": {},
   "source": [
    "Let's plot the heatmaps for the selected lab tests and vitals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf433d-094f-4e28-9c31-2c7f7e477e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cohorts = len(np.unique(labs_df.index.get_level_values(0)))\n",
    "fig, axs = plt.subplots(nrows=2, ncols=num_cohorts)\n",
    "fig.set_size_inches(24, 12)\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = labs_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[0, i], yticklabels=True if i==0 else False).set(title=f'Lab Tests – Cohort {i}')\n",
    "for i in np.arange(num_cohorts):\n",
    "    plot_df = vitals_df.unstack(1).stack(1).query(f'cohort == {i}').droplevel(0)\n",
    "    sns.heatmap(plot_df, ax=axs[1, i], yticklabels=True if i==0 else False).set(title=f'Vitals – Cohort {i}')\n",
    "plt.savefig('../img/heatmap_48')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb4790-a69b-41b6-84cb-489695f5df57",
   "metadata": {},
   "source": [
    "In the 48 hour experiment, labs do not show significant differences between the two cohorts. However, the vitals show changes in the blood pressure where cohort 1 trend is more on the high side compared to cohort 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db5427-8514-4b98-a260-ba574192e822",
   "metadata": {},
   "source": [
    "## 3. Predicting In-Hospital Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e49cd5-dafc-401c-b946-2be0c4734bfb",
   "metadata": {},
   "source": [
    "As mentioned in the previous section, the paper uses a two-step pipeline to: 1) identify relevant patient cohorts, and 2) use those relevant cohorts as separate tasks in a multi-lask learning framework to predict in-hospital mortality. In this section, we will focus on the second step of the pipeline, i.e., use multi-task learning to make in-hospital mortality predictions for different patient cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68d853-3a48-403e-8ee9-427bb876f783",
   "metadata": {},
   "source": [
    "The second step uses as input the result from the first step which is a series of 3D matrices, one per discovered cohort, of shape $(P \\times T \\times F)$ where $P$ represents the number of patients, $T$ the number of timesteps, and $F$ the number of features. As an example, the 24 hour experiment described by the authors in the paper and reproduced in the previous section resulted in three cohorts (clusters) called group 0, group 1, and group 2 where the shapes of the corresponding 3D matrices are:\n",
    "* $14120 \\times 24 \\times 232$ for group 0,\n",
    "* $10841 \\times 24 \\times 232$ for group 1, and\n",
    "* $7752 \\times 24 \\times 232$ for group 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbd026-c557-41b8-b7ac-f1d11e78aef3",
   "metadata": {},
   "source": [
    "To convert these matrices into predictions, the paper proposes an LSTM for all model configurations including the baseline. In particular, the paper shows results from two specific models: a baseline model that is called *global* and using single-task learning and the multi-task learning model the authors claim as superior to the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f9738-790c-472c-b329-bcc654eaea0a",
   "metadata": {},
   "source": [
    "A diagram of the baseline (*global*) model proposed by the authors is shown below. As it can be seen, this model consists of an LSTM layer of 16 cells using a RELU activation function followed by a *single* dense layer with a sigmoid activation function. The result of the dense (fully-connected) layer is an estimate of the probability of in-hospital mortality for a given patient. This baseline model is trained with all patient samples regardless the cohort, hence the name *global*, and used for per cohort predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07256b-dc0b-4238-8a79-c37ddba39885",
   "metadata": {},
   "source": [
    "![Figure 2](../img/paper-181-fig-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44531b75-a84e-4089-9a2a-3620becfc355",
   "metadata": {},
   "source": [
    "Moving to the second model and the one the authors claim it provides benefits against the baseline is the so called *multi-task learning model*. This model consists of an LSTM layer with same number of cells (16) as the baseline model, to ensure the comparison is fair, connected to as many dense layers as population subgroups (cohorts). Each of these cohorts is considered a *task* and authors propose training these models on multiple tasks simultaneously in contrast to the baseline model with just one dense layer. The benefit of this approach according to the authors is the ability to share knowledge learned from one task (cohort) to rest of tasks under the assumption that the subpopulations used are distinct enough with relation to the outcome learned (mortality) that such shared knowledge truly exists. A representation of the multi-task learning model is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8a713-3999-400d-880d-1c98a8738ab8",
   "metadata": {},
   "source": [
    "![Figure 3](../img/paper-181-fig-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776d05-12aa-4b18-ac87-468f91d79ee1",
   "metadata": {},
   "source": [
    "For benchmarking purposes of the entire pipeline, the authors compared the results from running the pipeline using unsupervised cohort discovery (step one) against cohorts created using the first careunit the patient went into which can be considered an engineered feature. We will show those results in the next subsections.\n",
    "\n",
    "The overall performance of this model is measured using both macro and micro metrics (section 4.3 in the paper) where:\n",
    "* In *micro* metrics all predicted probabilities for all patients are treated as if they come from a single classifier: $\\text{Metric}_\\text{Micro} = \\text{Metric}([\\hat{y}_0, ..., \\hat{y}_k], [y_0, ..., y_K])$.\n",
    "* In *macro* metrics probabilities are evaluated on a *per cohort* basis, and then averaged: $\\text{Metric}_\\text{Macro} = \\dfrac{1}{K} \\displaystyle\\sum_{k=0}^K \\text{Metric}(\\hat{y}_K, y_K)$.\n",
    "\n",
    "Paper suggests that, although micro metrics are the ones typically chosen in the literature, evaluating performance on different subpopulations will benefit from macro metrics instead of micro metrics specially when there is class imbalance in every cohort. All results show macro and micro versions of the metrics for the aggregate performance of the models.\n",
    "\n",
    "All results being used for comparison between models by the paper will use three metrics:\n",
    "* AUC (Area Under the ROC Curve) for every cohort and, for the aggregate performance, macro and micro.\n",
    "* PPV (Positive Predictive Value which is same as Precision) for every cohort and, for the aggregate performance, macro and micro. This PPV is calculated at a sensitivity of 80%, a value selected by the paper authors.\n",
    "* Specificity for every cohort and, for the aggregate performance, macro and micro. This specificity is calculated at a sensitivity of 80%, a value selected by the paper authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec025760-eb01-4aab-8180-304ae4599a38",
   "metadata": {},
   "source": [
    "All in-hospital mortality prediction tasks are implemented using the function `run_mortality_prediction_task()`. This function will call other functions to prepare the data, split the data in training/validation/test data sets, train the corresponding model, predict using the resulting model, and calculate the metrics of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d59d04-dfe5-4bab-80a3-fc008c105783",
   "metadata": {},
   "source": [
    "### 3.1. Predictions without Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512018c-1dcb-40f1-aa6a-acbce6fca3a1",
   "metadata": {},
   "source": [
    "In this section all in-hospital mortality predictions across the two models, global and multi-task learning, and across the two experiments, 24 hours and 48 hours, are calculated for the three metrics; AUC, PPV (precision) @80% sensitivity, and Specificity @80% sensitivity; using the test set (20% of the original dataset). No bootstrapping is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2f3cd-42ca-42ba-b48a-a8d536030ba5",
   "metadata": {},
   "source": [
    "#### 3.1.1. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 24 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af77c0-0c08-483d-a63b-19cf0f433e95",
   "metadata": {},
   "source": [
    "Let's first run the mortality prediction task using the *global* model (baseline) in the 24 hour experiment setting. In this experiment, the cutoff period is 24 hours and the gap period is 12 hours, meaning model can only feed from patient data collected during the first 24 hours of the ICU stay, and predict mortality 36 hours after patient goes into the ICU to avoid label leakage. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a5bdf-7131-4c23-a39d-41a9f47394fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_global_24_careunits_df = run_mortality_prediction_task(model_type='global', cutoff_hours=24, gap_hours=12, cohort_criteria_to_select='careunits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d99ef5-2261-4f1b-bcf1-0a0b597b042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_24_careunits_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1965b8-f887-400b-a690-2e4927dd0ba3",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d8a8a-c476-47b0-a4bb-e17af13ae059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_global_24_unsupervised_df = run_mortality_prediction_task(model_type='global', cutoff_hours=24, gap_hours=12,\n",
    "                                                                  cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d551b-6880-4016-8e2c-4b62f9f4f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_24_unsupervised_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972982a2-558a-4970-960c-95fd795bf4f6",
   "metadata": {},
   "source": [
    "#### 3.1.2. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 48 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748b404-8560-46c2-a5f6-959f4405ac66",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the *global* model (baseline) in the 48 hour experiment setting. In this experiment, the cutoff period is 48 hours and the gap period is 24 hours, meaning model can only feed from patient data collected during the first 48 hours of the ICU stay, and predict mortality 72 hours after patient goes into the ICU to avoid label leakage. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89891d2-19ab-41be-9532-6668dffd257a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_global_48_careunits_df = run_mortality_prediction_task(model_type='global', cutoff_hours=48, gap_hours=24, cohort_criteria_to_select='careunits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3ec4f-fe8c-47c5-b140-43859ab4463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_48_careunits_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cb1a2-2a44-4b86-82ec-dcdbed9bbfe1",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77732870-873d-4e1a-99ed-65a2331eb2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_global_48_unsupervised_df = run_mortality_prediction_task(model_type='global', cutoff_hours=48, gap_hours=24,\n",
    "                                                                  cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d3aba-ff49-4a9a-b4ff-edc87c45b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_48_unsupervised_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998f5fe-85a5-46ae-81eb-dbcde28e4b59",
   "metadata": {},
   "source": [
    "#### 3.1.3. In-Hospital Mortality Prediction – Multi-Task Learning Model at 24 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bbb7c-6a4b-437c-b881-9599ca1d088b",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 24 hour experiment setting. In this experiment, the cutoff period is 24 hours and the gap period is 12 hours, meaning model can only feed from patient data collected during the first 24 hours of the ICU stay, and predict mortality 36 hours after patient goes into the ICU to avoid label leakage. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857d90e-4e5a-4e58-b2d0-8c69a7667842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_24_careunits_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=24, gap_hours=12, cohort_criteria_to_select='careunits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2df7f8-4758-4e97-90a5-7dcd5a6b51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_24_careunits_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af687a6-6509-456e-b6ad-f4dc1f4e59e7",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6aa72d-e26f-463f-ae05-f85fd3293f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_24_unsupervised_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=24, gap_hours=12,\n",
    "                                                               cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05e2eb-efe7-4725-8932-9b7cd3586137",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_24_unsupervised_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df31321-29ba-49f3-ac4e-3c99cffd7d9b",
   "metadata": {},
   "source": [
    "#### 3.1.4. In-Hospital Mortality Prediction – Multi-Task Learning Model at 48 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ac5d1-d7c5-4ef1-bda7-baa5d90d089d",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 48 hour experiment setting. In this experiment, the cutoff period is 48 hours and the gap period is 24 hours, meaning model can only feed from patient data collected during the first 48 hours of the ICU stay, and predict mortality 72 hours after patient goes into the ICU to avoid label leakage. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23655239-3a10-4cce-aad2-5388de02c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_48_careunits_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=48, gap_hours=24, cohort_criteria_to_select='careunits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84efac9f-77c3-4063-8765-96ad814b5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_48_careunits_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3015-d11d-4a89-b6eb-4466afdf4b4a",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc60d1-59b9-47f8-99c9-56185631190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_48_unsupervised_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=48, gap_hours=24,\n",
    "                                                               cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09569892-4b60-47c7-b6aa-95033cf96011",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_48_unsupervised_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c796fc2-b567-4e72-8cec-6ab3f9ced8a4",
   "metadata": {},
   "source": [
    "#### 3.1.5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76426498-e1b8-422b-b54a-2e4b3b559f57",
   "metadata": {},
   "source": [
    "Similar to Table 4 in paper, the dataframe below summarizes all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754da080-9fd5-430f-8c27-4545d20798b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_a_df = metrics_global_24_unsupervised_df.reset_index()\n",
    "summary_a_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_a_df['Cohort type'] = 'Unsupervised'\n",
    "summary_a_df['Model'] = 'Global'\n",
    "summary_a_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_b_df = metrics_global_24_careunits_df.reset_index()\n",
    "summary_b_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_b_df['Cohort type'] = 'Careunits'\n",
    "summary_b_df['Model'] = 'Global'\n",
    "summary_b_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_c_df = metrics_mtl_24_unsupervised_df.reset_index()\n",
    "summary_c_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_c_df['Cohort type'] = 'Unsupervised'\n",
    "summary_c_df['Model'] = 'Multi-task'\n",
    "summary_c_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_d_df = metrics_mtl_24_careunits_df.reset_index()\n",
    "summary_d_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_d_df['Cohort type'] = 'Careunits'\n",
    "summary_d_df['Model'] = 'Multi-task'\n",
    "summary_d_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_24_df = pd.concat([summary_a_df, summary_b_df, summary_c_df, summary_d_df])\n",
    "\n",
    "summary_e_df = metrics_global_48_unsupervised_df.reset_index()\n",
    "summary_e_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_e_df['Cohort type'] = 'Unsupervised'\n",
    "summary_e_df['Model'] = 'Global'\n",
    "summary_e_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_f_df = metrics_global_48_careunits_df.reset_index()\n",
    "summary_f_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_f_df['Cohort type'] = 'Careunits'\n",
    "summary_f_df['Model'] = 'Global'\n",
    "summary_f_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_g_df = metrics_mtl_48_unsupervised_df.reset_index()\n",
    "summary_g_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_g_df['Cohort type'] = 'Unsupervised'\n",
    "summary_g_df['Model'] = 'Multi-task'\n",
    "summary_g_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_h_df = metrics_mtl_48_careunits_df.reset_index()\n",
    "summary_h_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_h_df['Cohort type'] = 'Careunits'\n",
    "summary_h_df['Model'] = 'Multi-task'\n",
    "summary_h_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_48_df = pd.concat([summary_e_df, summary_f_df, summary_g_df, summary_h_df])\n",
    "\n",
    "summary_df = pd.concat([summary_24_df, summary_48_df])\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cohort_type = CategoricalDtype(['CCU', 'CSRU', 'MICU', 'SICU', 'TSICU', 'Macro', 'Micro'], ordered=True)\n",
    "summary_df['Cohort type'] = summary_df['Cohort type'].astype(cohort_type)\n",
    "\n",
    "summary_df = pd.melt(summary_df, id_vars=['Cohort', 'Cohort type', 'Model', 'Experiment'], var_name='Metric')\n",
    "summary_df = summary_df.set_index(['Experiment', 'Cohort type', 'Cohort'])\n",
    "summary_df = summary_df.pivot(columns=['Metric', 'Model'], values='value')\n",
    "summary_df = summary_df.round(3)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d4117-f1f1-4d75-aead-36a9c740e9ae",
   "metadata": {},
   "source": [
    "### 3.2. Predictions with Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da524a9c-1d6f-4d2d-b37d-2e0ef4c369b3",
   "metadata": {},
   "source": [
    "In this section all in-hospital mortality predictions across the two models, global and multi-task learning, and across the two experiments, 24 hours and 48 hours, are calculated for the three metrics; AUC, PPV (precision) @80% sensitivity, and Specificity @80% sensitivity; using 100 bootstrapped samples of the test set (20% of the original dataset). The results will be metrics (AUC, PPV, and Specificity) for each bootstrapped sample. This will allow the comparison between the global model and the multi-task learning model using the Wilcoxon signed-rank test as indicated in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28906d07-2252-4ee3-b4c0-536add086263",
   "metadata": {},
   "source": [
    "#### 3.2.1. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 24 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a1bcc-c348-4d61-9ecf-0ee3ab219132",
   "metadata": {},
   "source": [
    "Let's first run the mortality prediction task using the *global* model (baseline) in the 24 hour experiment setting. In this experiment, the cutoff period is 24 hours and the gap period is 12 hours, meaning model can only feed from patient data collected during the first 24 hours of the ICU stay, and predict mortality 36 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacb099-b8b7-46c2-9d5b-b7bb024edf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"single_task_learning_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16)                15936     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 20:08:05.528535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "229/229 [==============================] - 4s 15ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1773 - accuracy: 0.9365 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1954 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1754 - accuracy: 0.9368 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1959 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 3s 14ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_global_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 3ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1ae0c2093d4d1c96416aa0447c10d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1370b9a8dd0e42a89483a6409f0dcb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0090608e53440e7a6b12cd7ff56d03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98991ca509e1435dbca73b8e162ad326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0457406dbc5641699d7348f6291e6e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ead716c8bd4467bf094c882243f25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_global_24_careunits_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=24, gap_hours=12, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519ff41-0303-4a3f-9ad1-2fd486509878",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 20\n",
    "metrics_global_24_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d00a05-ff33-4b9b-bc34-3b6070b65a9f",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789dbf10-6372-4855-980a-c4bd0a90c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_global_24_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=24, gap_hours=12, bootstrap=True,\n",
    "                                                                         cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbd97a-6b01-472b-9461-0277692f0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_24_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56092fc4-a347-4c32-95f8-2cf8adb4f327",
   "metadata": {},
   "source": [
    "#### 3.2.2. In-Hospital Mortality Prediction – Baseline (*Global*) Model at 48 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3accb4e8-3f96-4063-8849-71d30d185cea",
   "metadata": {},
   "source": [
    "Let's first run the mortality prediction task using the *global* model (baseline) in the 48 hour experiment setting. In this experiment, the cutoff period is 48 hours and the gap period is 24 hours, meaning model can only feed from patient data collected during the first 48 hours of the ICU stay, and predict mortality 72 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68686cb0-0a61-4954-91eb-7d5c7d9bbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_global_48_careunits_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=48, gap_hours=24, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a848db-4c42-45d5-89ed-d0603701a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_48_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9e943-618b-4010-9fa6-10339220dbbc",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe3ccf-459a-44b7-b5a4-3d5e838ada71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_global_48_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='global', cutoff_hours=48, gap_hours=24, bootstrap=True,\n",
    "                                                                         cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef1616-574a-4e3f-a645-81ec956b75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_global_48_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079b1d-28fd-4a67-9613-f188139cf2f5",
   "metadata": {},
   "source": [
    "#### 3.2.3. In-Hospital Mortality Prediction – Multi-Task Learning Model at 24 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a6085-32a9-411a-82be-a1a48894c36d",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 24 hour experiment setting. In this experiment, the cutoff period is 24 hours and the gap period is 12 hours, meaning model can only feed from patient data collected during the first 24 hours of the ICU stay, and predict mortality 36 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3358dc-8459-4225-abfe-841a8db5b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_mtl_24_careunits_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=24, gap_hours=12, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef88acf-1368-465d-80b4-79da55c24be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_24_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00efa1-fc2a-4a82-b443-4b4ced5f7f74",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8284e-e848-4c66-8217-e33f9badb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_24_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=24, gap_hours=12, bootstrap=True,\n",
    "                                                                      cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_24.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd74593-7bef-48c1-ba78-c6114a5ea6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_24_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47950f-79a4-46dd-be35-eb507ab49919",
   "metadata": {},
   "source": [
    "#### 3.2.4. In-Hospital Mortality Prediction – Multi-Task Learning Model at 48 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54117e8-1461-418a-a35b-1048330b785a",
   "metadata": {},
   "source": [
    "Let's now run the mortality prediction task using the multi-task learning model in the 48 hour experiment setting. In this experiment, the cutoff period is 48 hours and the gap period is 24 hours, meaning model can only feed from patient data collected during the first 48 hours of the ICU stay, and predict mortality 72 hours after patient goes into the ICU to avoid label leakage. Since we are enabling bootstrapping, we will repeat same experiment with 100 bootstrapped samples from the test dataset. In terms of the cohort type, let's go with careunits first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93df0b5-c5c1-42bb-82c5-9ce091d30020",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task\n",
    "\n",
    "metrics_mtl_48_careunits_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=48, gap_hours=24, cohort_criteria_to_select='careunits', bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650357b2-f54b-4d80-ac20-912e1b13bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_48_careunits_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50268b-9d0b-4f02-9da9-e2a877883c53",
   "metadata": {},
   "source": [
    "Now, let's repeat the prediction task but this time using the groups fetched in an unsupervised way from step 1 proposed by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a3d8b-d7a7-4028-9045-f91a3952ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_mtl_48_unsupervised_btstrp_df = run_mortality_prediction_task(model_type='multitask', cutoff_hours=48, gap_hours=24, bootstrap=True,\n",
    "                                                                      cohort_criteria_to_select='unsupervised', cohort_unsupervised_filename='../data/unsupervised_clusters_48.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1c55b-f1c6-4d58-baa5-4515ed96df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mtl_48_unsupervised_btstrp_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d467e8-64bd-4760-b740-b2ef4a81a030",
   "metadata": {},
   "source": [
    "#### 3.2.5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96e341-947e-478f-a0c7-dcee311bf307",
   "metadata": {},
   "source": [
    "Similar to Table 4 in paper, the dataframe below summarizes all results. Due to bootstrapping we will get 100 metric (AUC, PPV, or Specificity) values for every combination of experiment (24 hours or 48 hours), cohort type (careunits or unsupervised), and model type (global or multi-task. We will reduce that table in a next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a245a-b426-4885-89cc-338aeb3dd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_a_btstrp_df = metrics_global_24_unsupervised_btstrp_df.reset_index()\n",
    "summary_a_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_a_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_a_btstrp_df['Model'] = 'Global'\n",
    "summary_a_btstrp_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_b_btstrp_df = metrics_global_24_careunits_btstrp_df.reset_index()\n",
    "summary_b_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_b_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_b_btstrp_df['Model'] = 'Global'\n",
    "summary_b_btstrp_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_c_btstrp_df = metrics_mtl_24_unsupervised_btstrp_df.reset_index()\n",
    "summary_c_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_c_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_c_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_c_btstrp_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_d_btstrp_df = metrics_mtl_24_careunits_btstrp_df.reset_index()\n",
    "summary_d_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_d_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_d_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_d_btstrp_df['Experiment'] = '24 hours'\n",
    "\n",
    "summary_24_btstrp_df = pd.concat([summary_a_btstrp_df, summary_b_btstrp_df, summary_c_btstrp_df, summary_d_btstrp_df])\n",
    "\n",
    "summary_e_btstrp_df = metrics_global_48_unsupervised_btstrp_df.reset_index()\n",
    "summary_e_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_e_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_e_btstrp_df['Model'] = 'Global'\n",
    "summary_e_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_f_btstrp_df = metrics_global_48_careunits_btstrp_df.reset_index()\n",
    "summary_f_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_f_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_f_btstrp_df['Model'] = 'Global'\n",
    "summary_f_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_g_btstrp_df = metrics_mtl_48_unsupervised_btstrp_df.reset_index()\n",
    "summary_g_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_g_btstrp_df['Cohort type'] = 'Unsupervised'\n",
    "summary_g_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_g_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_h_btstrp_df = metrics_mtl_48_careunits_btstrp_df.reset_index()\n",
    "summary_h_btstrp_df.rename(columns={'index': 'Cohort'}, inplace=True)\n",
    "summary_h_btstrp_df['Cohort type'] = 'Careunits'\n",
    "summary_h_btstrp_df['Model'] = 'Multi-task'\n",
    "summary_h_btstrp_df['Experiment'] = '48 hours'\n",
    "\n",
    "summary_48_btstrp_df = pd.concat([summary_e_btstrp_df, summary_f_btstrp_df, summary_g_btstrp_df, summary_h_btstrp_df])\n",
    "\n",
    "summary_btstrp_df = pd.concat([summary_24_btstrp_df, summary_48_btstrp_df])\n",
    "\n",
    "# This is a trick using a categorical data type to have Macro and Micro after Cohort names while displaying\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cohort = CategoricalDtype(['0', '1', '2', 'CCU', 'CSRU', 'MICU', 'SICU', 'TSICU', 'Macro', 'Micro'], ordered=True)\n",
    "summary_btstrp_df['Cohort'] = summary_btstrp_df['Cohort'].astype(cohort)\n",
    "summary_btstrp_df = summary_btstrp_df.dropna()\n",
    "\n",
    "summary_btstrp_df = pd.melt(summary_btstrp_df, id_vars=['Cohort', 'Sample', 'Cohort type', 'Model', 'Experiment'], var_name='Metric')\n",
    "summary_btstrp_df = summary_btstrp_df.set_index(['Experiment', 'Cohort type', 'Cohort', 'Sample'])\n",
    "summary_btstrp_df = summary_btstrp_df.pivot(columns=['Metric', 'Model'], values='value')\n",
    "summary_btstrp_df = summary_btstrp_df.round(3)\n",
    "# Now summary_btstrp_df has all bootstrapped samples with right multi-indices for rows and columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dba52d-a5a5-4334-9250-1cce29f55065",
   "metadata": {},
   "source": [
    "##### 3.2.5.1. Mean values of metrics from bootstrapped samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c87f18-b85e-461c-bdb4-0061f800bd91",
   "metadata": {},
   "source": [
    "Let's get the mean values of the 100 bootstrapped samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d228b-ef74-4685-bfef-9e66109445ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "summary_df = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).mean().round(3).dropna()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d8c9a-dfd8-402b-9657-15bc85cb0a59",
   "metadata": {},
   "source": [
    "##### 3.2.5.2 Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3d152-1204-44fb-9d53-750239712492",
   "metadata": {},
   "source": [
    "Now it is time to apply the Wilcoxon Signed-Rank Test. [This video](https://www.youtube.com/watch?v=v4ZHlTbTOK8) has a very good detailed explanation of the Wilcoxon Signed-Rank Test which is a non-parametric version of the paired t-test used when there are not many samples (which is our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dae71-aa7f-4956-b51a-ea3f51f0aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def calc_wilcoxon(grp_df, what):\n",
    "    if (what == 'auc'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('AUC', 'Global')]\n",
    "        y = grp_df[('AUC', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    if (what == 'ppv'):\n",
    "        # calculate p-value for PPV using Wilcoxon Signed Rank Test\n",
    "        x = grp_df[('PPV', 'Global')]\n",
    "        y = grp_df[('PPV', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "    \n",
    "    if (what == 'specificity'):\n",
    "        # calculate p-value for AUC using Wilcoxon Signed=Rank Test\n",
    "        x = grp_df[('Specificity', 'Global')]\n",
    "        y = grp_df[('Specificity', 'Multi-task')]\n",
    "        _, pvalue = wilcoxon(x, y)\n",
    "\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373080a-62b1-47a2-ae13-bd5dd3433e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.loc[:, ('AUC', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='auc')\n",
    "summary_df.loc[:, ('PPV', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='ppv')\n",
    "summary_df.loc[:, ('Specificity', 'p-value')] = summary_btstrp_df.groupby(['Experiment', 'Cohort type', 'Cohort']).apply(calc_wilcoxon, what='specificity')\n",
    "cols = [('AUC', 'Global'), ('AUC', 'Multi-task'), ('AUC', 'p-value'),\n",
    "        ('PPV', 'Global'), ('PPV', 'Multi-task'), ('PPV', 'p-value'),\n",
    "        ('Specificity', 'Global'), ('Specificity', 'Multi-task'), ('Specificity', 'p-value')]\n",
    "summary_df = summary_df[cols]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc3686-2ce2-49db-be67-fb2d5b218ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
