{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cd5f07",
   "metadata": {},
   "source": [
    "# Testing Baseline with Bootstrapping (Global Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025cd50",
   "metadata": {},
   "source": [
    "Importing the functions needed from the `mtl_patients` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531ddfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 17:52:29.255112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "pathname = \"../code/\"\n",
    "if pathname not in sys.path:\n",
    "    sys.path.append(\"../code/\")\n",
    "\n",
    "from mtl_patients import run_mortality_prediction_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a5d97",
   "metadata": {},
   "source": [
    "## `run_mortality_prediction_task()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7d18e",
   "metadata": {},
   "source": [
    "Let's run the mortality prediction task for the *global* model without bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "38bb71e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 4s 13ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n",
      "    Done!\n"
     ]
    }
   ],
   "source": [
    "metrics_df_with_no_bootstrapping = run_mortality_prediction_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "87680d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCU</th>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.993457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRU</th>\n",
       "      <td>0.889536</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.997141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICU</th>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.988731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SICU</th>\n",
       "      <td>0.853458</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.991407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSICU</th>\n",
       "      <td>0.866083</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.993679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.860823</td>\n",
       "      <td>0.572829</td>\n",
       "      <td>0.992883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.992433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC       PPV  Specificity\n",
       "CCU    0.866500  0.666667     0.993457\n",
       "CSRU   0.889536  0.333333     0.997141\n",
       "MICU   0.828538  0.661765     0.988731\n",
       "SICU   0.853458  0.619048     0.991407\n",
       "TSICU  0.866083  0.583333     0.993679\n",
       "Macro  0.860823  0.572829     0.992883\n",
       "Micro  0.863960  0.632000     0.992433"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_with_no_bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "894f8db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUC            float64\n",
       "PPV            float64\n",
       "Specificity    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_with_no_bootstrapping.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a670d",
   "metadata": {},
   "source": [
    "Let's run the mortality prediction task for the *global* model with bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d0263491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 2s 11ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n",
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:19<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"all\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:44<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_df_with_bootstrapping = run_mortality_prediction_task(bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "283ae5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CCU</th>\n",
       "      <th>1</th>\n",
       "      <td>0.857437</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.992481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.892022</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.989669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.869949</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.994463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.888846</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.991605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.835649</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Micro</th>\n",
       "      <th>97</th>\n",
       "      <td>0.873432</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.993420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.871268</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.993584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.849979</td>\n",
       "      <td>0.675439</td>\n",
       "      <td>0.993913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.867830</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.992597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <th></th>\n",
       "      <td>0.860413</td>\n",
       "      <td>0.573397</td>\n",
       "      <td>0.992946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AUC       PPV  Specificity\n",
       "Cohort Sample                                 \n",
       "CCU    1       0.857437  0.588235     0.992481\n",
       "       2       0.892022  0.375000     0.989669\n",
       "       3       0.869949  0.750000     0.994463\n",
       "       4       0.888846  0.578947     0.991605\n",
       "       5       0.835649  0.615385     0.994624\n",
       "...                 ...       ...          ...\n",
       "Micro  97      0.873432  0.682540     0.993420\n",
       "       98      0.871268  0.685484     0.993584\n",
       "       99      0.849979  0.675439     0.993913\n",
       "       100     0.867830  0.642857     0.992597\n",
       "Macro          0.860413  0.573397     0.992946\n",
       "\n",
       "[601 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_with_bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e2ad9",
   "metadata": {},
   "source": [
    "## `run_mortality_prediction_task()` step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b924a2",
   "metadata": {},
   "source": [
    "### Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a382db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa115b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtl_patients import set_global_determinism, prepare_data, stratified_split, create_single_task_learning_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db25ad",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd5a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type='global'\n",
    "cutoff_hours=24\n",
    "gap_hours=12\n",
    "save_to_folder='../data/'\n",
    "cohort_criteria_to_select='careunits'\n",
    "seed=0\n",
    "cohort_unsupervised_filename='../data/unsupervised_clusters.npy'\n",
    "lstm_layer_size=16\n",
    "epochs=30\n",
    "learning_rate=0.0001\n",
    "use_cohort_inv_freq_weights=False\n",
    "bootstrap=False\n",
    "num_bootstrapped_samples=100\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3eec0",
   "metadata": {},
   "source": [
    "### Code common to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe8e2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Preparing the data\n",
      "--------------------------------------------------------------------------------\n",
      "    Loading data from MIMIC-Extract pipeline...\n",
      "    Adding SAPS II score to static dataset...\n",
      "    Adding mortality columns to static dataset...\n",
      "    Discretizing X...\n",
      "        X.shape: (2200954, 33), X.subject_id.nunique(): 34472\n",
      "        X_discrete.shape: (2200954, 225), X_discrete.subject_id.nunique(): 34472\n",
      "    Keep only X_discrete[X_discrete.hours_in < 24]...\n",
      "        New X_discrete.shape: (808539, 223), new X_discrete.subject_id.nunique(): 34472\n",
      "    Padding patients with less than 24 hours of data...\n",
      "    Merging dataframes to create X_full...\n",
      "    Mortality per careunit...\n",
      "        MICU: 1138 out of 11403\n",
      "        SICU: 409 out of 5187\n",
      "        CCU: 344 out of 4907\n",
      "        CSRU: 139 out of 6971\n",
      "        TSICU: 291 out of 4245\n",
      "    Final shape of X: (32713, 24, 232)\n",
      "    Number of positive samples: 2321\n",
      "    Done!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Running the Mortality Prediction Task\n",
      "--------------------------------------------------------------------------------\n",
      "    Splitting data into train/validation/test sets...\n",
      "    Calculating number of training samples in cohort...\n",
      "        # of patients in cohort CCU is 3464\n",
      "        # of patients in cohort CSRU is 4848\n",
      "        # of patients in cohort MICU is 7912\n",
      "        # of patients in cohort SICU is 3696\n",
      "        # of patients in cohort TSICU is 2978\n"
     ]
    }
   ],
   "source": [
    "# setting the seeds to get reproducible results\n",
    "# taken from https://stackoverflow.com/questions/36288235/how-to-get-stable-results-with-tensorflow-setting-random-seed\n",
    "set_global_determinism(seed=seed)\n",
    "\n",
    "# create folders to store models and results\n",
    "for folder in ['results', 'models']:\n",
    "    if not os.path.exists(os.path.join(save_to_folder, folder)):\n",
    "        os.makedirs(os.path.join(save_to_folder, folder))\n",
    "\n",
    "X, Y, careunits, sapsii_quartile, subject_ids = prepare_data(cutoff_hours=cutoff_hours, gap_hours=gap_hours)\n",
    "Y = Y.astype(int) # Y is originally a boolean\n",
    "\n",
    "print('+' * 80, flush=True)\n",
    "print('Running the Mortality Prediction Task', flush=True)\n",
    "print('-' * 80, flush=True)\n",
    "\n",
    "# fetch right cohort criteria\n",
    "if cohort_criteria_to_select == 'careunits':\n",
    "    cohort_criteria = careunits\n",
    "elif cohort_criteria_to_select == 'sapsii_quartile':\n",
    "    cohort_criteria = sapsii_quartile\n",
    "elif cohort_criteria_to_select == 'unsupervised':\n",
    "    cohort_criteria = np.load(f\"{cohort_unsupervised_filename}\")\n",
    "\n",
    "# Do train/validation/test split using `cohort_criteria` as the cohort classifier\n",
    "print('    Splitting data into train/validation/test sets...', flush=True)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, cohorts_train, cohorts_val, cohorts_test = \\\n",
    "    stratified_split(X, Y, cohort_criteria, train_val_random_seed=seed)\n",
    "\n",
    "# one task by distinct cohort\n",
    "tasks = np.unique(cohorts_train)\n",
    "\n",
    "# calculate number of samples per cohort and its reciprocal\n",
    "# (to be used in sample weight calculation)\n",
    "print('    Calculating number of training samples in cohort...', flush=True)\n",
    "task_weights = {}\n",
    "for cohort in tasks:\n",
    "    num_samples_in_cohort = len(np.where(cohorts_train == cohort)[0])\n",
    "    print(f\"        # of patients in cohort {cohort} is {str(num_samples_in_cohort)}\")\n",
    "    task_weights[cohort] = len(X_train) / num_samples_in_cohort\n",
    "\n",
    "sample_weight = None\n",
    "if use_cohort_inv_freq_weights:\n",
    "    # calculate sample weight as the cohort's inverse frequency corresponding to each sample\n",
    "    sample_weight = np.array([task_weights[cohort] for cohort in cohorts_train])\n",
    "\n",
    "model_filename = f\"{save_to_folder}models/model_{cutoff_hours}+{gap_hours}_{cohort_criteria_to_select}\"\n",
    "filename_part_bootstrap = \"bootstrap-ON\" if bootstrap else \"bootstrap-OFF\"\n",
    "results_filename = f'{save_to_folder}results/model_{cutoff_hours}+{gap_hours}_{cohort_criteria_to_select}_{filename_part_bootstrap}.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9230f",
   "metadata": {},
   "source": [
    "### Global model common code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e91f46f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Training 'global' model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 16)                15936     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,953\n",
      "Trainable params: 15,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.3924 - accuracy: 0.9268 - val_loss: 0.2854 - val_accuracy: 0.9291\n",
      "Epoch 2/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.9290 - val_loss: 0.2531 - val_accuracy: 0.9291\n",
      "Epoch 3/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2367 - accuracy: 0.9290 - val_loss: 0.2317 - val_accuracy: 0.9291\n",
      "Epoch 4/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2202 - accuracy: 0.9290 - val_loss: 0.2205 - val_accuracy: 0.9291\n",
      "Epoch 5/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.2139 - val_accuracy: 0.9291\n",
      "Epoch 6/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.2047 - accuracy: 0.9291 - val_loss: 0.2097 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.2059 - val_accuracy: 0.9297\n",
      "Epoch 8/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1949 - accuracy: 0.9309 - val_loss: 0.2036 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1916 - accuracy: 0.9324 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.2011 - val_accuracy: 0.9331\n",
      "Epoch 11/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.1995 - val_accuracy: 0.9315\n",
      "Epoch 12/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1847 - accuracy: 0.9342 - val_loss: 0.1983 - val_accuracy: 0.9340\n",
      "Epoch 13/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1832 - accuracy: 0.9347 - val_loss: 0.1984 - val_accuracy: 0.9331\n",
      "Epoch 14/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1818 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "229/229 [==============================] - 3s 12ms/step - loss: 0.1792 - accuracy: 0.9356 - val_loss: 0.1963 - val_accuracy: 0.9346\n",
      "Epoch 17/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.1965 - val_accuracy: 0.9352\n",
      "Epoch 18/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9352\n",
      "Epoch 19/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9343\n",
      "Epoch 20/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 0.1960 - val_accuracy: 0.9337\n",
      "Epoch 21/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1962 - val_accuracy: 0.9346\n",
      "Epoch 22/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1951 - val_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1965 - val_accuracy: 0.9346\n",
      "Epoch 24/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1723 - accuracy: 0.9378 - val_loss: 0.1960 - val_accuracy: 0.9346\n",
      "Epoch 25/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1716 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9349\n",
      "Epoch 26/30\n",
      "229/229 [==============================] - 3s 11ms/step - loss: 0.1708 - accuracy: 0.9379 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "INFO:tensorflow:Assets written to: ../data/models/model_24+12_careunits/assets\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Predicting using 'global' model...\n",
      "205/205 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#-----------------------\n",
    "# train the global model\n",
    "\n",
    "print('    ' + '~' * 76)\n",
    "print(f\"    Training '{model_type}' model...\")\n",
    "\n",
    "model = create_single_task_learning_model(lstm_layer_size=lstm_layer_size, input_dims=X_train.shape[1:],\n",
    "                                          output_dims=1, learning_rate=learning_rate)\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=100, sample_weight=sample_weight,\n",
    "          callbacks=[early_stopping], validation_data=(X_val, y_val))\n",
    "model.save(model_filename)\n",
    "\n",
    "print('    ' + '~' * 76)\n",
    "print(f\"    Predicting using '{model_type}' model...\", flush=True)\n",
    "y_scores = np.squeeze(model.predict(X_test))\n",
    "y_pred = (y_scores > 0.5).astype(\"int32\")\n",
    "\n",
    "# calculate AUC, PPV, and Specificity for every cohort\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8156826/\n",
    "# https://stackoverflow.com/questions/56253863/precision-recall-and-confusion-matrix-problems-in-sklearn\n",
    "# https://stackoverflow.com/questions/33275461/specificity-in-scikit-learn\n",
    "# PPV (Predictive Positive Value) is same as precision\n",
    "# Specificity is same as recall of the negative class... using that trick to get it in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cf59cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CCU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"CSRU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                        | 6/100 [00:01<00:17,  5.40it/s]/Users/geramire/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"MICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"SICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bootstrap prediction for task \"TSICU\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.81it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     metrics_df\u001b[38;5;241m.\u001b[39mloc[task, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_specificity\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# calculate macro AUC\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m metrics_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m'\u001b[39m, :] \u001b[38;5;241m=\u001b[39m metrics_df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCohort != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calculate micro AUC\u001b[39;00m\n\u001b[1;32m     20\u001b[0m all_auc, all_ppv, all_specificity \u001b[38;5;241m=\u001b[39m bootstrap_predict(X_test, y_test, cohorts_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, model,\n\u001b[1;32m     21\u001b[0m                             num_bootstrap_samples\u001b[38;5;241m=\u001b[39mnum_bootstrapped_samples)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mimic_data_extraction/lib/python3.10/site-packages/pandas/core/indexing.py:1879\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1876\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1882\u001b[0m         )\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1885\u001b[0m \n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "# get `num_bootstrapped_samples` and calculate AUC, PPV, and specificity\n",
    "\n",
    "lst_of_tasks = list(tasks)\n",
    "lst_of_tasks.append('Micro')\n",
    "\n",
    "idx = pd.MultiIndex.from_product([lst_of_tasks, list(np.arange(1, 101))], names=['Cohort', 'Sample'])\n",
    "metrics_df = pd.DataFrame(index=idx, columns=['AUC', 'PPV', 'Specificity'])\n",
    "\n",
    "for task in tasks:\n",
    "    all_auc, all_ppv, all_specificity = bootstrap_predict(X_test, y_test, cohorts_test, task, model,\n",
    "                                num_bootstrap_samples=num_bootstrapped_samples)\n",
    "    metrics_df.loc[task, 'AUC'] = all_auc\n",
    "    metrics_df.loc[task, 'PPV'] = all_ppv\n",
    "    metrics_df.loc[task, 'Specificity'] = all_specificity\n",
    "\n",
    "# calculate macro AUC\n",
    "metrics_df.loc['Macro', :] = metrics_df.query(\"Cohort != 'Micro'\").mean()\n",
    "\n",
    "# calculate micro AUC\n",
    "all_auc, all_ppv, all_specificity = bootstrap_predict(X_test, y_test, cohorts_test, 'all', model,\n",
    "                            num_bootstrap_samples=num_bootstrapped_samples)\n",
    "metrics_df.loc['Micro', 'AUC'] = all_auc\n",
    "metrics_df.loc['Micro', 'PPV'] = all_ppv\n",
    "metrics_df.loc['Micro', 'Specificity'] = all_specificity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
